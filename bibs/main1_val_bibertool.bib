@article{lee2020locomotion,
  author = {Lee, Joonho ; and Hwangbo, Jemin ; and Wellhausen, Lorenz ; and Koltun, Vladlen ; and Hutter, Marco},
  url    = {https://doi.org/10.3929/ethz-b-000448343},
  date   = {2020},
  doi    = {10.3929/ethz-b-000448343},
  title  = {Learning quadrupedal locomotion over challenging terrain},
}

@article{degrave2022fusion,
  author    = {Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de las Casas, Diego and Donner, Craig and Fritz, Leslie and Galperti, Cristian and Huber, Andrea and Keeling, James and Tsimpoukelli, Maria and Kay, Jackie and Merle, Antoine and Moret, Jean Marc and Noury, Seb and Pesamosca, Federico and Pfau, David and Sauter, Olivier and Sommariva, Cristian and Coda, Stefano and Duval, Basil and Fasoli, Ambrogio and Kohli, Pushmeet and Kavukcuoglu, Koray and Hassabis, Demis and Riedmiller, Martin},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/s41586-021-04301-9},
  date      = {2022-02},
  doi       = {10.1038/s41586-021-04301-9},
  issn      = {1476-4687},
  issue     = {7897},
  keywords  = {Computer science,Magnetically confined plasmas,Nuclear fusion and fission},
  pages     = {414--419},
  title     = {Magnetic control of tokamak plasmas through deep reinforcement learning},
  volume    = {602},
}

@article{bellemare2020loon,
  author    = {Bellemare, Marc G. and Candido, Salvatore and Castro, Pablo Samuel and Gong, Jun and Machado, Marlos C. and Moitra, Subhodeep and Ponda, Sameera S. and Wang, Ziyu},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/s41586-020-2939-8},
  date      = {2020-12},
  doi       = {10.1038/s41586-020-2939-8},
  issn      = {1476-4687},
  issue     = {7836},
  keywords  = {Aerospace engineering,Computer science},
  pages     = {77--82},
  title     = {Autonomous navigation of stratospheric balloons using reinforcement learning},
  volume    = {588},
}

@article{vinyals2019starcraft,
  author    = {Vinyals, Oriol and others},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/s41586-019-1724-z},
  date      = {2019-10},
  doi       = {10.1038/s41586-019-1724-z},
  issn      = {1476-4687},
  issue     = {7782},
  keywords  = {Computer science,Statistics},
  pages     = {350--354},
  title     = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  volume    = {575},
}

@article{openai2019dota,
  author = {OpenAI and : and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dbiak, Przemysaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Jzefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and d. O. Pinto, Henrique P. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
  url    = {https://arxiv.org/abs/1912.06680v1},
  date   = {2019-12},
  doi    = {10.48550/arxiv.1912.06680},
  title  = {Dota 2 with Large Scale Deep Reinforcement Learning},
}

@article{ang2005pid,
  author = {Ang, Kiam Heong and Chong, G. and Li, Yun},
  date   = {2005},
  doi    = {10.1109/TCST.2005.847331},
  number = {4},
  pages  = {559--576},
  title  = {PID control system analysis, design, and technology},
  volume = {13},
}

@article{hogan1985impedance,
  author = {Hogan, Neville},
  url    = {https://doi.org/10.1115/1.3140713},
  date   = {1985-03},
  doi    = {10.1115/1.3140713},
  eprint = {https://asmedigitalcollection.asme.org/dynamicsystems/article-pdf/107/1/8/5492420/8\_1.pdf},
  issn   = {0022-0434},
  number = {1},
  pages  = {8--16},
  title  = {{Impedance Control: An Approach to Manipulation: Part IIImplementation}},
  volume = {107},
}

@article{wang2020soft,
  author   = {Wang, Zhongkui and Or, Keung and Hirai, Shinichi},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889019300879},
  date     = {2020},
  doi      = {https://doi.org/10.1016/j.robot.2020.103427},
  issn     = {0921-8890},
  keywords = {Soft gripper,Grasping,Suction,Food packaging,Automation},
  pages    = {103427},
  title    = {A dual-mode soft gripper for food packaging},
  volume   = {125},
}

@article{jumper2021alphafold,
  author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  url    = {https://doi.org/10.1038/s41586-021-03819-2},
  date   = {2021},
  doi    = {10.1038/s41586-021-03819-2},
  isbn   = {1476-4687},
  number = {7873},
  pages  = {583--589},
  title  = {Highly accurate protein structure prediction with AlphaFold},
  volume = {596},
}

@article{ren2015fasterrcnn,
  author    = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  publisher = {IEEE Computer Society},
  url       = {https://arxiv.org/abs/1506.01497v3},
  date      = {2015-06},
  doi       = {10.48550/arxiv.1506.01497},
  issn      = {01628828},
  issue     = {6},
  keywords  = {Object detection,convolutional neural network,region proposal},
  pages     = {1137--1149},
  title     = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  volume    = {39},
}

@article{mason1981compliance,
  author = {Mason, Matthew T.},
  date   = {1981},
  doi    = {10.1109/TSMC.1981.4308708},
  number = {6},
  pages  = {418--432},
  title  = {Compliance and Force Control for Computer Controlled Manipulators},
  volume = {11},
}

@article{sacerdoti1974planning,
  author = {Sacerdoti, Earl D.},
  url    = {https://www.sciencedirect.com/science/article/pii/0004370274900265},
  date   = {1974},
  doi    = {https://doi.org/10.1016/0004-3702(74)90026-5},
  issn   = {0004-3702},
  number = {2},
  pages  = {115--135},
  title  = {Planning in a hierarchy of abstraction spaces},
  volume = {5},
}

@inproceedings{schulman2015computation,
  author    = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  eprint    = {1506.05254v3},
  title     = {{Gradient Estimation Using Stochastic Computation Graphs}},
}

@inproceedings{hart2010affordances,
  author    = {Hart, Stephen and Grupen, Roderic},
  booktitle = {IEEE Transactions on Autonomous Mental Development},
  date      = {2010},
  keywords  = {Generalization,Incremental Learning,Index Terms-Cognitive Architectures,Intrinsic Motivation,Reinforcement Learning,Schema},
  title     = {{Learning Generalizable Control Programs}},
}

@inproceedings{abel2014affordances,
  author    = {Abel, David and Barth-Maron, Gabriel and Macglashan, James and Tellex, Stefanie},
  url       = {https://vimeo.com/88689171},
  booktitle = {RSS Workshop on Affordances in Vision for Cognitive Robotics},
  date      = {2014},
  title     = {{Toward Affordance-Aware Planning}},
}

@inproceedings{chentanez2005intrinsically,
  author    = {Chentanez, Nuttapong and Barto, Andrew G and Singh, Satinder P},
  booktitle = {Advances in neural information processing systems},
  date      = {2005},
  pages     = {1281--1288},
  title     = {Intrinsically motivated reinforcement learning},
}

@inproceedings{lopes2012exploration,
  author    = {Lopes, Manuel and Lang, Tobias and Toussaint, Marc and Oudeyer, Pierre-Yves},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2012},
  pages     = {206--214},
  title     = {Exploration in model-based reinforcement learning by empirically estimating learning progress},
}

@misc{coumans2021,
  author       = {Coumans, Erwin and Bai, Yunfei},
  date         = {2016--2021},
  howpublished = {\url{http://pybullet.org}},
  title        = {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
}

@inproceedings{robosuite2020,
  author    = {Zhu, Yuke and Wong, Josiah and Mandlekar, Ajay and Martn-Martn, Roberto},
  booktitle = {arXiv preprint arXiv:2009.12293},
  date      = {2020},
  title     = {robosuite: A Modular Simulation Framework and Benchmark for Robot Learning},
}

@inproceedings{khetarpal2020affordances,
  author    = {Khetarpal, Khimya and Ahmed, Zafarali and Comanici, Gheorghe and Abel, David and Precup, Doina},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2020},
  eprint    = {2006.15085v1},
  title     = {{What can I do here? A Theory of Affordances in Reinforcement Learning}},
}

@article{min2016affordances,
  author = {Min, Huaqing and Yi, An and Luo, Ronghua and Zhu, Jinhui and Bi, Sheng},
  url    = {http://www.ieee.org/publications{\_}standards/publications/rights/index.html},
  date   = {2016},
  doi    = {10.1109/TCDS.2016.2614992},
  number = {4},
  title  = {{Affordance Research in Developmental Robotics: A Survey}},
  volume = {8},
}

@article{yamanobe2018affordances,
  author = {Yamanobe, Natsuki and Wan, Weiwei and Ramirez-Alpizar, Ixchel G. and Petit, Damien and Tsuji, Tokuo and Akizuki, Shuichi and Hashimoto, Manabu and Nagata, Kazuyuki and Harada, Kensuke},
  date   = {2018-01},
  doi    = {10.7210/jrsj.36.327},
  pages  = {327--337},
  title  = {A Brief Review of Affordance in Robotic Manipulation Research},
  volume = {36},
}

@article{zech2017affordances,
  author = {Zech, Philipp and Haller, Simon and Lakani, Safoura Rezapour and Ridge, Barry and Ugur, Emre and Piater, Justus},
  url    = {https://doi.org/10.1177/1059712317726357},
  date   = {2017},
  doi    = {10.1177/1059712317726357},
  eprint = {https://doi.org/10.1177/1059712317726357},
  number = {5},
  pages  = {235--271},
  title  = {Computational models of affordance in robotics: a taxonomy and systematic classification},
  volume = {25},
}

@techreport{hassanin2018affordances,
  author   = {Hassanin, Mohammed and Khan, Salman and Tahtali, Murat},
  date     = {2018},
  eprint   = {1807.06775v1},
  keywords = {Index Terms-affordance prediction,deep learning,functional scene understanding,object detection !},
  number   = {1},
  title    = {{Visual Affordance and Function Understanding: A Survey}},
  volume   = {6},
}

@inproceedings{xu2021affordances,
  author    = {Xu, Danfei and Mandlekar, Ajay and Martn-Martn, Roberto and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
  url       = {https://sites.google.com/stanford.edu/daf},
  booktitle = {International Conference on Robotics and Automation (ICRA)},
  date      = {2021},
  eprint    = {2011.08424v1},
  title     = {{Deep Affordance Foresight: Planning Through What Can Be Done in the Future}},
}

@techreport{colas2021gepsurvey,
  author = {Colas, Cdric and Karch, Tristan and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  date   = {2021},
  eprint = {2012.09830v2},
  title  = {{Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey}},
}

@article{Nair2019,
  author   = {Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  url      = {http://arxiv.org/abs/1910.11670},
  date     = {2019-10},
  eprint   = {1910.11670},
  keywords = {Deep Reinforcement Learning,Robotics,Self-Supervision},
  title    = {{Contextual Imagined Goals for Self-Supervised Robotic Learning}},
}

@inproceedings{rakelly2019pearl,
  author    = {Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey},
  url       = {https://github.com/katerakelly/oyster.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2019},
  title     = {{Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables}},
}

@inproceedings{nair2019ccrig,
  author    = {Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  url       = {http://arxiv.org/abs/1910.11670},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-10},
  eprint    = {1910.11670},
  keywords  = {Deep Reinforcement Learning,Robotics,Self-Supervision},
  title     = {{Contextual Imagined Goals for Self-Supervised Robotic Learning}},
}

@inproceedings{yu2019pcgrad,
  author = {Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  date   = {2019},
  eprint = {2001.06782v2},
  title  = {{Gradient Surgery for Multi-Task Learning}},
}

@techreport{kidambi2020morel,
  author = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  eprint = {2005.05951v1},
  title  = {{MOReL : Model-Based Offline Reinforcement Learning}},
}

@techreport{Kumar,
  author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  eprint = {2006.04779v1},
  title  = {{Conservative Q-Learning for Offline Reinforcement Learning}},
}

@techreport{Rajeswarana,
  author = {Rajeswaran, Aravind and Mordatch, Igor and Kumar, Vikash},
  url    = {https://sites.google.com/view/mbrl-game.},
  eprint = {2004.07804v1},
  title  = {{A Game Theoretic Framework for Model Based Reinforcement Learning}},
}

@techreport{Grill,
  author = {Grill, Jean-Bastien and Strub, Florian and Altch, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, Rmi and Valko, Michal},
  eprint = {2006.07733v1},
  title  = {{Bootstrap Your Own Latent A New Approach to Self-Supervised Learning}},
}

@techreport{Sutton,
  author = {Sutton, Richard S and Mcallester, David and Singh, Satinder and Mansour, Yishay},
  title  = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},
}

@techreport{Ghosh,
  author = {Ghosh, Dibya and Machado, Marlos C and {Le Roux}, Nicolas},
  eprint = {2006.11266v2},
  title  = {{An operator view of policy gradient methods}},
}

@techreport{Tang,
  author = {Tang, Yunhao and Kucukelbir, Alp},
  eprint = {2006.07549v1},
  title  = {{Hindsight Expectation Maximization for Goal-conditioned Reinforcement Learning}},
}

@inproceedings{jiang2016doublyrobust,
  author    = {Jiang, Nan and Li, Lihong},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  eprint    = {1511.03722v3},
  title     = {{Doubly Robust Off-policy Value Evaluation for Reinforcement Learning}},
}

@inproceedings{hallak2015offpolicy,
  author    = {Hallak, Assaf and Schnitzler, Francois and Mann, Timothy and Mannor, Shie},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2015},
  title     = {{Off-policy Model-based Learning under Unknown Factored Dynamics}},
}

@inproceedings{hallak2016td,
  author    = {Hallak, Assaf and Tamar, Aviv and Munos, Rmi and Mannor, Shie},
  booktitle = {Association for the Advancement of Artificial Intelligence (AAAI)},
  date      = {2016},
  eprint    = {1509.05172v2},
  keywords  = {()},
  title     = {{Generalized Emphatic Temporal Difference Learning: Bias-Variance Analysis}},
}

@inproceedings{hallak2017onlineoffpolicy,
  author    = {Hallak, Assaf and Mannor, Shie},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  eprint    = {1702.07121v1},
  title     = {{Consistent On-Line Off-Policy Evaluation}},
}

@techreport{levine2020offlinetutorial,
  author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  eprint = {2005.01643v1},
  title  = {{Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems}},
  date      = {2020},
}

@techreport{Munos2016,
  author = {Munos, Rmi and Deepmind, Google and Stepleton, Thomas and Harutyunyan, Anna and Bellemare, Marc G},
  date   = {2016},
  eprint = {1606.02647v2},
  title  = {{Safe and efficient off-policy reinforcement learning}},
}

@article{ramapuram2017lifelonggm,
  author    = {Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  publisher = {Elsevier BV},
  url       = {http://arxiv.org/abs/1705.09847},
  date      = {2017-05},
  eprint    = {1705.09847},
  title     = {{Lifelong Generative Modeling}},
}

@techreport{Foerster2018,
  author = {Foerster, Jakob and Farquhar, Gregory and Al-Shedivat, Maruan and Rocktschel, Tim and Xing, Eric P and Whiteson, Shimon},
  date   = {2018},
  eprint = {1802.05098v3},
  title  = {{DiCE: The Infinitely Differentiable Monte Carlo Estimator}},
}

@techreport{Wirth,
  author = {Wirth, Christian and Neumann, Gerhard},
  url    = {http://homepages.inf.ed.ac.uk/imurray2/pub/10ess/},
  title  = {{Model-Free Preference-based Reinforcement Learning}},
}

@techreport{Wang,
  author = {Wang, Qing and Xiong, Jiechao and Han, Lei and Sun, Peng and Liu, Han and Zhang, Tong},
  title  = {{Exponentially Weighted Imitation Learning for Batched Historical Data}},
}

@inproceedings{schaal97lfd,
  author    = {Schaal, Stefan},
  url       = {http://www.cc.gatech.edulfac http://wwwiaim.ira.uka.de/users/rogalla/WebOrdnerMaterial/ml-robotlearning.pdf http://www.cc.gatech.edulfac/Stefan.Schaal},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {1997},
  doi       = {10.1016/j.robot.2004.03.001},
  isbn      = {1558604863},
  issn      = {1049-5258},
  keywords  = {2-2 Hikaridai,619-02 Kyoto,801 Atlantic Drive,Atlanta,GA 30332-0280 ATR Human Information Processing,Georgia Tech,Seiko-cho,Soraku-gun,http://wwwccgatechedulfac/StefanSchaal College of},
  number    = {9},
  pages     = {1040--1046},
  title     = {{Learning from demonstration}},
}

@inproceedings{atkeson1997lfd,
  author    = {Atkeson, Christopher G and Schaal, Stefan},
  url       = {http://www.cc.gatech.edu/fac/fChris.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {1997},
  title     = {{Robot Learning From Demonstration}},
}

@techreport{Schroecker,
  author = {Schroecker, Yannick and Isbell, Charles},
  eprint = {2002.06473v1},
  title  = {{Universal Value Density Estimation for Imitation Learning and Goal-Conditioned Reinforcement Learning}},
}

@inproceedings{devlin2019bert,
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  url       = {http://arxiv.org/abs/1810.04805},
  booktitle = {Association for Compuational Linguistics (ACL)},
  date      = {2019-10},
  eprint    = {1810.04805},
  title     = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
}

@techreport{Dempster1977,
  author    = {Dempster, A P and Laird, ; N M and Rubin, ; D B},
  booktitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  date      = {1977},
  number    = {1},
  pages     = {1--38},
  title     = {{Maximum Likelihood from Incomplete Data via the EM Algorithm}},
  volume    = {39},
}

@techreport{Dayan1996,
  author = {Dayan, Peter and Hinton, Geoffrey E},
  date   = {1996},
  title  = {{Using EM for Reinforcement Learning}},
}

@techreport{Nachum,
  author = {Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Brain, Google},
  url    = {https://github.com/tensorflow/models/tree/},
  eprint = {1702.08892v3},
  title  = {{Bridging the Gap Between Value and Policy Based Reinforcement Learning}},
}

@techreport{Nachum2018,
  author = {Nachum, Ofir and Norouzi, Mohammad and Tucker, George and Schuurmans, Dale},
  date   = {2018},
  eprint = {1803.02348v3},
  title  = {{Smoothed Action Value Functions for Learning Gaussian Policies}},
}

@techreport{Lee,
  author = {Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  url    = {https://sites.google.com/},
  eprint = {1906.05274v3},
  isbn   = {1906.05274v3},
  title  = {{Efficient Exploration via State Marginal Matching}},
}

@inproceedings{ding2019gcil,
  author    = {Ding, Yiming and Florensa, Carlos and Phielipp, Mariano and Abbeel, Pieter},
  url       = {https://sites.google.com/view/goalconditioned-il/},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2019},
  title     = {{Goal-conditioned Imitation Learning}},
}

@inproceedings{zhang2020gendice,
  author    = {Zhang, Ruiyi and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  url       = {http://arxiv.org/abs/2002.09072},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2020-02},
  eprint    = {2002.09072},
  title     = {{GenDICE: Generalized Offline Estimation of Stationary Values}},
}

@inproceedings{wu2019brac,
  author    = {Wu, Yifan and Tucker, George and Nachum, Ofir},
  url       = {http://arxiv.org/abs/1911.11361},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2020-11},
  eprint    = {1911.11361},
  title     = {{Behavior Regularized Offline Reinforcement Learning}},
}

@inproceedings{nachum2019dualdice,
  author    = {Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  url       = {http://arxiv.org/abs/1906.04733},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2019-06},
  eprint    = {1906.04733},
  title     = {{DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections}},
}

@inproceedings{degris2012,
  author    = {Degris, Thomas and White, Martha and Sutton, Richard S.},
  url       = {http://arxiv.org/abs/1205.4839},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2012-05},
  eprint    = {1205.4839},
  keywords  = {3D printing,biped locomotion,humanoid robotics,morphological computation,physical human-robot interaction},
  title     = {{Off-Policy Actor-Critic}},
}

@techreport{Zhu,
  author = {Zhu, Yuke and Gordon, Daniel and Kolve, Eric and Fox, Dieter and Fei-Fei, Li and Gupta, Abhinav and Mottaghi, Roozbeh and Farhadi, Ali},
  eprint = {1705.08080v2},
  title  = {{Visual Semantic Planning using Deep Successor Representations}},
}

@article{Burda2015,
  author    = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
  publisher = {International Conference on Learning Representations, ICLR},
  url       = {http://arxiv.org/abs/1509.00519},
  date      = {2015-09},
  eprint    = {1509.00519},
  title     = {{Importance Weighted Autoencoders}},
}

@inproceedings{Hershey,
  author = {Hershey, John R and Olsen, Peder A},
  title  = {{APPROXIMATING THE KULLBACK LEIBLER DIVERGENCE BETWEEN GAUSSIAN MIXTURE MODELS}},
}

@techreport{levine2018tutorial,
  author = {Levine, Sergey},
  date   = {2018},
  eprint = {1805.00909v3},
  title  = {{Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}},
}

@techreport{degrave2019quinoa,
  author = {Degrave, Jonas and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Heess, Nicolas and Riedmiller, Martin},
  eprint = {1911.01831v1},
  pages  = {2018--2030},
  title  = {{Quinoa: a Q-function You Infer Normalized Over Actions}},
}

@inproceedings{gu2017qp,
  author    = {Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  eprint    = {1611.02247v3},
  title     = {{Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic}},
}

@inproceedings{zhu2017cyclegan,
  author    = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A and Research, Berkeley Ai},
  booktitle = {International Conference on Computer Vision (ICCV)},
  date      = {2017},
  eprint    = {1703.10593v6},
  title     = {{Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks Monet Photos}},
}

@inproceedings{eysenbach2020rewriting,
  author = {Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan and Berkeley, U C and Brain, Google},
  eprint = {2002.11089v1},
  isbn   = {2002.11089v1},
  title  = {{Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement}},
}

@inproceedings{smith2020avid,
  author = {Smith, Laura and Dhawan, Nikita and Zhang, Marvin and Abbeel, Pieter and Levine, Sergey},
  url    = {https://sites.google.com/view/icra20avid},
  eprint = {1912.04443v1},
  title  = {{AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human Videos}},
}

@inproceedings{siegel2020keepdoing,
  author    = {Siegel, Noah Y. and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  url       = {http://arxiv.org/abs/2002.08396},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2020-02},
  eprint    = {2002.08396},
  title     = {{Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning}},
}

@inproceedings{zhu2019hands,
  author    = {Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  url       = {http://arxiv.org/abs/1810.06045},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2019-10},
  eprint    = {1810.06045},
  pages     = {3651--3657},
  title     = {{Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost}},
  volume    = {2019-May},
}

@inproceedings{neumann2008fqiawr,
  author    = {Neumann, Gerhard and Peters, Jan},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2008},
  title     = {{Fitted Q-iteration by Advantage Weighted Regression}},
}

@inproceedings{gupta2019relay,
  author    = {Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  url       = {http://arxiv.org/abs/1910.11956},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-10},
  eprint    = {1910.11956},
  title     = {{Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning}},
}

@article{fu2020d4rl,
  author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  url    = {http://arxiv.org/abs/2004.07219},
  date   = {2020-04},
  eprint = {2004.07219},
  title  = {{D4RL: Datasets for Deep Data-Driven Reinforcement Learning}},
}

@inproceedings{konda2000actorcritic,
  author    = {Konda, Vijay R and Tsitsiklis, John N},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2000},
  title     = {{Actor-Critic Algorithms}},
}

@inproceedings{chebotar2019simtoreal,
  author    = {Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  url       = {https://arxiv.org/pdf/1810.05687.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2019},
  eprint    = {1810.05687v4},
  title     = {{Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience}},
}

@article{ke2019fdivergence,
  author = {Ke, Liyiming and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Choudhury, Sanjiban and Srinivasa, Siddhartha},
  url    = {http://arxiv.org/abs/1905.12888},
  date   = {2019-05},
  eprint = {1905.12888},
  title  = {{Imitation Learning as {\$}f{\$}-Divergence Minimization}},
}

@techreport{Gordon1995,
  author      = {Gordon, Geoffrey},
  institution = {Carnegie Mellon University},
  date        = {1995},
  title       = {{Stable Function Approximation in Dynamic Programming}},
}

@article{James2018,
  author    = {James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  publisher = {IEEE Computer Society},
  url       = {http://arxiv.org/abs/1812.07252},
  date      = {2018-12},
  eprint    = {1812.07252},
  keywords  = {Deep Learning,Robotics + Driving},
  pages     = {12619--12629},
  title     = {{Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks}},
  volume    = {2019-June},
}

@inproceedings{mehta2019adr,
  author    = {Mehta, Bhairav and Diaz, Manfred and Golemo, Florian and Pal, Christopher J. and Paull, Liam},
  url       = {http://arxiv.org/abs/1904.04762},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-04},
  eprint    = {1904.04762},
  title     = {{Active Domain Randomization}},
}

@techreport{Arndt,
  author = {Arndt, Karol and Hazara, Murtaza and Ghadirzadeh, Ali and Kyrki, Ville},
  eprint = {1909.12906v1},
  title  = {{Meta Reinforcement Learning for Sim-to-real Domain Adaptation}},
}

@inproceedings{Song,
  author = {Song, Xingyou and Yang, Yuxiang and Choromanski, Krzysztof and Caluwaerts, Ken and Gao, Wenbo and Finn, Chelsea and Tan, Jie},
  url    = {http://g.co/},
  eprint = {2003.01239v1},
  title  = {{Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning}},
}

@inproceedings{bharadhwaj2019simtoreal,
  author    = {Bharadhwaj, Homanga and Wang, Zihan and Bengio, Yoshua and Paull, Liam},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2019-05},
  doi       = {10.1109/ICRA.2019.8794310},
  isbn      = {9781538660263},
  issn      = {10504729},
  pages     = {782--788},
  title     = {{A data-efficient framework for training and sim-to-real transfer of navigation policies}},
  volume    = {2019-May},
}

@article{openai2019cube,
  author = {OpenAI and Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and Schneider, Jonas and Tezak, Nikolas and Tworek, Jerry and Welinder, Peter and Weng, Lilian and Yuan, Qiming and Zaremba, Wojciech and Zhang, Lei},
  url    = {http://arxiv.org/abs/1910.07113},
  date   = {2019-10},
  eprint = {1910.07113},
  title  = {{Solving Rubik's Cube with a Robot Hand}},
}

@inproceedings{ramos2019bayessim,
  author    = {Ramos, Fabio and {Carvalhaes Possas}, Rafael and Fox, Dieter},
  url       = {https://github.com/rafaelpossas/bayes{\_}sim},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2019},
  eprint    = {1906.01728v1},
  title     = {{BayesSim: adaptive domain randomization via probabilistic inference for robotics simulators}},
}

@article{marvel2018insertionsearch,
  author = {Marvel, Jeremy A and Bostelman, Roger and Falco, Joe},
  date   = {2018},
  number = {1},
  pages  = {14},
  title  = {{Multi-Robot Assembly Strategies and Metrics}},
  volume = {51},
}

@article{schoettler2019insertion,
  author = {Schoettler, Gerrit and Nair, Ashvin and Luo, Jianlan and Bahl, Shikhar and {Aparicio Ojea}, Juan and Solowjow, Eugen and Levine, Sergey},
  date   = {2019},
  eprint = {1906.05841v2},
  title  = {{Deep Reinforcement Learning for Industrial Insertion Tasks with Visual Inputs and Natural Rewards}},
}

@inproceedings{rawlik2012rss,
  author    = {Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
  url       = {http://arxiv.org/abs/1009.3958},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2012},
  title     = {{On Stochastic Optimal Control and Reinforcement Learning by Approximate Inference}},
}

@article{williams1992reinforce,
  author = {Williams, Ronald J},
  date   = {1992},
  pages  = {229--256},
  title  = {{Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}},
}

@article{agarwal2018simplicity,
  author = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  eprint = {1907.04543v2},
  title  = {{Striving for Simplicity in Off-Policy Deep Reinforcement Learning}},
}

@inproceedings{dasari2019robonet,
  author    = {Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},
  url       = {http://arxiv.org/abs/1910.11215},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-10},
  eprint    = {1910.11215},
  title     = {{RoboNet: Large-Scale Multi-Robot Learning}},
}

@article{Torralba2008,
  author   = {Torralba, Antonio and Fergus, Rob and Freeman, William T.},
  date     = {2008},
  doi      = {10.1109/TPAMI.2008.128},
  issn     = {01628828},
  keywords = {Internet images,Large data sets,Nearest neighbor methods,Object recognition,Tiny images},
  number   = {11},
  pages    = {1958--1970},
  title    = {{80 million tiny images: A large data set for nonparametric object and scene recognition}},
  volume   = {30},
}

@inproceedings{andrychowicz2016metalearning,
  author    = {Andrychowicz, Marcin and Denil, Misha and Colmenarejo, Sergio Gmez and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and {De Freitas}, Nando},
  publisher = {Neural information processing systems foundation},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1606.04474},
  issn      = {10495258},
  pages     = {3988--3996},
  title     = {{Learning to learn by gradient descent by gradient descent}},
}

@article{duan2016rl2,
  author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L. and Sutskever, Ilya and Abbeel, Pieter},
  url    = {http://arxiv.org/abs/1611.02779},
  date   = {2016-11},
  eprint = {1611.02779},
  title  = {{RL{\$}{\^}2{\$}: Fast Reinforcement Learning via Slow Reinforcement Learning}},
}

@inproceedings{fujimoto19bcq,
  author    = {Fujimoto, Scott and Meger, David and Precup, Doina},
  url       = {http://arxiv.org/abs/1812.02900},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2019-12},
  eprint    = {1812.02900},
  title     = {{Off-Policy Deep Reinforcement Learning without Exploration}},
}

@article{oord2018cpc,
  author = {{van den Oord DeepMind}, Aaron and {Li DeepMind}, Yazhe and {Vinyals DeepMind}, Oriol and van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  url    = {http://arxiv.org/abs/1807.03748 https://arxiv.org/pdf/1807.03748.pdf},
  date   = {2018},
  eprint = {1807.03748},
  title  = {{Representation Learning with Contrastive Predictive Coding}},
}

@inproceedings{kumar19bear,
  author    = {Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  url       = {http://arxiv.org/abs/1906.00949},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2019-06},
  eprint    = {1906.00949},
  title     = {{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}},
}

@article{peng2019awr,
  author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  url    = {http://arxiv.org/abs/1910.00177},
  date   = {2019-09},
  eprint = {1910.00177},
  title  = {{Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning}},
}

@article{james2019rlbench,
  author = {James, Stephen and Ma, Zicong and Arrojo, David Rovick and Davison, Andrew J.},
  url    = {http://arxiv.org/abs/1909.12271},
  date   = {2019-09},
  eprint = {1909.12271},
  title  = {{RLBench: The Robot Learning Benchmark {\&} Learning Environment}},
}

@inproceedings{chhatpar2001insertion,
  author    = {Chhatpar, S. R. and {M.S. Branicky}},
  booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2001},
  title     = {{Search strategies for peg-in-hole assemblies with position uncertainty}},
}

@article{sermanet2018tcn,
  author = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  date   = {2018},
  doi    = {10.1109/ICRA.2018.8462891},
  eprint = {1704.06888},
  isbn   = {9781538630815},
  issn   = {10504729},
  pages  = {1134--1141},
  title  = {{Time-Contrastive Networks: Self-Supervised Learning from Video}},
}

@article{tobin2017domainrandomization,
  author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  date   = {2017},
  title  = {{Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World}},
}

@inproceedings{wortsman2019learntolearn,
  author    = {Wortsman, Mitchell and Ehsani, Kiana and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2019},
  title     = {{Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning}},
}

@inproceedings{chen19surrogate,
  author    = {Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2019},
  title     = {{Surrogate Objectives for Batch Policy Optimization in One-step Decision Making}},
}

@inproceedings{nachum2018hiro,
  author    = {Nachum, Ofir and Gu, Shane Shixiang and Lee, Honglak and Levine, Sergey},
  url       = {https://sites.google.com/view/efficient-hrl},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2018},
  eprint    = {arXiv:1805.08296v2},
  title     = {{Data-Efficient Hierarchical Reinforcement Learning}},
}

@inproceedings{zamir2018taskonomy,
  author    = {Zamir, Amir R and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
  url       = {http://taskonomy.vision/},
  booktitle = {Conference on Vision and Pattern Recognition (CVPR)},
  date      = {2018},
  eprint    = {1804.08328v1},
  title     = {{Taskonomy: Disentangling Task Transfer Learning}},
}

@inproceedings{sax2018midlevel,
  author    = {Sax, Alexander and Emi, Bradley and Zamir, Amir and Guibas, Leonidas and Savarese, Silvio and Malik, Jitendra},
  url       = {http://perceptual.actor/},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019},
  eprint    = {1812.11971v3},
  title     = {{Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies}},
}

@inproceedings{Johnsona,
  author    = {Johnson, Matthew James and Duvenaud, David and Wiltschko, Alexander B and Datta, Sandeep R and Adams, Ryan P},
  url       = {https://arxiv.org/pdf/1603.06277.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  eprint    = {1603.06277v5},
  title     = {{Composing graphical models with neural networks for structured representations and fast inference}},
}

@techreport{Rolnick2019,
  author = {Rolnick, David and Donti, Priya L and Kaack, Lynn H and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and Luccioni, Alexandra and Maharaj, Tegan and Sherwin, Evan D and Mukkavilli, S Karthik and Kording, Konrad P and Gomes, Carla and Ng, Andrew Y and Hassabis, Demis and Platt, John C and Creutzig, Felix and Chayes, Jennifer and Bengio, Yoshua},
  url    = {https://arxiv.org/pdf/1906.05433.pdf},
  date   = {2019},
  eprint = {1906.05433v1},
  title  = {{Tackling Climate Change with Machine Learning}},
  volume = {16},
}

@techreport{Jurgenson,
  author = {Jurgenson, Tom and Tamar, Aviv},
  url    = {https://arxiv.org/pdf/1906.05329.pdf},
  eprint = {1906.05329v1},
  title  = {{Sub-Goal Trees-a Framework for Goal-Directed Trajectory Prediction and Optimization}},
}

@article{Lin2019,
  author   = {Lin, Xingyu and {Singh Baweja}, Harjatin and Held, David},
  url      = {https://arxiv.org/pdf/1905.07866.pdf},
  date     = {2019},
  eprint   = {1905.07866v1},
  keywords = {lin2019rlwithoutstate},
  title    = {{Reinforcement Learning without Ground-Truth State}},
}

@inproceedings{sohn2015cvae,
  author    = {Sohn, Kihyuk and Yan, Xinchen and Lee, Honglak},
  url       = {https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  title     = {{Learning Structured Output Representation using Deep Conditional Generative Models}},
}

@article{hwangbo2019quadruped,
  author    = {Hwangbo, Jemin and Lee, Joonho and Dosovitskiy, Alexey and Bellicoso, Dario and Tsounis, Vassilios and Koltun, Vladlen and Hutter, Marco},
  publisher = {Science Robotics},
  url       = {http://robotics.sciencemag.org/lookup/doi/10.1126/scirobotics.aau5872},
  date      = {2019-01},
  doi       = {10.1126/scirobotics.aau5872},
  issn      = {2470-9476},
  number    = {26},
  pages     = {5872},
  title     = {{Learning agile and dynamic motor skills for legged robots}},
  volume    = {4},
}

@inproceedings{tan2018quadruped,
  author    = {Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent and Brain, Google and Deepmind, Google},
  url       = {https://arxiv.org/pdf/1804.10332.pdf},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2018},
  eprint    = {1804.10332v2},
  isbn      = {1804.10332v2},
  title     = {{Sim-to-Real: Learning Agile Locomotion For Quadruped Robots}},
}

@inproceedings{peng2018openai,
  author    = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  url       = {https://xbpeng.github.io/projects/SimToReal/2018{\_}SimToReal.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  isbn      = {9781538630815},
  keywords  = {Deep Learning in Robotics and Automation,Learning and Adaptive Systems,Robust/Adaptive Control of Robotic Systems},
  title     = {{Sim-to-Real Transfer of Robotic Control with Dynamics Randomization}},
}

@inproceedings{sadeghi2017simtoreal,
  author    = {Sadeghi, Fereshteh and Levine, Sergey},
  url       = {https://youtu.be/nXBWmzFrj5s},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2017},
  eprint    = {1611.04201v4},
  title     = {{CAD 2 RL: Real Single-Image Flight Without a Single Real Image}},
}

@inproceedings{zhou2019epi,
  author    = {Zhou, Wenxuan and Pinto, Lerrel and Gupta, Abhinav},
  url       = {https://openreview.net/pdf?id=ryl8-3AcFX},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  title     = {{Environment Probing Interaction Policies}},
}

@inproceedings{wadefarley2019discern,
  author    = {Warde-Farley, David and {Van De Wiele}, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Volodymyr, Mnih},
  url       = {https://arxiv.org/pdf/1811.11359.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  eprint    = {1811.11359v1},
  isbn      = {1811.11359v1},
  title     = {{Unsupervised Control Through Non-Parametric Discriminative Rewards}},
}

@inproceedings{fu2017ex2,
  author    = {Fu, Justin and Co-Reyes, John D and Levine, Sergey},
  url       = {https://papers.nips.cc/paper/6851-ex2-exploration-with-exemplar-models-for-deep-reinforcement-learning.pdf https://arxiv.org/pdf/1703.01260.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  title     = {{EX 2 : Exploration with Exemplar Models for Deep Reinforcement Learning}},
}

@inproceedings{pong2020skewfit,
  author    = {Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1903.03698.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2020},
  eprint    = {1903.03698v2},
  title     = {{Skew-Fit: State-Covering Self-Supervised Reinforcement Learning}},
}

@inproceedings{zhang2019solar,
  author    = {Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew J. and Levine, Sergey},
  url       = {http://arxiv.org/abs/1808.09105},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2019-08},
  eprint    = {1808.09105},
  title     = {{SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning}},
}

@inproceedings{fu2018vice,
  author    = {Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  url       = {http://arxiv.org/abs/1805.11686},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2018-05},
  eprint    = {1805.11686},
  title     = {{Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition}},
}

@misc{hessel2018rainbow,
  author    = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  url       = {www.aaai.org https://arxiv.org/pdf/1710.02298.pdf},
  booktitle = {Association for the Advancement of Artificial Intelligence (AAAI)},
  date      = {2018},
  eprint    = {1710.02298v1},
  isbn      = {1710.02298v1},
  title     = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
}

@inproceedings{singh2019raq,
  author    = {Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  url       = {http://arxiv.org/abs/1904.07854},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2019-04},
  eprint    = {1904.07854},
  title     = {{End-to-End Robotic Reinforcement Learning without Reward Engineering}},
}

@inproceedings{yu2019dpn,
  author    = {Yu, Tianhe and Shevchuk, Gleb and Sadigh, Dorsa and Finn, Chelsea},
  url       = {https://arxiv.org/pdf/1902.05542.pdf},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2019},
  eprint    = {1902.05542v1},
  title     = {{Unsupervised Visuomotor Control through Distributional Planning Networks}},
}

@book{Szepesvari2009a,
  author = {Szepesvri, Csaba},
  url    = {https://sites.ualberta.ca/{~}szepesva/papers/RLAlgsInMDPs.pdf},
  date   = {2009},
  title  = {{Algorithms for Reinforcement Learning}},
}

@inproceedings{vanhasselt2016doubledqn,
  author    = {{Van Hasselt}, Hado and Guez, Arthur and Silver, David},
  url       = {www.aaai.org},
  booktitle = {Association for the Advancement of Artificial Intelligence (AAAI)},
  date      = {2016},
  eprint    = {1509.06461v3},
  isbn      = {1509.06461v3},
  title     = {{Deep Reinforcement Learning with Double Q-learning}},
}

@inproceedings{johnson2000hedging,
  author    = {Johnson, Eric and Calise, Anthony},
  url       = {https://www.researchgate.net/publication/2492500{\_}Pseudo-Control{\_}Hedging{\_}A{\_}New{\_}Method{\_}For{\_}Adaptive{\_}Control},
  booktitle = {Advances in Navigation Guidance and Control Technology Workshop},
  date      = {2000},
  title     = {{Pseudo-Control Hedging: A New Method For Adaptive Control}},
}

@inproceedings{johannink18residualrl,
  author    = {Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and {Aparicio Ojea}, Juan and Solowjow, Eugen and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1812.03201.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2019},
  eprint    = {1812.03201v2},
  title     = {{Residual Reinforcement Learning for Robot Control}},
}

@inproceedings{li2014usbgelsight,
  author    = {Li, Rui and Platt, Robert and Yuan, Wenzhen and {Ten Pas}, Andreas and Roscup, Nathan and Srinivasan, Mandayam A and Adelson, Edward},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.448.7123{\&}rep=rep1{\&}type=pdf},
  booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2014},
  title     = {{Localization and Manipulation of Small Parts Using GelSight Tactile Sensing}},
}

@inproceedings{kalashnikov2018qtopt,
  author    = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and Levine, Sergey},
  url       = {https://goo.gl/ykQn6g.},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2018},
  eprint    = {1806.10293v3},
  title     = {{QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation}},
}

@inproceedings{nair2018rig,
  author    = {Nair, Ashvin and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  url       = {https://sites.google.com/site/},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2018},
  eprint    = {arXiv:1807.04742v1},
  title     = {{Visual Reinforcement Learning with Imagined Goals}},
}

@article{kroemer2010grasping,
  author = {Kroemer, Oliver and Detry, Renaud and Piater, Justus and Peters, Jan},
  url    = {https://orbi.uliege.be//bitstream/2268/60643/1/Kroemer-2010-RAS-author-postprint.pdf},
  date   = {2010},
  number = {9},
  pages  = {1105--1116},
  title  = {{Combining Active Learning and Reactive Control for Robot Grasping}},
  volume = {58},
}

@inproceedings{lee2018videoprediction,
  author = {Lee, Alex X and Zhang, Richard and Ebert, Frederik and Abbeel, Pieter and Finn, Chelsea and Levine, Sergey},
  url    = {https://alexlee-gk.github.io/video{\_}prediction},
  eprint = {1804.01523v1},
  title  = {{Stochastic Adversarial Video Prediction}},
}

@article{ebert2018journal,
  author = {Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  url    = {https://sites.google.com/view/visualforesight},
  eprint = {1812.00568v1},
  title  = {{Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control}},
}

@inproceedings{ebert2018retrying,
  author    = {Ebert, Frederik and Dasari, Sudeep and Lee, Alex X and Levine, Sergey and Finn, Chelsea},
  url       = {https://arxiv.org/pdf/1810.03043.pdf},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2018},
  eprint    = {1810.03043v1},
  title     = {{Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning}},
}

@inproceedings{he2016resnet,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  url       = {http://image-net.org/challenges/LSVRC/2015/},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2016},
  eprint    = {1512.03385v1},
  title     = {{Deep Residual Learning for Image Recognition}},
}

@inproceedings{srouji18structuredcontrolnets,
  author    = {Srouji, Mario and Zhang, Jian and Salakhutdinov, Ruslan},
  url       = {http://arxiv.org/abs/1802.08311},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  eprint    = {1802.08311},
  title     = {{Structured Control Nets for Deep Reinforcement Learning}},
}

@article{silver18residualpolicylearning,
  author = {Silver, Tom and Allen, Kelsey and Tenenbaum, Josh and Kaelbling, Leslie},
  url    = {http://arxiv.org/abs/1812.06298},
  date   = {2018},
  eprint = {1812.06298},
  title  = {{Residual Policy Learning}},
}

@misc{Valtonen2006,
  author    = {Liu, Cixin},
  booktitle = {The Three-Body Problem},
  date      = {2006},
  doi       = {10.1017/CBO9780511616006},
  eprint    = {1508.02312},
  isbn      = {9780511616006},
  issn      = {21643725},
  pages     = {1--345},
  title     = {{The three-body problem}},
}

@misc{ArundhatiRoy1997,
  author = {{Arundhati Roy} and "Roy, Arundhati"},
  date   = {1997},
  isbn   = {679457313},
  issn   = {01400460},
  title  = {{God of Small Things}},
}

@misc{LaFollette2015,
  author    = {Haidt, Jonathan},
  url       = {http://www.tandfonline.com/doi/abs/10.1080/09515089.2013.838752},
  booktitle = {Philosophical Psychology},
  date      = {2015},
  doi       = {10.1080/03057240.2012.723940},
  eprint    = {arXiv:1011.1669v3},
  isbn      = {978-0307377906},
  issn      = {0305-7240},
  number    = {3},
  pages     = {452--465},
  title     = {{The Righteous Mind: Why Good People Are Divided by Politics and Religion}},
  volume    = {28},
}

@misc{Harari2015,
  author    = {Harari, Yuval Noah},
  booktitle = {An Animal of No Significance},
  date      = {2015},
  doi       = {10.1017/CBO9781107415324.004},
  eprint    = {arXiv:1011.1669v3},
  isbn      = {9788578110796},
  issn      = {1098-6596},
  pages     = {1--9},
  title     = {{Sapiens - A Brief History of Humankind}},
}

@inproceedings{chua18probabilisticdynamics,
  author    = {Chua, Kurtland and Calandra, Roberto and Mcallister, Rowan and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1805.12114.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2018},
  eprint    = {1805.12114v1},
  title     = {{Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}},
}

@techreport{Shyam,
  author = {Shyam, Pranav and Jaskowski, Wojciech and Gomez, Faustino},
  url    = {https://arxiv.org/pdf/1810.12162.pdf},
  eprint = {1810.12162v1},
  title  = {{Model-Based Active Exploration}},
}

@techreport{Nickel,
  author = {Nickel, Maximilian and Kiela, Douwe},
  url    = {https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations.pdf},
  title  = {{Poincar Embeddings for Learning Hierarchical Representations}},
}

@inproceedings{colas2019curious,
  author    = {Colas, Cdric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  url       = {https://arxiv.org/pdf/1810.06284.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2019},
  eprint    = {1810.06284v1},
  title     = {{CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning}},
}

@book{goodfellow2016deeplearningbook,
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  url    = {http://goodfeli.github.io/dlbook/{\%}0Ahttp://dx.doi.org/10.1038/nature14539},
  date   = {2016},
  doi    = {10.1038/nmeth.3707},
  eprint = {arXiv:1312.6184v5},
  isbn   = {978-0262035613},
  issn   = {0028-0836},
  number = {7553},
  pages  = {800},
  title  = {{Deep Learning}},
  volume = {521},
}

@inproceedings{kahn2018navigation,
  author    = {Kahn, Gregory and Villaflor, Adam and Ding, Bosen and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1709.10489.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  eprint    = {1709.10489v3},
  title     = {{Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation}},
}

@article{Ollowing2009,
  date  = {2009},
  pages = {1--12},
  title = {{FROM LANGUAGE TO GOALS: INVERSE REINFORCE- MENT LEARNING FOR VISION-BASED INSTRUCTION FOLLOWING}},
}

@article{Qa2007,
  date   = {2007},
  pages  = {1--8},
  title  = {{CURIOSITY-DRIVEN EXPERIENCE PRIORITIZATION VIA DENSITY ESTIMATION}},
  volume = {33},
}

@article{Pere2018a,
  date     = {2018},
  eprint   = {arXiv:1803.00781v2},
  keywords = {autonomous goal setting,deep neural network,diversity,exploration,learning,unsupervised},
  pages    = {1--26},
  title    = {{LEARNING TO UNDERSTAND GOAL SPECIFICATIONS BY MODELLING REWARD}},
}

@inproceedings{hausman2018skillembedding,
  author    = {Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  pages     = {1--16},
  title     = {{Learning an Embedding Space for Transferable Robot Skills}},
}

@article{chawla2002smote,
  author = {Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  url    = {https://arxiv.org/pdf/1106.1813.pdf},
  date   = {2002},
  pages  = {321--357},
  title  = {{SMOTE: Synthetic Minority Over-sampling Technique}},
  volume = {16},
}

@inproceedings{eysenbach18diayn,
  author    = {Eysenbach, Benjamin and Brain, Google and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  url       = {https://sites.google.com/view/diayn/},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  eprint    = {arXiv:1802.06070v5},
  title     = {{Diversity is All You Need: Learning Skills without a Reward Function}},
}

@inproceedings{gupta18structuredexploration,
  author    = {Gupta, Abhishek and Mendonca, Russell and Liu, Yuxuan and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1802.07245.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2018},
  eprint    = {arXiv:1802.07245v1},
  title     = {{Meta-Reinforcement Learning of Structured Exploration Strategies}},
}

@inproceedings{tang2017hashtag,
  author    = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, Xi and Duan, Yan and Schulman, John and {De Turck}, Filip and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1611.04717.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  eprint    = {arXiv:1611.04717v3},
  title     = {{{\#}Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning}},
}

@inproceedings{rezende2014stochasticbackprop,
  author    = {Rezende, Danilo J and Mohamed, Shakir and Wierstra, Daan},
  url       = {https://arxiv.org/pdf/1401.4082.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2014},
  eprint    = {arXiv:1401.4082v3},
  title     = {{Stochastic Backpropagation and Approximate Inference in Deep Generative Models}},
}

@inproceedings{Oh2017,
  author    = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
  url       = {https://arxiv.org/pdf/1706.05064.pdf https://sites.google.com/a/umich.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  eprint    = {arXiv:1706.05064v2},
  title     = {{Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning}},
}

@article{Tang2016,
  author = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, Xi and Duan, Yan and Schulman, John and {De Turck}, Filip and Abbeel, Pieter},
  url    = {http://arxiv.org/abs/1611.04717},
  date   = {2016-11},
  eprint = {1611.04717},
  title  = {{{\#}Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning}},
}

@inproceedings{giusti15trails,
  author    = {Giusti, Alessandro and Guzzi, Jrme Jerome and Cirean, Dan C and He, Fang-Lin and Rodrguez, Juan P and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, Jrgen Jurgen and Caro, Gianni Di and Scaramuzza, Davide and Gambardella, Luca M and Ciresan, Dan C. and He, Fang-Lin and Rodriguez, Juan P. and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, Jrgen Jurgen and Caro, Gianni Di and Scaramuzza, Davide and Gambardella, Luca M},
  url       = {http://bit.ly/perceivingtrails. http://ieeexplore.ieee.org/document/7358076/},
  booktitle = {IEEE Robotics and Automation Letters (RAL)},
  date      = {2015},
  doi       = {10.1109/LRA.2015.2509024},
  isbn      = {9781467380256},
  issn      = {2377-3766},
  keywords  = {Aerial Robotics,Deep Learning,Index TermsVisual-Based Navigation,Ma-chine Learning},
  number    = {2},
  pages     = {2377--3766},
  title     = {{A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots}},
  volume    = {1},
}

@inproceedings{haarnoja2018sac,
  author    = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1801.01290.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  eprint    = {arXiv:1801.01290v2},
  title     = {{Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}},
}

@article{wang2018differentiablepogramming,
  author = {Wang, Fei and Decker, James},
  url    = {http://colah.github.io/posts/2015-09-NN-Types-FP/},
  date   = {2018},
  eprint = {arXiv:1803.10228v1},
  title  = {{Demystifying Differentiable Programming: Shift/Reset the Penultimate Backpropagator}},
}

@inproceedings{loftin2014discretehumanfeedback,
  author    = {Loftin, Robert and Macglashan, James and Peng, Bei and Taylor, Matthew E and Littman, Michael L and Huang, Jeff and Roberts, David L},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2014},
  isbn      = {9781577356783},
  keywords  = {Humans and AI},
  pages     = {937--943},
  title     = {{A Strategy-Aware Technique for Learning Behaviors from Discrete Human Feedback}},
}

@inproceedings{saunders2018trialwithouterror,
  author    = {Saunders, William and Sastry, Girish and Stuhlmller, Andreas and Evans, Owain},
  url       = {https://arxiv.org/pdf/1707.05173.pdf},
  booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  date      = {2018},
  eprint    = {arXiv:1707.05173v1},
  title     = {{Trial without Error: Towards Safe Reinforcement Learning via Human Intervention}},
}

@inproceedings{torrey2013teachingbudget,
  author    = {Torrey, Lisa and Taylor, Matthew E},
  url       = {www.ifaamas.org},
  booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  date      = {2013},
  title     = {{Teaching on a Budget: Agents Advising Agents in Reinforcement Learning}},
}

@inproceedings{subramanian2016efd,
  author    = {Subramanian, Kaushik and Isbell, Charles L and Thomaz, Andrea L},
  url       = {www.ifaamas.org},
  booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  date      = {2016},
  title     = {{Exploration from Demonstration for Interactive Reinforcement Learning}},
}

@inproceedings{frank2008rareevents,
  author    = {Frank, Jordan and Mannor, Shie and Precup, Doina},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.4737{\&}rep=rep1{\&}type=pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2008},
  title     = {{Reinforcement Learning in the Presence of Rare Events}},
}

@inproceedings{daniel2014activereward,
  author    = {Daniel, Christian and Viering, Malte and Metz, Jan and Kroemer, Oliver and Peters, Jan},
  url       = {http://www.roboticsproceedings.org/rss10/p31.pdf},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2014},
  title     = {{Active Reward Learning}},
}

@techreport{Fu,
  author = {Fu, Justin and Luo, Katie and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1710.11248.pdf},
  eprint = {arXiv:1710.11248v2},
  title  = {{LEARNING ROBUST REWARDS WITH ADVERSARIAL INVERSE REINFORCEMENT LEARNING}},
}

@book{Keener2006,
  author    = {Keener, Robert W.},
  url       = {http://books.google.com/books?id=9tv0taI8l6YC},
  booktitle = {Design},
  date      = {2006},
  doi       = {10.1016/j.peva.2007.06.006},
  eprint    = {arXiv:1011.1669v3},
  isbn      = {9780387781884},
  issn      = {01621459},
  pages     = {618},
  title     = {{Theoretical Statistics}},
  volume    = {102},
}

@inproceedings{Grant2018,
  author    = {Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
  url       = {https://arxiv.org/pdf/1801.08930.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  eprint    = {arXiv:1801.08930v1},
  title     = {{Recasting Gradient-Based Meta-Learning As Hierarchical Bayes}},
}

@inproceedings{andreas2018latentlanguage,
  author    = {Andreas, Jacob and Klein, Dan and Levine, Sergey},
  url       = {http://github.com/},
  booktitle = {North American Chapter of the Association for Computational Linguistics (NAACL)},
  date      = {2018},
  eprint    = {arXiv:1711.00482v1},
  title     = {{Learning with Latent Language}},
}

@phdthesis{Duvallet2015,
  author = {Duvallet, Felix},
  url    = {https://felixduvallet.github.io/pubs/dissertation-felixd.pdf},
  date   = {2015},
  title  = {{Natural Language Direction Following for Robots in Unstructured Unknown Environments}},
}

@inproceedings{Belousov2016,
  author    = {Belousov, Boris and Neumann, Gerhard and Rothkopf, Constantin A and Peters, Jan},
  url       = {https://www.ias.informatik.tu-darmstadt.de/uploads/Site/EditPublication/Belousov{\_}ANIPS{\_}2016.pdf},
  booktitle = {Neural Information Processing Systems (NIPS)},
  date      = {2016},
  title     = {{Catching heuristics are optimal control policies}},
}

@inproceedings{Fish2018,
  author    = {Fish, Hsiao-Yu and Adam, Tung and Harley, W and Huang, Liang-Kang and Fragkiadaki, Katerina},
  url       = {https://arxiv.org/pdf/1804.10692.pdf},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2018},
  eprint    = {arXiv:1804.10692v1},
  title     = {{Reward Learning from Narrated Demonstrations}},
}

@inproceedings{Li2017,
  author    = {Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
  url       = {https://arxiv.org/pdf/1703.08840.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  title     = {{InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations}},
}

@inproceedings{Odonoghue2018,
  author    = {O'donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  url       = {https://arxiv.org/pdf/1709.05380.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  eprint    = {arXiv:1709.05380v3},
  title     = {{The Uncertainty Bellman Equation and Exploration}},
}

@inproceedings{Dinh2017a,
  author    = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  url       = {https://arxiv.org/pdf/1605.08803.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  eprint    = {arXiv:1605.08803v3},
  title     = {{Density Estimation Using Real NVP}},
}

@inproceedings{Dinh2015,
  author    = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  url       = {https://arxiv.org/pdf/1410.8516.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2015},
  eprint    = {arXiv:1410.8516v6},
  title     = {{NICE: Non-linear Independent Components Estimation}},
}

@article{Plappert2018,
  author = {Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and Mcgrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and Kumar, Vikash and Zaremba, Wojciech},
  url    = {http://fetchrobotics.com/},
  date   = {2018},
  eprint = {arXiv:1802.09464v2},
  title  = {{Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research}},
}

@inproceedings{lee2017servo,
  author    = {Lee, Alex and Levine, Sergey and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1703.11000.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  title     = {{Learning Visual Servoing with Deep Features and Fitted Q-Iteration}},
}

@inproceedings{Srinivas2018,
  author    = {Srinivas, Aravind and Jabri, Allan and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  url       = {https://sites.google.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  eprint    = {arXiv:1804.00645v2},
  title     = {{Universal Planning Networks}},
}

@article{Baranes2012,
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  url    = {http://dx.doi.org/10.1016/j.robot.2012.05.008},
  date   = {2012},
  doi    = {10.1016/j.robot.2012.05.008},
  eprint = {arXiv:1301.4862v1},
  number = {1},
  pages  = {49--73},
  title  = {{Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots}},
  volume = {61},
}

@inproceedings{thomas2017independentlycontrollable,
  author    = {Thomas, Valentin and Pondard, Jules and Bengio, Emmanuel and Sarfati, Marc and Beaudoin, Philippe and Meurs, Marie-Jean and Pineau, Joelle and Precup, Doina and Bengio, Yoshua and Thoma, Valentin and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
  url       = {https://arxiv.org/pdf/1703.07718.pdf https://arxiv.org/pdf/1708.01289.pdf},
  booktitle = {NIPS Workshop},
  date      = {2017},
  keywords  = {controllable features Acknowledgements,representation learning},
  title     = {{Independently Controllable Factors}},
}

@inproceedings{Pere2018,
  author    = {Pr, Alexandre and Forestier, Sebastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  url       = {https://arxiv.org/pdf/1803.00781.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration}},
}

@article{Fernando,
  author = {Fernando, Chrisantha and Sygnowski, Jakub and Osindero, Simon and Wang, Jane and Schaul, Tom and Teplyashin, Denis and Sprechmann, Pablo and Pritzel, Alexander and Rusu, Andrei A},
  url    = {https://arxiv.org/pdf/1806.07917.pdf},
  title  = {{Meta-Learning by the Baldwin Effect}},
}

@inproceedings{Oh2018,
  author    = {Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  url       = {https://arxiv.org/pdf/1806.05635v1.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  title     = {{Self-Imitation Learning}},
}

@inproceedings{Dumoulin2017,
  author    = {Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Mastropietro, Olivier and Lamb, Alex and Arjovsky, Martin and Courville, Aaron},
  url       = {https://arxiv.org/pdf/1606.00704.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  title     = {{Adversarially Learned Inference}},
}

@inproceedings{thomas2018cad,
  author    = {Thomas, Garrett and Chien, Melissa and Tamar, Aviv and Ojea, Juan Aparicio and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1803.07635.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{Learning Robotic Assembly from CAD}},
}

@inproceedings{ng1999rewardshaping,
  author    = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart},
  url       = {https://www-cs.stanford.edu/people/ang/papers/shaping-icml99.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {1999},
  title     = {{Policy invariance under reward transformations: Theory and application to reward shaping}},
}

@inproceedings{rajeswaran2018dextrous,
  author    = {Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1709.10087.pdf},
  booktitle = {Robotics: Science and Systems},
  date      = {2018},
  title     = {{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}},
}

@inproceedings{agrawal2016poking,
  author    = {Agrawal, Pulkit and Nair, Ashvin and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  url       = {http://arxiv.org/abs/1606.07419},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1606.07419},
  issn      = {10495258},
  title     = {{Learning to Poke by Poking: Experiential Learning of Intuitive Physics}},
}

@inproceedings{lange2012autonomous,
  author       = {Lange, Sascha and Riedmiller, Martin and Voigtlander, Arne and Voigtlnder, Arne},
  organization = {IEEE},
  booktitle    = {International Joint Conference on Neural Networks (IJCNN)},
  date         = {2012},
  doi          = {10.1109/IJCNN.2012.6252823},
  isbn         = {9781467314909},
  issn         = {2161-4393},
  number       = {June},
  pages        = {1--8},
  title        = {{Autonomous reinforcement learning on raw visual input data in a real world application}},
}

@inproceedings{kingma2014vae,
  author    = {Kingma, Diederik P and Welling, Max},
  url       = {https://arxiv.org/pdf/1312.6114.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2014},
  title     = {{Auto-Encoding Variational Bayes}},
}

@article{levine2016gps,
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  publisher = {JMLR. org},
  url       = {https://arxiv.org/pdf/1504.00702.pdf},
  date      = {2016},
  doi       = {10.1007/s13398-014-0173-7.2},
  eprint    = {1504.00702},
  isbn      = {9781479969227},
  issn      = {15337928},
  keywords  = {Neural Networks,Optimal Control,Reinforcement Learning,Vision},
  number    = {1},
  pages     = {1334--1373},
  title     = {{End-to-End Training of Deep Visuomotor Policies}},
  volume    = {17},
}

@article{bojarski2016nvidia,
  author = {Bojarski, Mariusz and {Del Testa}, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol and Testa, Davide Del and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
  url    = {https://arxiv.org/pdf/1604.07316.pdf http://arxiv.org/abs/1604.07316},
  date   = {2016},
  eprint = {1604.07316},
  pages  = {1--9},
  title  = {{End to End Learning for Self-Driving Cars}},
  volume = {abs/1604.0},
}

@inproceedings{mnih2016asynchronous,
  author    = {Mnih, Volodymyr and {Puigdomnech Badia}, Adri and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P and Silver, David and Kavukcuoglu, Koray and Com, Korayk@google and Deepmind, Google},
  url       = {https://arxiv.org/pdf/1602.01783.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  title     = {{Asynchronous Methods for Deep Reinforcement Learning}},
}

@inproceedings{hester17dqfd,
  author    = {Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and Leibo, Joel Z and Gruslys, Audrunas},
  url       = {https://arxiv.org/pdf/1704.03732.pdf http://arxiv.org/abs/1704.03732},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2018},
  eprint    = {1704.03732},
  title     = {{Learning from Demonstrations for Real World Reinforcement Learning}},
}

@article{jordan1992forward,
  author    = {Jordan, Michael I and Rumelhart, David E and Mozer, Michael and Barto, Andrew and Jacobs, Robert and Loeb, Eric and Mcclelland, James},
  publisher = {Wiley Online Library},
  url       = {https://pdfs.semanticscholar.org/bea6/713f0bdd8069d734846fc532660c3152d027.pdf},
  date      = {1992},
  number    = {3},
  pages     = {307--354},
  title     = {{Forward models: Supervised learning with a distal teacher}},
  volume    = {16},
}

@inproceedings{torralba,
  author    = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2016},
  title     = {{Anticipating Visual Representations from Unlabeled Video}},
}

@inproceedings{nair2017icra,
  author    = {Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey and Chen, Dian and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2017},
  doi       = {10.1109/ICRA.2017.7989247},
  eprint    = {1703.02018},
  isbn      = {9781509046331},
  issn      = {10504729},
  title     = {{Combining Self-Supervised Learning and Imitation for Vision-Based Rope Manipulation}},
}

@inproceedings{andrychowicz2017her,
  author    = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and Mcgrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  url       = {https://arxiv.org/pdf/1707.01495.pdf http://arxiv.org/abs/1707.01495},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  eprint    = {1707.01495},
  title     = {{Hindsight Experience Replay}},
}

@inproceedings{ebert2017videoprediction,
  author    = {Ebert, Frederik and Finn, Chelsea and Lee, Alex X and Levine, Sergey},
  url       = {https://128.84.21.199/pdf/1710.05268.pdf https://arxiv.org/pdf/1710.05268.pdf},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2017},
  keywords  = {deep learning,manipulation,model-based rein-forcement learning,video prediction},
  title     = {{Self-Supervised Visual Planning with Temporal Skip Connections}},
}

@inproceedings{watter2015embed,
  author    = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
  url       = {https://arxiv.org/pdf/1506.07365.pdf http://arxiv.org/abs/1506.07365},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  eprint    = {1506.07365},
  issn      = {10495258},
  pages     = {2728--2736},
  title     = {{Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images}},
}

@inproceedings{lange2010deep,
  author       = {Lange, Sascha and Riedmiller, Martin A},
  organization = {Citeseer},
  url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.6898{\&}rep=rep1{\&}type=pdf},
  booktitle    = {European Symposium on Artificial Neural Networks (ESANN)},
  date         = {2010},
  title        = {{Deep learning of visual control policies.}},
}

@article{popov17stacking,
  author   = {Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin and Deepmind, Martin Riedmiller},
  url      = {https://arxiv.org/pdf/1704.03073.pdf},
  date     = {2017},
  eprint   = {1704.03073},
  keywords = {popov2017stacking},
  title    = {{Data-efficient Deep Reinforcement Learning for Dexterous Manipulation}},
  volume   = {abs/1704.0},
}

@inproceedings{rauber2017hindsight,
  author    = {Rauber, Paulo and Mutz, Filipe and Schmidhuber, Juergen Jrgen},
  url       = {https://arxiv.org/pdf/1711.06006.pdf},
  booktitle = {CoRR},
  date      = {2017},
  title     = {{Hindsight policy gradients}},
  volume    = {abs/1711.0},
}

@inproceedings{lillicrap2015continuous,
  author    = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  url       = {https://arxiv.org/pdf/1509.02971.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2016},
  doi       = {10.1613/jair.301},
  eprint    = {9605103},
  isbn      = {0-7803-3213-X},
  issn      = {10769757},
  title     = {{Continuous control with deep reinforcement learning}},
}

@inproceedings{kober2008mp,
  author    = {Kober, Jens and Peter, J.},
  url       = {http://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2008},
  doi       = {10.1007/978-3-319-03194-1_4},
  isbn      = {1099401052236},
  issn      = {1610742X},
  pages     = {83--117},
  title     = {{Policy search for motor primitives in robotics}},
  volume    = {97},
}

@inproceedings{deisenroth2011pilco,
  author    = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
  url       = {http://mlg.eng.cam.ac.uk/pub/pdf/DeiRas11.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2011},
  pages     = {465--472},
  title     = {{PILCO: A model-based and data-efficient approach to policy search}},
}

@inproceedings{gu2016naf,
  author    = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1603.00748.pdf http://arxiv.org/abs/1603.00748},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  doi       = {10.3390/robotics2030122},
  eprint    = {1603.00748},
  isbn      = {3405062780},
  issn      = {{<}null{>}},
  title     = {{Continuous Deep Q-Learning with Model-based Acceleration}},
}

@inproceedings{oh2015action,
  author    = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  url       = {https://arxiv.org/pdf/1507.08750v1.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  title     = {{Action-Conditional Video Prediction using Deep Networks in Atari Games}},
}

@article{henderson2017deep,
  author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  date   = {2017},
  title  = {{Deep reinforcement learning that matters}},
}

@inproceedings{inoue1985hand,
  author    = {Inoue, H and Inaba, M},
  booktitle = {Robotics Research: The First International Symposium},
  date      = {1985},
  title     = {{Hand-eye coordination in rope handling}},
  volume    = {1},
}

@book{winograd72shrdlr,
  author    = {Winograd, Terry},
  publisher = {Academic Press},
  date      = {1972},
  title     = {{Understanding Natural Language}},
}

@article{billiards,
  author = {Fragkiadaki, Katerina and Agrawal, Pulkit and Levine, Sergey and Malik, Jitendra},
  date   = {2016},
  title  = {{Learning Visual Predictive Models of Physics for Playing Billiards}},
}

@article{burgess2018understanding,
  author = {Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  date   = {2018},
  title  = {{Understanding disentangling in {\$}\beta{\$}-VAE}},
}

@article{machado2018eigenoption,
  author = {Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  date   = {2018},
  title  = {{Eigenoption Discovery through the Deep Successor Representation}},
}

@inproceedings{kopicki2011learning,
  author       = {Kopicki, Marek and Zurek, Sebastian and Stolkin, Rustam and Mrwald, Thomas and Wyatt, Jeremy},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2011},
  pages        = {5722--5729},
  title        = {{Learning to predict how rigid objects behave under simple manipulation}},
}

@article{kuniyoshi1994learning,
  author    = {Kuniyoshi, Yasuo and Inaba, Masayuki and Inoue, Hirochika},
  publisher = {IEEE},
  date      = {1994},
  number    = {6},
  pages     = {799--822},
  title     = {{Learning by watching: Extracting reusable task knowledge from visual observation of human performance}},
  volume    = {10},
}

@article{jaderberg2016auxiliary,
  author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  date   = {2017},
  title  = {{Reinforcement learning with unsupervised auxiliary tasks}},
}

@article{hansen2001completely,
  author    = {Hansen, Nikolaus and Ostermeier, Andreas},
  publisher = {MIT Press},
  date      = {2001},
  number    = {2},
  pages     = {159--195},
  title     = {{Completely derandomized self-adaptation in evolution strategies}},
  volume    = {9},
}

@article{pinto2016curious,
  author = {Pinto, Lerrel and Gandhi, Dhiraj and Han, Yuanfeng and Park, Yong-Lae and Gupta, Abhinav},
  date   = {2016},
  title  = {{The Curious Robot: Learning Visual Representations via Physical Interactions}},
}

@inproceedings{lau2011automatic,
  author       = {Lau, Manfred and Mitani, Jun and Igarashi, Takeo},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2011},
  pages        = {3733--3738},
  title        = {{Automatic learning of pushing strategy for delivery of irregular-shaped objects}},
}

@article{kingma2014adam,
  author = {Kingma, Diederik and Ba, Jimmy},
  date   = {2015},
  title  = {{Adam: A method for stochastic optimization}},
}

@article{ponomarenko2015image,
  author    = {Ponomarenko, Nikolay and Jin, Lina and Ieremeiev, Oleg and Lukin, Vladimir and Egiazarian, Karen and Astola, Jaakko and Vozel, Benoit and Chehdi, Kacem and Carli, Marco and Battisti, Federica and others},
  publisher = {Elsevier},
  date      = {2015},
  pages     = {57--77},
  title     = {{Image database TID2013: Peculiarities, results and perspectives}},
  volume    = {30},
}

@article{schmidhuber1992learning,
  author    = {Schmidhuber, Jrgen},
  publisher = {MIT Press},
  date      = {1992},
  number    = {6},
  pages     = {863--879},
  title     = {{Learning factorial codes by predictability minimization}},
  volume    = {4},
}

@inproceedings{abbeel2004apprenticeship,
  author    = {Abbeel, Pieter and Ng, Andrew Y},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2004},
  pages     = {1},
  title     = {{Apprenticeship learning via inverse reinforcement learning}},
}

@article{aksoy2011learning,
  author    = {Aksoy, Eren Erdal and Abramov, Alexey and Drr, Johannes and Ning, Kejun and Dellen, Babette and Wrgtter, Florentin},
  publisher = {Sage Publications},
  date      = {2011},
  pages     = {0278364911410459},
  title     = {{Learning the semantics of object--action relations by observation}},
}

@inproceedings{saha2006motion,
  author       = {Saha, Mitul and Isto, Pekka},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2006},
  pages        = {2478--2484},
  title        = {{Motion planning for robotic manipulation of deformable linear objects}},
}

@article{ha2018world,
  author = {Ha, David and Schmidhuber, Jrgen},
  date   = {2018},
  title  = {{World Models}},
}

@inproceedings{DBLP:conf/bmvc/KyriazisOA11,
  author    = {Kyriazis, Nikolaos and Oikonomidis, Iason and Argyros, Antonis A},
  url       = {http://dx.doi.org/10.5244/C.25.43},
  booktitle = {British Machine Vision Conference, {\{}BMVC{\}} 2011, Dundee, UK, August 29 - September 2, 2011. Proceedings},
  date      = {2011},
  doi       = {10.5244/C.25.43},
  pages     = {1--11},
  title     = {{Binding Computer Vision to Physics Based Simulation: The Case Study of a Bouncing Ball}},
}

@article{lee2013syntactic,
  author    = {Lee, Kyuhwa and Su, Yanyu and Kim, Tae-Kyun and Demiris, Yiannis},
  publisher = {Elsevier},
  date      = {2013},
  number    = {12},
  pages     = {1323--1334},
  title     = {{A syntactic approach to robot imitation learning using probabilistic activity grammars}},
  volume    = {61},
}

@inproceedings{katz2008manipulating,
  author       = {Katz, Dov and Brock, Oliver},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2008},
  pages        = {272--277},
  title        = {{Manipulating articulated objects with interactive perception}},
}

@article{florensa2017stochastic,
  author = {Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
  date   = {2017},
  title  = {{Stochastic neural networks for hierarchical reinforcement learning}},
}

@article{mccloskey1983intuitive,
  author = {McCloskey, Michael},
  date   = {1983},
  number = {4},
  pages  = {122--130},
  title  = {{Intuitive physics}},
  volume = {248},
}

@article{pinto2015supersizing,
  author = {Pinto, Lerrel and Gupta, Abhinav},
  date   = {2016},
  title  = {{Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours}},
}

@inproceedings{schulman2013warping,
  author    = {Schulman, John and Gupta, Ankush and Venkatesan, Sibi and Tayson-Frederick, Mallory and Abbeel, Pieter},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2013},
  title     = {{A Case Study of Trajectory Transfer Through Non-Rigid Registration for a Simplified Suturing Scenario}},
}

@article{mericcli2015push,
  author    = {Merili, Tekin and Veloso, Manuela and Ak$\backslash$in, H Levent},
  publisher = {Springer},
  date      = {2015},
  number    = {3},
  pages     = {317--329},
  title     = {{Push-manipulation of complex passive mobile objects using experimentally acquired motion models}},
  volume    = {38},
}

@inproceedings{kietzmann2009neuro,
  author       = {Kietzmann, Tim C and Riedmiller, Martin},
  organization = {IEEE},
  booktitle    = {International Conference on Machine Learning (ICML)},
  date         = {2009},
  pages        = {311--316},
  title        = {{The neuro slot car racer: Reinforcement learning in a real world setting}},
}

@inproceedings{chui2000tpsrpm,
  author    = {Chui, Haili and Rangarajan, Anand},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2000},
  title     = {{A new algorithm for non-rigid point matching}},
}

@inproceedings{todorov2003unsupervised,
  author       = {Todorov, Emanuel and Ghahramani, Zoubin},
  organization = {IEEE},
  booktitle    = {Engineering in Medicine and Biology Society, 2003. Proceedings of the 25th Annual International Conference of the IEEE},
  date         = {2003},
  pages        = {1750--1753},
  title        = {{Unsupervised learning of sensory-motor primitives}},
  volume       = {2},
}

@article{zhang2018unreasonable,
  author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  date   = {2018},
  title  = {{The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}},
}

@article{pinto2017asymmetric,
  author = {Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  date   = {2018},
  title  = {{Asymmetric Actor Critic for Image-Based Robot Learning}},
}

@article{desjardins2012disentangling,
  author = {Desjardins, Guillaume and Courville, Aaron and Bengio, Yoshua},
  date   = {2012},
  title  = {{Disentangling factors of variation via generative entangling}},
  volume = {abs/1210.5},
}

@book{crowell2012introduction,
  author    = {Crowell, Richard H and Fox, Ralph Hartzler},
  publisher = {Springer Science {\&} Business Media},
  date      = {2012},
  title     = {{Introduction to knot theory}},
  volume    = {57},
}

@article{lerer2016learning,
  author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
  date   = {2016},
  title  = {{Learning Physical Intuition of Block Towers by Example}},
}

@article{cheung2014discovering,
  author = {Cheung, Brian and Livezey, Jesse A and Bansal, Arjun K and Olshausen, Bruno A},
  date   = {2014},
  title  = {{Discovering hidden factors of variation in deep networks}},
}

@inproceedings{schulman2013generalization,
  author    = {Schulman, John and Ho, Jonathan and Lee, Cameron and Abbeel, Pieter},
  booktitle = {Proceedings of the 16th International Symposium on Robotics Research (ISRR)},
  date      = {2013},
  title     = {{Generalization in robotic manipulation through the use of non-rigid registration}},
}

@article{wolpert1995internal,
  author    = {Wolpert, Daniel M and Ghahramani, Zoubin and Jordan, Michael I},
  publisher = {New York, NY:[sn] 1880-},
  date      = {1995},
  number    = {5232},
  pages     = {1880--1882},
  title     = {{An internal model for sensorimotor integration}},
  volume    = {269},
}

@inproceedings{krizhevsky2012imagenet,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2012},
  pages     = {1097--1105},
  title     = {{Imagenet classification with deep convolutional neural networks}},
}

@article{huh2016makes,
  author = {Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  date   = {2016},
  title  = {{What makes ImageNet good for transfer learning?}},
}

@article{dogar2012planning,
  author    = {Dogar, Mehmet R and Srinivasa, Siddhartha S},
  publisher = {Springer},
  date      = {2012},
  number    = {3},
  pages     = {217--236},
  title     = {{A planning framework for non-prehensile manipulation under clutter and uncertainty}},
  volume    = {33},
}

@article{levine2017grasping,
  author = {Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},
  date   = {2017},
  title  = {{Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection}},
}

@article{higgins2017darla,
  author = {Higgins, Irina and Pal, Arka and Rusu, Andrei A and Matthey, Loic and Burgess, Christopher P and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
  date   = {2017},
  title  = {{Darla: Improving zero-shot transfer in reinforcement learning}},
}

@article{fujimoto2018td3,
  author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  date   = {2018},
  title  = {{Addressing Function Approximation Error in Actor-Critic Methods}},
}

@article{mayer2008system,
  author    = {Mayer, Hermann and Gomez, Faustino and Wierstra, Daan and Nagy, Istvan and Knoll, Alois and Schmidhuber, Jrgen},
  publisher = {Taylor {\&} Francis},
  date      = {2008},
  number    = {13-14},
  pages     = {1521--1537},
  title     = {{A system for robotic heart surgery that learns to tie knots using recurrent neural networks}},
  volume    = {22},
}

@inproceedings{hamrick2011internal,
  author       = {Hamrick, Jessica and Battaglia, Peter and Tenenbaum, Joshua B},
  organization = {Cognitive Science Society Austin, TX},
  booktitle    = {Proceedings of the 33rd annual conference of the cognitive science society},
  date         = {2011},
  pages        = {1545--1550},
  title        = {{Internal physics models guide probabilistic judgments about object dynamics}},
}

@article{mayne2014model,
  author   = {Mayne, David Q},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109814005160},
  date     = {2014},
  doi      = {http://dx.doi.org/10.1016/j.automatica.2014.10.128},
  issn     = {0005-1098},
  keywords = {Model predictive control},
  number   = {12},
  pages    = {2967--2986},
  title    = {{Model predictive control: Recent developments and future promise}},
  volume   = {50},
}

@article{mnih2015human,
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  publisher = {Nature Publishing Group},
  date      = {2015},
  number    = {7540},
  pages     = {529--533},
  title     = {{Human-level control through deep reinforcement learning}},
  volume    = {518},
}

@article{mottaghi2015newtonian,
  author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
  date   = {2015},
  title  = {{Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images}},
}

@inproceedings{stilman2007manipulation,
  author       = {Stilman, Mike and Schamburek, Jan-Ullrich and Kuffner, James and Asfour, Tamim},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2007},
  pages        = {3327--3332},
  title        = {{Manipulation planning among movable obstacles}},
}

@article{higgins2016beta,
  author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  date   = {2017},
  title  = {{{\$}\backslashbeta{\$}-VAE: Learning basic visual concepts with a constrained variational framework}},
}

@article{haruno2001mosaic,
  author    = {Haruno, Masahiko and Wolpert, David H and Kawato, Mitsuo},
  publisher = {MIT Press},
  date      = {2001},
  number    = {10},
  pages     = {2201--2220},
  title     = {{Mosaic model for sensorimotor learning and control}},
  volume    = {13},
}

@inproceedings{lenz2015deepMPC,
  author    = {Lenz, Ian and Knepper, Ross and Saxena, Ashutosh},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2015},
  title     = {{DeepMPC: Learning Deep Latent Features for Model Predictive Control}},
}

@article{hopcroft1991case,
  author    = {Hopcroft, John E and Kearney, Joseph K and Krafft, Dean B},
  publisher = {Sage Publications},
  date      = {1991},
  number    = {1},
  pages     = {41--50},
  title     = {{A case study of flexible object manipulation}},
  volume    = {10},
}

@article{rusu2016sim,
  author = {Rusu, Andrei A and Vecerik, Matej and Rothrl, Thomas and Heess, Nicolas and Pascanu, Razvan and Hadsell, Raia},
  date   = {2017},
  title  = {{Sim-to-real robot learning from pixels with progressive nets}},
}

@techreport{winograd1971procedures,
  author      = {Winograd, Terry},
  institution = {DTIC Document},
  date        = {1971},
  title       = {{Procedures as a representation for data in a computer program for understanding natural language}},
}

@inproceedings{5459407,
  author    = {Brubaker, Marcus A and Sigal, L and Fleet, D J},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  date      = {2009-09},
  doi       = {10.1109/ICCV.2009.5459407},
  issn      = {1550-5499},
  keywords  = {Biological system modeling,Geometry,Gravity,Humans},
  pages     = {2389--2396},
  title     = {{Estimating contact dynamics}},
}

@article{eysenbach2018diayn,
  author = {Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  date   = {2018},
  title  = {{Diversity is All You Need: Learning Skills without a Reward Function}},
}

@inproceedings{agarwal1997nonholonomic,
  author       = {Agarwal, Pankaj K and Latombe, Jean-Claude and Motwani, Rajeev and Raghavan, Prabhakar},
  organization = {Citeseer},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {1997},
  pages        = {3124--3129},
  title        = {{Nonholonomic path planning for pushing a disk among obstacles}},
}

@inproceedings{conf/eccv/BhatSP02,
  author    = {Bhat, Kiran S and Seitz, Steven M and Popovic, Jovan},
  editor    = {Heyden, Anders and Sparr, Gunnar and Nielsen, Mads and Johansen, Peter},
  publisher = {Springer},
  url       = {http://dblp.uni-trier.de/db/conf/eccv/eccv2002-1.html{\#}BhatSP02},
  booktitle = {European Conference on Computer Vision (ECCV)},
  date      = {2002},
  isbn      = {3-540-43745-2},
  keywords  = {dblp},
  pages     = {551--565},
  series    = {Lecture Notes in Computer Science},
  title     = {{Computing the Physical Parameters of Rigid-Body Motion from Video.}},
  volume    = {2350},
}

@article{wahlstrom2015from,
  author = {Wahlstrm, Niklas and Schn, Thomas B and Deisenroth, Marc Peter},
  date   = {2015},
  title  = {{From Pixels to Torques: Policy Learning with Deep Dynamical Models}},
  volume = {abs/1502.0},
}

@inproceedings{wu2015galileo,
  author    = {Wu, Jiajun and Yildirim, Ilker and Lim, Joseph J and Freeman, Bill and Tenenbaum, Josh},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  pages     = {127--135},
  title     = {{Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning}},
}

@article{argall2009survey,
  author    = {Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  publisher = {Elsevier},
  date      = {2009},
  number    = {5},
  pages     = {469--483},
  title     = {{A survey of robot learning from demonstration}},
  volume    = {57},
}

@article{shelhamer2016loss,
  author = {Shelhamer, Evan and Mahmoudieh, Parsa and Argus, Max and Darrell, Trevor},
  date   = {2016},
  title  = {{Loss is its own reward: Self-supervision for reinforcement learning}},
}

@inproceedings{yamakawa2007one,
  author       = {Yamakawa, Yuji and Namiki, Akio and Ishikawa, Masatoshi and Shimojo, Makoto},
  organization = {IEEE},
  booktitle    = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date         = {2007},
  pages        = {703--708},
  title        = {{One-handed knotting of a flexible rope with a high-speed multifingered hand having tactile sensors}},
}

@article{maaten2008visualizing,
  author = {van der Maaten, Laurens and Hinton, Geoffrey},
  date   = {2008},
  number = Nov,
  pages  = {2579--2605},
  title  = {{Visualizing data using t-SNE}},
  volume = {9},
}

@phdthesis{bell2010flexible,
  author = {Bell, Matthew},
  date   = {2010},
  title  = {{Flexible object manipulation}},
}

@inproceedings{bellemare2016unifying,
  author    = {Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  pages     = {1471--1479},
  title     = {{Unifying count-based exploration and intrinsic motivation}},
}

@inproceedings{maitin2010cloth,
  author       = {Maitin-Shepard, Jeremy and Cusumano-Towner, Marco and Lei, Jinna and Abbeel, Pieter},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2010},
  pages        = {2308--2315},
  title        = {{Cloth grasp point detection based on multiple-view geometric cues with application to robotic towel folding}},
}

@inproceedings{miller2011parametrized,
  author       = {Miller, Stephen and Fritz, Mario and Darrell, Trevor and Abbeel, Pieter},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2011},
  pages        = {4861--4868},
  title        = {{Parametrized shape models for clothing}},
}

@inproceedings{sutton2011horde,
  author    = {Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  url       = {https://www.cs.swarthmore.edu/{~}meeden/DevelopmentalRobotics/horde1.pdf},
  booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  date      = {2011},
  keywords  = {Categories and,Descriptors,Subject},
  pages     = {761--768},
  title     = {{Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction}},
  volume    = {10},
}

@inproceedings{ziebart2008maxent,
  author    = {Ziebart, Brian D and Maas, Andrew and Bagnell, J Andrew and Dey, Anind K},
  url       = {https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf http://www.scopus.com/inward/record.url?eid=2-s2.0-57749097473{\&}partnerID=40{\%}5Cnhttp://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2008},
  eprint    = {arXiv:1507.04888v2},
  isbn      = {9781577353683 (ISBN)},
  issn      = {10450823},
  keywords  = {Artificial intelligence,Bionics,Driving behaviors,Existing methods,Imitation learnings,Inverse problems,Maximum entropies,New approaches,Optimal policies,Partial trajectories,Performance guarantees,Principle of Maximum entropies,Probabilistic approaches,Probability,Probability distributions,Reinforcement,Reinforcement learning,Route preferences,Utility functions},
  pages     = {1433--1438},
  title     = {{Maximum Entropy Inverse Reinforcement Learning.}},
}

@article{Gu2016b,
  author = {Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1610.00633.pdf http://arxiv.org/abs/1610.00633},
  date   = {2017},
  doi    = {10.1038/nature20101},
  eprint = {1610.00633},
  isbn   = {0896-6273},
  issn   = {0028-0836},
  title  = {{Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Off-Policy Updates}},
}

@article{deisenroth2011stacking,
  author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Fox, Dieter},
  url    = {http://www.roboticsproceedings.org/rss07/p08.pdf},
  date   = {2011},
  pages  = {57--64},
  title  = {{Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning}},
  volume = {VII},
}

@inproceedings{ross2011dagger,
  author    = {Ross, Stphane and Gordon, Geoffrey J and Bagnell, J Andrew},
  url       = {https://arxiv.org/pdf/1011.0686.pdf https://www.cs.cmu.edu/{~}sross1/publications/Ross-AIStats11-NoRegret.pdf},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  date      = {2011},
  title     = {{A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning}},
}

@article{Kaelbling2011,
  author = {Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  url    = {http://people.csail.mit.edu/lpk/papers/hpn2.pdf http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5980391},
  date   = {2011},
  doi    = {10.1109/ICRA.2011.5980391},
  isbn   = {9781612843865},
  issn   = {10504729},
  pages  = {1470--1477},
  title  = {{Hierarchical task and motion planning in the now}},
}

@inproceedings{todorov12mujoco,
  author    = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  url       = {https://homes.cs.washington.edu/{~}todorov/papers/TodorovIROS12.pdf},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2012},
  doi       = {10.1109/IROS.2012.6386109},
  isbn      = {9781467317375},
  issn      = {21530858},
  pages     = {5026--5033},
  title     = {{MuJoCo: A physics engine for model-based control}},
}

@inproceedings{kim2013apid,
  author    = {Kim, Beomjoon and Farahmand, Amir-Massoud and Pineau, Joelle and Precup, Doina},
  url       = {https://papers.nips.cc/paper/4918-learning-from-limited-demonstrations.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2013},
  title     = {{Learning from Limited Demonstrations}},
}

@inproceedings{schaul2015uva,
  author    = {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  url       = {http://proceedings.mlr.press/v37/schaul15.pdf http://jmlr.org/proceedings/papers/v37/schaul15.html},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2015},
  isbn      = {9781510810587},
  pages     = {1312--1320},
  title     = {{Universal Value Function Approximators}},
}

@inproceedings{finn2016deep,
  author       = {Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2016},
  doi          = {10.1109/ICRA.2016.7487173},
  eprint       = {1509.06113},
  isbn         = {9781467380263},
  issn         = {10504729},
  pages        = {512--519},
  title        = {{Deep spatial autoencoders for visuomotor learning}},
  volume       = {2016-June},
}

@inproceedings{schulman2015trpo,
  author    = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1502.05477.pdf http://arxiv.org/abs/1502.05477},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2015},
  doi       = {10.1063/1.4927398},
  eprint    = {1502.05477},
  isbn      = {0375-9687},
  issn      = {2158-3226},
  title     = {{Trust Region Policy Optimization}},
}

@inproceedings{kolev2015physically,
  author       = {Kolev, Svetoslav and Todorov, Emanuel},
  organization = {IEEE},
  url          = {http://homes.cs.washington.edu/{~}todorov/papers/KolevHumanoids15.pdf},
  booktitle    = {IEEE-RAS International Conference on Humanoid Robots (Humanoids)},
  date         = {2015},
  pages        = {1036--1043},
  title        = {{Physically consistent state estimation and system identification for contacts}},
}

@inproceedings{peters2010reps,
  author    = {Peters, Jan and Mlling, Katharina and Altn, Yasemin},
  url       = {https://pdfs.semanticscholar.org/ff47/526838ce85d77a50197a0c5f6ee5095156aa.pdf http://www-clmc.usc.edu/publications/P/Peters{\_}POTTNCOAIPGAT{\_}2010.pdf},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2010},
  pages     = {1607--1612},
  title     = {{Relative Entropy Policy Search}},
}

@inproceedings{ho2016gail,
  author    = {Ho, Jonathan and Ermon, Stefano},
  url       = {https://arxiv.org/pdf/1606.03476.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  title     = {{Generative Adversarial Imitation Learning}},
}

@inproceedings{chen2016infogan,
  author    = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  url       = {http://arxiv.org/abs/1606.03657},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1606.03657},
  pages     = {2172--2180},
  title     = {{Infogan: Interpretable representation learning by information maximizing generative adversarial nets}},
}

@article{silver2016alphago,
  author    = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  url       = {http://dx.doi.org/10.1038/nature16961 http://10.0.4.14/nature16961 http://www.nature.com/nature/journal/v529/n7587/abs/nature16961.html{\#}supplementary-information http://airesearch.com/wp-content/uploads/2016/01/deepmind-mastering-go.pdf},
  date      = {2016-01},
  doi       = {10.1038/nature16961},
  eprint    = {1610.00633},
  isbn      = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
  issn      = {0028-0836},
  number    = {7587},
  pages     = {484--489},
  title     = {{Mastering the game of Go with deep neural networks and tree search}},
  volume    = {529},
}

@inproceedings{nakanishi2004bipedlfd,
  author    = {Nakanishi, Jun and Morimoto, Jun and Endo, Gen and Cheng, Gordon and Schaal, Stefan and Kawato, Mitsuo},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.534{\&}rep=rep1{\&}type=pdf},
  booktitle = {Robotics and Autonomous Systems},
  date      = {2004},
  doi       = {10.1016/j.robot.2004.03.003},
  isbn      = {0921-8890},
  issn      = {09218890},
  keywords  = {Biped locomotion,Dynamical movement primitives,Frequency adaptation,Learning from demonstration,Phase resetting},
  number    = {2-3},
  pages     = {79--91},
  title     = {{Learning from demonstration and adaptation of biped locomotion}},
  volume    = {47},
}

@inproceedings{schaal2001augmentation,
  author    = {Schaal, Stefan and Vijayakumar, Sethu and Souza, Aaron D ' and Ijspeert, Auke and Nakanishi, Jun},
  url       = {http://www-clmc.usc.edu},
  booktitle = {International Symposium on Robotics Research},
  title     = {{Real-Time Statistical Learning For Robotics and Human Augmentation}},
}

@article{Kavraki1996,
  author = {Kavraki, Lydia and Svestka, Petr and Latombe, J-C and Overmars, Mark},
  date   = {1996},
  number = {4},
  pages  = {566--580},
  title  = {{Probabilistic roadmaps for path planning in high-dimensional configuration spaces}},
  volume = {12},
}

@inproceedings{pathak2017curiosity,
  author       = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  organization = {IEEE},
  booktitle    = {International Conference on Machine Learning (ICML)},
  date         = {2017},
  eprint       = {1705.05363},
  pages        = {488--489},
  title        = {{Curiosity-Driven Exploration by Self-Supervised Prediction}},
}

@article{smith2005development,
  author    = {Smith, Linda and Gasser, Michael},
  publisher = {MIT Press},
  url       = {https://www.cogsci.msu.edu/DSS/2010-2011/Smith/6lessons.pdf},
  date      = {2005},
  keywords  = {cognition,development,embodiment,language,motor control},
  number    = {1-2},
  pages     = {13--29},
  title     = {{The development of embodied cognition: Six lessons from babies}},
  volume    = {11},
}

@inproceedings{ng2000irl,
  author    = {Ng, Andrew and Russell, Stuart},
  url       = {http://ai.stanford.edu/{~}ang/papers/icml00-irl.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2000},
  title     = {{Algorithms for Inverse Reinforcement Learning}},
}

@inproceedings{srivastava14tamp,
  author    = {Srivastava, Siddharth and Fang, Eugene and Riano, Lorenzo and Chitnis, Rohan and Russell, Stuart and Abbeel, Pieter},
  url       = {https://people.eecs.berkeley.edu/{~}russell/papers/icra14-planrob.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2014},
  title     = {{Combined Task and Motion Planning Through an Extensible Planner-Independent Interface Layer}},
}

@article{peters2003naturalac,
  author = {Peters, Jan and Vijayakumar, Sethu and Schaal, Stefan},
  url    = {http://kyb.tuebingen.mpg.de/fileadmin/user{\_}upload/files/publications/attachments/NIPS-Workshop-2003-Peters{\_}{\%}5B0{\%}5D.pdf},
  date   = {2008},
  pages  = {1180--1190},
  title  = {{Natural Actor Critic}},
  volume = {71},
}

@inproceedings{boots2014traces,
  author    = {Boots, Byron and Byravan, Arunkumar and Fox, Dieter},
  url       = {http://dx.doi.org/10.1109/ICRA.2014.6907443},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2014},
  doi       = {10.1109/ICRA.2014.6907443},
  pages     = {4021--4028},
  title     = {{Learning predictive models of a depth camera {\&} manipulator from raw execution traces}},
}

@inproceedings{florensa2017resets,
  author    = {Florensa, Carlos and Held, David and Wulfmeier, Markus and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1707.05300.pdf http://arxiv.org/abs/1707.05300},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  eprint    = {1707.05300},
  keywords  = {Automatic Curricu-lum Generation,Reinforcement Learning,Robotic Manipulation},
  title     = {{Reverse Curriculum Generation for Reinforcement Learning}},
}

@article{peters2008baseball,
  author   = {Peters, Jan and Schaal, Stefan},
  url      = {https://pdfs.semanticscholar.org/eb5b/459c8a3e56064158fb3514eeab763486e437.pdf},
  date     = {2008},
  doi      = {10.1016/j.neunet.2008.02.003},
  eprint   = {arXiv:1411.3159v1},
  isbn     = {0893-6080},
  issn     = {08936080},
  keywords = {Motor primitives,Motor skills,Natural Actor-Critic,Natural gradients,Policy gradient methods,Reinforcement learning},
  number   = {4},
  pages    = {682--697},
  title    = {{Reinforcement learning of motor skills with policy gradients}},
  volume   = {21},
}

@inproceedings{kalakrishnan09terraintemplates,
  author    = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Schaal, Stefan},
  url       = {https://pdfs.semanticscholar.org/02db/2c0100ffb02592e8738d0ffcf454224f4b1b.pdf},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2009},
  title     = {{Learning Locomotion over Rough Terrain using Terrain Templates}},
}

@inproceedings{finn16guidedcostlearning,
  author    = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1603.00448.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  title     = {{Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization}},
}

@inproceedings{bahdanau14attention,
  author    = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  url       = {https://arxiv.org/pdf/1409.0473.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2015},
  title     = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
}

@inproceedings{duan2017oneshotimitation,
  author    = {Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly C. and Ho, Jonathan and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  eprint    = {1703.07326},
  title     = {{One-Shot Imitation Learning}},
}

@inproceedings{pong2018tdm,
  author    = {Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1802.09081.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Temporal Difference Models: Model-Free Deep RL For Model-Based Control}},
}

@inproceedings{finn2016visualforesight,
  author    = {Finn, Chelsea and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1610.00696.pdf http://arxiv.org/abs/1610.00696},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1610.00696},
  title     = {{Deep Visual Foresight for Planning Robot Motion}},
}

@inproceedings{ijspeert2002attractor,
  author    = {Ijspeert, Auke Jan and Nakanishi, Jun and Schaal, Stefan},
  url       = {https://papers.nips.cc/paper/2140-learning-attractor-landscapes-for-learning-motor-primitives.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2002},
  isbn      = {1049-5258},
  issn      = {10495258},
  keywords  = {reinforcement},
  pages     = {1547--1554},
  title     = {{Learning Attractor Landscapes for Learning Motor Primitives}},
}

@inproceedings{pathak2018zeroshot,
  author    = {Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A and Darrell, Trevor},
  url       = {https://arxiv.org/pdf/1804.08606.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Zero-Shot Visual Imitation}},
}

@inproceedings{pomerleau1989alvinn,
  author    = {Pomerleau, Dean A},
  url       = {http://repository.cmu.edu/compsci},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {1989},
  isbn      = {1-558-60015-9},
  pages     = {305--313},
  title     = {{Alvinn: An autonomous land vehicle in a neural network}},
}

@inproceedings{sun17deeplyaggrevated,
  author    = {Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Edu, Bboots@cc Gatech and Bagnell, J Andrew},
  url       = {https://arxiv.org/pdf/1703.01030.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction}},
}

@article{wakamatsu2006knotting,
  author    = {Wakamatsu, Hidefumi and Arai, Eiji and Hirai, Shinichi},
  publisher = {SAGE Publications},
  date      = {2006},
  number    = {4},
  pages     = {371--395},
  title     = {{Knotting/unknotting manipulation of deformable linear objects}},
  volume    = {25},
}

@article{Ross2014,
  author   = {Ross, Stphane Stephane and Bagnell, J Andrew},
  url      = {https://arxiv.org/pdf/1406.5979.pdf http://arxiv.org/abs/1406.5979},
  date     = {2014},
  eprint   = {1406.5979},
  keywords = {()},
  title    = {{Reinforcement and Imitation Learning via Interactive No-Regret Learning}},
  volume   = {abs/1406.5},
}

@article{vecerik17ddpgfd,
  author   = {Veerk, Matej and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Rothrl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  url      = {https://arxiv.org/pdf/1707.08817.pdf},
  date     = {2017},
  keywords = {Apprenticeship,Demonstrations,Learning,Robot},
  title    = {{Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards}},
  volume   = {abs/1707.0},
}

@inproceedings{reed2014learning,
  author    = {Reed, Scott and Sohn, Kihyuk and Zhang, Yuting and Lee, Honglak},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2014},
  pages     = {1431--1439},
  title     = {{Learning to disentangle factors of variation with manifold interaction}},
}

@inproceedings{yang2015robot,
  author    = {Yang, Yezhou and Li, Yi and Fermller, Cornelia and Aloimonos, Yiannis},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2015},
  pages     = {3686--3693},
  title     = {{Robot Learning Manipulation Action Plans by" Watching" Unconstrained Videos from the World Wide Web.}},
}

@article{michotte1963perception,
  author    = {Michotte, Albert},
  publisher = {Basic Books},
  date      = {1963},
  title     = {{The perception of causality.}},
}

@article{levy2017hierarchical,
  author = {Levy, Andrew and Platt, Robert and Saenko, Kate},
  date   = {2017},
  title  = {{Hierarchical Actor-Critic}},
}

@inproceedings{morita2003knot,
  author       = {Morita, Takuma and Takamatsu, Jun and Ogawara, Koichi and Kimura, Hiroshi and Ikeuchi, Katsushi},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2003},
  pages        = {3887--3892},
  title        = {{Knot planning from observation}},
  volume       = {3},
}

@book{lavalle2006planning,
  author    = {LaValle, Steven M},
  publisher = {Cambridge university press},
  date      = {2006},
  title     = {{Planning algorithms}},
}

@inproceedings{kakade2002approximatelyoptimal,
  author    = {Kakade, Sham and Langford, John},
  url       = {http://www.cs.cmu.edu/afs/cs/Web/People/jcl/papers/aoarl/Final.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2002},
  isbn      = {1-55860-873-7},
  pages     = {267--274},
  title     = {{Approximately Optimal Approximate Reinforcement Learning}},
}

@inproceedings{hosu2016humancheckpoint,
  author    = {Hosu, Ionel-Alexandru and Rebedea, Traian},
  url       = {https://arxiv.org/pdf/1607.05077.pdf},
  booktitle = {Workshop on Evaluating General Purpose AI},
  date      = {2016},
  title     = {{Playing Atari Games with Deep Reinforcement Learning and Human Checkpoint Replay}},
}

@article{Dragan2017,
  author = {Dragan, Anca D.},
  url    = {https://arxiv.org/pdf/1705.04226.pdf http://arxiv.org/abs/1705.04226},
  date   = {2017-05},
  eprint = {1705.04226},
  title  = {{Robot Planning with Mathematical Models of Human State and Action}},
}

@inproceedings{mnih2013atari,
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  url       = {https://arxiv.org/pdf/1312.5602.pdf http://arxiv.org/abs/1312.5602 https://www.cs.toronto.edu/{~}vmnih/docs/dqn.pdf},
  booktitle = {NIPS Workshop on Deep Learning},
  date      = {2013},
  doi       = {10.1038/nature14236},
  eprint    = {1312.5602},
  isbn      = {1476-4687 (Electronic) 0028-0836 (Linking)},
  issn      = {0028-0836},
  pages     = {1--9},
  title     = {{Playing Atari with Deep Reinforcement Learning}},
}

@inproceedings{rajeswaran2017simplicity,
  author    = {Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel and Kakade, Sham},
  url       = {https://arxiv.org/pdf/1703.02660.pdf https://homes.cs.washington.edu/{~}todorov/papers/RajeswaranICML17.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  title     = {{Towards Generalization and Simplicity in Continuous Control}},
}

@inproceedings{nair2018demonstrations,
  author    = {Nair, Ashvin and Mcgrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1709.10089.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{Overcoming Exploration in Reinforcement Learning with Demonstrations}},
}

@inproceedings{vezhnevets2017fun,
  author    = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  url       = {https://arxiv.org/pdf/1703.01161.pdf http://arxiv.org/abs/1703.01161},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  eprint    = {1703.01161},
  title     = {{FeUdal Networks for Hierarchical Reinforcement Learning}},
}

@inproceedings{wang2016duelingdqn,
  author    = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Com, Mtthss@google and {Van Hasselt}, Hado and Lanctot, Marc},
  url       = {https://arxiv.org/pdf/1511.06581.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  title     = {{Dueling Network Architectures for Deep Reinforcement Learning}},
}

@inproceedings{silver2014dpg,
  author    = {Silver, David and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  url       = {http://proceedings.mlr.press/v32/silver14.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2014},
  title     = {{Deterministic Policy Gradient Algorithms}},
}

@inproceedings{liu2018imitation,
  author    = {Liu, Yuxuan and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1707.03374.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation}},
}

@inproceedings{Groshev,
  author = {Groshev, Edward and Tamar, Aviv and Srivastava, Siddharth and Abbeel, Pieter},
  url    = {https://arxiv.org/pdf/1708.07280.pdf},
  title  = {{Learning Generalized Reactive Policies using Deep Neural Networks}},
}

@book{sutton1998rl,
  author = {Sutton, Richard S and Barto, Andrew G},
  url    = {http://incompleteideas.net/sutton/book/bookdraft2016sep.pdf https://webdocs.cs.ualberta.ca/{~}sutton/book/bookdraft2016sep.pdf},
  date   = {1998},
  title  = {{Reinforcement Learning: An Introduction}},
}

@inproceedings{heess2015svg,
  author    = {Heess, Nicolas and Wayne, Greg and Silver, David and Lillicrap, Timothy and Tassa, Yuval and Erez, Tom and Deepmind, Google},
  url       = {https://arxiv.org/pdf/1510.09142.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  title     = {{Learning Continuous Control Policies by Stochastic Value Gradients}},
}

@inproceedings{jang2017grasping,
  author    = {Jang, Eric and Brain, Google and Vijayanarasimhan, Sudheendra and Pastor, Peter and Ibarz, Julian and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1707.01932.pdf},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2017},
  keywords  = {deep learning,semantic grasping},
  title     = {{End-to-End Learning of Semantic Grasping}},
}

@inproceedings{wu2017acktr,
  author    = {Wu, Yuhuai and Mansimov, Elman and Liao, Shun and Grosse, Roger and Ba, Jimmy},
  url       = {https://arxiv.org/pdf/1708.05144.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  title     = {{Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation}},
}

@inproceedings{mishra2017icml,
  author    = {Mishra, Nikhil and Abbeel, Pieter and Mordatch, Igor},
  url       = {https://arxiv.org/pdf/1703.04070.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Prediction and Control with Temporal Segment Models}},
}

@inproceedings{haarnoja2017sql,
  author    = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1702.08165.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Reinforcement Learning with Deep Energy-Based Policies}},
}

@inproceedings{christiano2017humanpreferences,
  author    = {Christiano, Paul F and Leike, Jan and Brown, Tom B and Martic, Miljan and Legg, Shane and Amodei, Dario},
  url       = {https://arxiv.org/pdf/1706.03741.pdf http://arxiv.org/abs/1706.03741},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  eprint    = {1706.03741},
  title     = {{Deep reinforcement learning from human preferences}},
}

@book{szepesvari2010,
  author    = {Szepesvri, Csaba},
  url       = {https://sites.ualberta.ca/{~}szepesva/papers/RLAlgsInMDPs.pdf},
  booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  date      = {2010},
  doi       = {10.2200/S00268ED1V01Y201005AIM009},
  isbn      = {9781608454921},
  issn      = {1939-4608},
  number    = {1},
  pages     = {1--103},
  title     = {{Algorithms for Reinforcement Learning}},
  volume    = {4},
}

@inproceedings{goodfellow2014gan,
  author    = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  url       = {https://arxiv.org/pdf/1406.2661.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2014},
  title     = {{Generative Adversarial Nets}},
}

@article{Sunderhauf2018,
  author = {Snderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, Jrgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael and Corke, Peter},
  url    = {http://arxiv.org/abs/1804.06557},
  date   = {2018},
  doi    = {10.1177/ToBeAssigned},
  eprint = {1804.06557},
  isbn   = {0037549716666},
  issn   = {1756-8277},
  number = {4-5},
  pages  = {405--420},
  title  = {{The Limits and Potentials of Deep Learning for Robotics}},
  volume = {37},
}

@inproceedings{Todorov2018,
  author    = {Todorov, Emanuel},
  url       = {https://homes.cs.washington.edu/{~}todorov/papers/TodorovICRA18.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  isbn      = {9781538630808},
  title     = {{Goal Directed Dynamics}},
}

@article{Keramati,
  author = {Keramati, Ramtin and Whang, Jay and Cho, Patrick and Brunskill, Emma},
  eprint = {1806.00175},
  pages  = {1--10},
  title  = {{Strategic Object Oriented Reinforcement Learning}},
}

@article{Johnson,
  author = {Johnson, Matthew James and Duvenaud, David and Wiltschko, Alexander B and Datta, Sandeep R and Adams, Ryan P},
  title  = {{Composing graphical models with neural networks for structured representations and fast inference}},
}

@inproceedings{Arjovsky2017,
  author    = {Arjovsky, Martin and Chintala, Soumith and Bottou, Lon},
  url       = {https://arxiv.org/pdf/1701.07875.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Wasserstein GAN}},
}

@article{Kalakrishnan2011,
  author   = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
  url      = {https://www.researchgate.net/profile/Michael{\_}Mistry/publication/220122611{\_}Learning{\_}planning{\_}and{\_}control{\_}for{\_}quadruped{\_}locomotion{\_}over{\_}challenging{\_}terrain/links/02bfe50ca950d456c2000000.pdf},
  date     = {2011},
  doi      = {10.1177/0278364910388677},
  isbn     = {0278-3649},
  issn     = {0278-3649},
  keywords = {floating base inverse,locomotion planning and control,quadruped locomotion,template learning,zmp optimization},
  number   = {2},
  pages    = {236--258},
  title    = {{Learning, planning, and control for quadruped locomotion over challenging terrain}},
  volume   = {30},
}

@inproceedings{Lambert2018,
  author    = {Lambert, Alexander and Shaban, Amirreza and Raj, Amit and Liu, Zhen and Boots, Byron},
  url       = {http://arxiv.org/abs/1710.11311},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  eprint    = {1710.11311},
  isbn      = {9781538630808},
  title     = {{Deep Forward and Inverse Perceptual Models for Tracking and Prediction}},
}

@article{Wayne2018,
  author = {Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and Grabska-Barwinska, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z. and Santoro, Adam and Gemici, Mevlana and Reynolds, Malcolm and Harley, Tim and Abramson, Josh and Mohamed, Shakir and Rezende, Danilo and Saxton, David and Cain, Adam and Hillier, Chloe and Silver, David and Kavukcuoglu, Koray and Botvinick, Matt and Hassabis, Demis and Lillicrap, Timothy},
  url    = {http://arxiv.org/abs/1803.10760},
  date   = {2018},
  eprint = {1803.10760},
  title  = {{Unsupervised Predictive Memory in a Goal-Directed Agent}},
}

@article{Mirowski2018,
  author = {Mirowski, Piotr and Grimes, Matthew Koichi and Malinowski, Mateusz and Hermann, Karl Moritz and Anderson, Keith and Teplyashin, Denis and Simonyan, Karen and Kavukcuoglu, Koray and Zisserman, Andrew and Hadsell, Raia},
  url    = {http://arxiv.org/abs/1804.00168},
  date   = {2018},
  eprint = {1804.00168},
  title  = {{Learning to Navigate in Cities Without a Map}},
}

@article{Hunt1992,
  author   = {Hunt, K. J. and Sbarbaro, D. and Zbikowski, R. and Gawthrop, P. J.},
  date     = {1992},
  doi      = {10.1016/0005-1098(92)90053-I},
  eprint   = {92 {\$}5.00 + 0.00},
  isbn     = {ISSN{\~}{\~}0005-1098},
  issn     = {00051098},
  keywords = {Neural networks,nonlinear control systems,nonlinear systems modelling,systems identification},
  number   = {6},
  pages    = {1083--1112},
  title    = {{Neural networks for control systems-A survey}},
  volume   = {28},
}

@inproceedings{kaelbling1993goals,
  author    = {Kaelbling, L P},
  booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
  date      = {1993},
  keywords  = {learning (artificial intelligence),temporal reason},
  pages     = {1094--8},
  title     = {{Learning to achieve goals}},
  volume    = {vol.2},
}

@article{Cheney2013,
  author   = {Cheney, Nick and Maccurdy, Robert and Clune, Jeff and Lipson, Hod},
  url      = {http://jeffclune.com/publications/2013{\_}Softbots{\_}GECCO.pdf},
  date     = {2013},
  keywords = {Algorithms,CPPN-NEAT,Categories and Subject Descriptors,Design,Evolving Morphologies,Experimentation Keywords,Generative Encodings,Genetic Algorithms,HyperNEAT,I211 [Distributed Artificial Intelligence],Intelligent Agents General Terms,Soft-Robotics},
  title    = {{Unshackling Evolution: Evolving Soft Robots with Multiple Materials and a Powerful Generative Encoding}},
}

@article{Levine2018,
  author = {Levine, Sergey},
  url    = {https://arxiv.org/pdf/1805.00909.pdf},
  date   = {2018},
  eprint = {arXiv:1805.00909v2},
  title  = {{Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}},
}

@article{Lesort2018,
  author   = {Lesort, Timothe and Daz-Rodrguez, Natalia and Goudou, Jean-Franois and Filliat, David},
  url      = {https://arxiv.org/pdf/1802.04181.pdf},
  date     = {2018},
  eprint   = {arXiv:1802.04181v1},
  keywords = {Disentanglement of control factors,Learning Disentangled Representations,Low Dimensional Embedding Learning,Reinforcement Learn-ing,Robotics,State Representation Learning},
  title    = {{State Representation Learning for Control: An Overview}},
}

@inproceedings{konda2015odometry,
  author    = {Konda, Kishore and Memisevic, Roland},
  url       = {http://www.iro.umontreal.ca/{~}memisevr/pubs/VISAPP2015.pdf},
  booktitle = {International Conference on Computer Vision Theory and Applications (VISAPP)},
  date      = {2015},
  keywords  = {Convolutional networks,Motion,Stereo,Visual odometry},
  title     = {{Learning visual odometry with a convolutional network}},
}

@inproceedings{coates2008demos,
  author    = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y},
  url       = {https://www-cs.stanford.edu/people/ang/papers/icml08-LearningForControlFromMultipleDemonstrations.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2008},
  title     = {{Learning for Control from Multiple Demonstrations}},
}

@inproceedings{we2018mpo,
  author    = {Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  pages     = {1--19},
  title     = {{Maximum a Posteriori Policy Optimisation}},
}

@article{Silver,
  author = {Silver, David and Hasselt, Hado Van and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and Degris, Thomas},
  url    = {https://arxiv.org/pdf/1612.08810.pdf},
  title  = {{The Predictron: End-To-End Learning and Planning}},
}

@article{Ritchie,
  author = {Ritchie, Daniel and Horsfall, Paul and Goodman, Noah D},
  url    = {https://arxiv.org/pdf/1610.05735.pdf},
  title  = {{Deep Amortized Inference for Probabilistic Programs}},
}

@article{Blei2017,
  author   = {Blei, David M and Kucukelbir, Alp and Mcauliffe, Jon D},
  url      = {https://arxiv.org/pdf/1601.00670.pdf},
  date     = {2017},
  eprint   = {arXiv:1601.00670v7},
  keywords = {Algorithms,Computationally Intensive Methods,Statistical Computing},
  title    = {{Variational Inference: A Review for Statisticians}},
}

@article{Hashim2017,
  author   = {Hashim, S.A. and Amin, M.A. and Nair, A. and {Raja Mokhtar}, R.A. and Krishnasamy, S. and Cheng, K.},
  date     = {2017},
  doi      = {10.1016/j.hlc.2017.11.011},
  issn     = {14442892},
  keywords = {CABG device,Coronary artery bypass graft},
  title    = {{A Flowmeter Technique to Exclude Internal Mammary Artery Anastomosis Error in an Arrested Heart}},
}

@article{Hestness,
  author = {Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and {Mostofa Ali Patwary}, Md and Yang, Yang and Zhou, Yanqi and Research, Baidu},
  url    = {https://arxiv.org/pdf/1712.00409.pdf},
  title  = {{Deep Learning Scaling Is Predictable, Empirically}},
}

@article{Legg2007,
  author   = {Legg, Shane and Hutter, Marcus},
  url      = {www.vetta.org/shane www.hutter1.net},
  date     = {2007},
  eprint   = {arXiv:0712.3329v1},
  keywords = {AIXI,Complexity theory,Intel-ligence definitions,Intelligence,Intelligence tests,Theoretical foundations,Turing test},
  title    = {{Universal Intelligence: A Definition of Machine Intelligence}},
}

@article{Behrouzi,
  author = {Behrouzi, Bita and Tweed, Douglas},
  url    = {https://arxiv.org/pdf/1711.05817.pdf},
  title  = {{Lagrange policy gradient}},
}

@article{Klein,
  author = {Klein, Dan},
  url    = {https://people.eecs.berkeley.edu/{~}klein/papers/lagrange-multipliers.pdf},
  title  = {{Lagrange Multipliers without Permanent Scarring}},
}

@article{I,
  author   = {I, Momennejad and Em, Russek and Jh, Cheong and Mm, Botvinick and Nd, Daw and Sj, Gershman},
  url      = {https://www.biorxiv.org/content/biorxiv/early/2017/07/04/083824.full.pdf},
  doi      = {10.1101/083824},
  keywords = {Decision making,Human behavior,Model-based,Planning,Predictive representation Acknowledgements,Reinforcement learning,Retrospective revaluation,Successor representation},
  title    = {{The successor representation in human reinforcement learning}},
}

@article{Dayan,
  author = {Dayan, Peter},
  url    = {http://www.gatsby.ucl.ac.uk/{~}dayan/papers/d93b.pdf},
  title  = {{Improving Generalisation for Temporal Difference Learning: The Successor Representation}},
}

@article{Norouzi2017,
  author   = {Norouzi, Mohammad and Bengio, Samy and Chen, Zhifeng and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale},
  url      = {https://arxiv.org/pdf/1609.00150.pdf},
  date     = {2017},
  eprint   = {arXiv:1609.00150v3},
  keywords = {()},
  title    = {{Reward Augmented Maximum Likelihood for Neural Structured Prediction}},
}

@inproceedings{peters2007rwr,
  author    = {Peters, Jan and Schaal, Stefan},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.6266{\&}rep=rep1{\&}type=pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2007},
  title     = {{Reinforcement Learning by Reward-weighted Regression for Operational Space Control}},
}

@article{Lecun2006,
  author = {Lecun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc Aurelio and Huang, Fu Jie},
  url    = {http://yann.lecun.com},
  date   = {2006},
  title  = {{A Tutorial on Energy-Based Learning}},
}

@article{Anderson1999,
  author = {Anderson, Eric C},
  url    = {http://ib.berkeley.edu/labs/slatkin/eriq/classes/guest{\_}lect/mc{\_}lecture{\_}notes.pdf},
  date   = {1999},
  title  = {{Lecture Notes for Stat 578C Monte Carlo Methods and Importance Sampling}},
}

@article{Bengioa,
  author = {Bengio, Yoshua and Lee, Dong-Hyun and Bornschein, Jorg and Mesnard, Thomas and Lin, Zhouhan},
  url    = {https://arxiv.org/pdf/1502.04156.pdf},
  title  = {{Towards Biologically Plausible Deep Learning}},
}

@article{Rivest,
  author = {Rivest, Franois and Bengio, Yoshua and Kalaska, John},
  url    = {https://papers.nips.cc/paper/2749-brain-inspired-reinforcement-learning.pdf},
  title  = {{Brain Inspired Reinforcement Learning}},
}

@inproceedings{Dosovitskiy,
  author    = {Dosovitskiy, Alexey and Koltun, Vladlen},
  url       = {https://arxiv.org/pdf/1611.01779.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  title     = {{Learning To Act By Predicting The Future}},
}

@article{Silvera,
  author = {Silver, David},
  url    = {http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching{\_}files/pg.pdf},
  title  = {{Lecture 7: Policy Gradient}},
}

@article{Levine,
  author = {Levine, Sergey},
  url    = {http://rll.berkeley.edu/deeprlcourse/f17docs/lecture{\_}11{\_}control{\_}and{\_}inference.pdf},
  title  = {{Connections Between Inference and Control CS 294-112: Deep Reinforcement Learning}},
}

@article{Ziebart,
  author = {Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  url    = {http://www.cs.cmu.edu/{~}bziebart/publications/maximum-causal-entropy.pdf},
  title  = {{Modeling Interaction via the Principle of Maximum Causal Entropy}},
}

@inproceedings{bojanowski2017unsupervised,
  author    = {Bojanowski, Piotr and Joulin, Armand},
  url       = {https://arxiv.org/pdf/1704.05310.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Unsupervised Learning by Predicting Noise}},
}

@article{Rolf,
  author = {Rolf, Matthias and Asada, Minoru},
  url    = {http://acl.mit.edu/amlsc/files/amlsc13{\_}submission{\_}7.pdf},
  title  = {{Learning Inverse Models in High Dimensions with Goal Babbling and Reward-Weighted Averaging}},
}

@article{Kremer,
  author = {Kremer, Jan and Pedersen, Kim Steenstrup and Igel, Christian},
  url    = {http://image.diku.dk/jank/papers/WIREs2014.pdf},
  title  = {{Active Learning with Support Vector Machines}},
}

@article{Jonas2017,
  author    = {Jonas, Eric and Kording, Konrad Paul},
  editor    = {Diedrichsen, Jrn},
  publisher = {Public Library of Science},
  url       = {http://dx.plos.org/10.1371/journal.pcbi.1005268},
  date      = {2017-01},
  doi       = {10.1371/journal.pcbi.1005268},
  issn      = {1553-7358},
  number    = {1},
  pages     = {e1005268},
  title     = {{Could a Neuroscientist Understand a Microprocessor?}},
  volume    = {13},
}

@article{Czarnecki,
  author = {Czarnecki, Wojciech Marian and Osindero, Simon and Jaderberg, Max and Swirszcz, Grzegorz and Pascanu, Razvan},
  url    = {https://arxiv.org/pdf/1706.04859.pdf},
  title  = {{Sobolev Training for Neural Networks}},
}

@article{Odonoghue2017,
  author = {{O 'donoghue}, Brendan and Osband, Ian and Munos, Remi and Deepmind, Volodymyr Mnih},
  url    = {https://arxiv.org/pdf/1709.05380.pdf},
  date   = {2017},
  title  = {{The Uncertainty Bellman Equation and Exploration}},
}

@article{Vasilaki2017,
  author = {Vasilaki, Eleni},
  url    = {https://arxiv.org/pdf/1710.04582.pdf},
  date   = {2017},
  eprint = {arXiv:1710.04582v1},
  title  = {{Is Epicurus the father of Reinforcement Learning?}},
}

@inproceedings{osband2016bootstrapped,
  author    = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Roy, Benjamin Van},
  url       = {https://arxiv.org/pdf/1602.04621.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  title     = {{Deep Exploration via Bootstrapped DQN}},
}

@inproceedings{byravan2018se3pose,
  author    = {Byravan, Arunkumar and Leeb, Felix and Meier, Franziska and Fox, Dieter},
  url       = {https://arxiv.org/pdf/1710.00489.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Planning and Control}},
}

@article{Pritzel,
  author = {Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Com, Adriap@google and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  url    = {https://arxiv.org/pdf/1703.01988.pdf},
  title  = {{Neural Episodic Control Adr aPuigdo enech}},
}

@article{Venkatraman,
  author = {Venkatraman, Arun and Rhinehart, Nicholas and Sun, Wen and Pinto, Lerrel and Hebert, Martial and Boots, Byron and Kitani, Kris M and Bagnell, J Andrew},
  url    = {https://arxiv.org/pdf/1709.08520.pdf},
  title  = {{Predictive-State Decoders: Encoding the Future into Recurrent Networks}},
}

@inproceedings{kaiser2017rareevents,
  author    = {Kaiser, Lukasz and Nachum, Ofir and Aurko, Roy and Bengio, Samy},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  title     = {{Learning to Remember Rare Events}},
}

@article{Ghahramani2015,
  author = {Ghahramani, Zoubin},
  url    = {https://www.cse.iitk.ac.in/users/piyush/courses/pml{\_}winter16/nature14541.pdf},
  date   = {2015},
  doi    = {10.1038/nature14541},
  title  = {{Probabilistic modelling and representing uncertainty}},
  volume = {521},
}

@article{Brooks1991,
  author = {Brooks, Rodney A},
  url    = {http://people.csail.mit.edu/brooks/papers/representation.pdf},
  date   = {1991},
  pages  = {139--159},
  title  = {{Intelligence without representation*}},
  volume = {47},
}

@inproceedings{held2018goalgan,
  author    = {Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1705.06366.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  title     = {{Automatic Goal Generation for Reinforcement Learning Agents}},
}

@inproceedings{schulman2016gae,
  author    = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1506.02438.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2016},
  title     = {{High-Dimensional Continuous Control Using Generalized Advantage Estimation}},
}

@article{Pastor2011,
  author = {Pastor, Peter},
  url    = {http://www.cs.utexas.edu/{~}sniekum/classes/RLFD-F16/papers/Pastor11.pdf},
  date   = {2011},
  doi    = {10.1109/ICRA.2011.5980200},
  isbn   = {978-1-61284-386-5},
  issn   = {1050-4729},
  pages  = {3828--3834},
  title  = {{Skill Learning and Task Outcome Prediction for Manipulation}},
}

@article{Ghadirzadeh,
  author = {Ghadirzadeh, Ali and Maki, Atsuto and Kragic, Danica and Bjrkman, M{}rten},
  url    = {https://arxiv.org/pdf/1703.00727.pdf},
  title  = {{Deep Predictive Policy Training using Reinforcement Learning}},
}

@article{Plappert,
  author = {Plappert, Matthias and Houthooft, Rein and Dhariwal, Prafulla and Sidor, Szymon and Chen, Richard Y and Chen, Xi and Asfour, Tamim and Abbeel, Pieter and Openai, Marcin Andrychowicz},
  url    = {https://arxiv.org/pdf/1706.01905.pdf},
  title  = {{Parameter Space Noise for Exploration}},
}

@article{Rajeswaran,
  author = {Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1610.01283.pdf},
  title  = {{EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES USING MODEL ENSEMBLES}},
}

@inproceedings{Bansal,
  author    = {Bansal, Somil and Calandra, Roberto and Xiao, Ted and Levine, Sergey and Tomlin, Claire J},
  url       = {https://arxiv.org/pdf/1703.09260.pdf},
  booktitle = {IEEE Conference on Decision and Control (CDC)},
  date      = {2017},
  title     = {{Goal-Driven Dynamics Learning via Bayesian Optimization}},
}

@article{Calandra2017,
  author = {Calandra, Roberto},
  url    = {http://www.robertocalandra.com/wp-content/uploads/2017-04-20-dali.pdf},
  date   = {2017},
  title  = {{Goal-Driven Dynamics Learning for Model-Based RL Motivation}},
}

@inproceedings{Tamar2016,
  author    = {Tamar, Aviv and Levine, Sergey and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1602.02867},
  issn      = {10495258},
  title     = {{Value Iteration Networks}},
}

@inproceedings{houthooft2016vime,
  author    = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and {De Turck}, Filip and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1605.09674},
  issn      = {10495258},
  title     = {{Variational Information Maximizing Exploration}},
}

@article{Reed,
  author = {Reed, Scott and {De Freitas}, Nando},
  url    = {https://arxiv.org/pdf/1511.06279v3.pdf},
  title  = {{Neural Programmer-Interpreters}},
}

@inproceedings{nagaband2018mbmf,
  author    = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1708.02596.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning}},
}

@article{Devin,
  author   = {Devin, Coline and Abbeel, Pieter and Darrell, Trevor and Levine, Sergey},
  url      = {https://arxiv.org/pdf/1708.04225.pdf},
  keywords = {manipulation,reinforcement learning,vision},
  title    = {{Deep Object-Centric Representations for Generalizable Robot Learning}},
}

@article{Rahmatizadeh,
  author = {Rahmatizadeh, Rouhollah and Abolghasemi, Pooya and Behal, Aman and Blni, Ladislau},
  url    = {https://arxiv.org/pdf/1603.03833.pdf},
  title  = {{Learning real manipulation tasks from virtual demonstrations using LSTM}},
}

@article{Wulfmeier,
  author   = {Wulfmeier, Markus and Posner, Ingmar and Abbeel, Pieter},
  url      = {https://arxiv.org/pdf/1707.07907.pdf},
  keywords = {Adversarial Learning,Robotics,Simulation,Transfer Learning},
  title    = {{Mutual Alignment Transfer Learning}},
}

@article{Singh,
  author = {Singh, Avi and Yang, Larry and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1708.02313.pdf},
  title  = {{GPLAC: Generalizing Vision-Based Robotic Skills using Weakly Labeled Images}},
}

@inproceedings{murali2018cassl,
  author    = {Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  url       = {https://arxiv.org/pdf/1708.01354.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  title     = {{CASSL: Curriculum Accelerated Self-Supervised Learning}},
}

@inproceedings{vaswani2017transformers,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {}ukasz and Polosukhin, Illia},
  url       = {https://arxiv.org/pdf/1706.03762.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2017},
  title     = {{Attention Is All You Need}},
}

@article{Oh,
  author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
  url    = {https://arxiv.org/pdf/1707.03497.pdf},
  title  = {{Value Prediction Network}},
}

@article{schulman2017ppo,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Openai, Oleg Klimov},
  url    = {https://arxiv.org/pdf/1707.06347.pdf},
  date   = {2017},
  title  = {{Proximal Policy Optimization Algorithms}},
}

@inproceedings{bellemare2017distributional,
  author    = {Bellemare, Marc G and Dabney, Will and Munos, Rmi},
  url       = {https://arxiv.org/pdf/1707.06887.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{A Distributional Perspective on Reinforcement Learning}},
}

@article{pearl1999reasoning,
  author = {Pearl, Judea},
  url    = {http://bayes.cs.ucla.edu/IJCAI99/ijcai-99.pdf},
  date   = {1999},
  title  = {{Reasoning with Cause and Effect}},
}

@inproceedings{Rahmatizadeha,
  author    = {Rahmatizadeh, Rouhollah and Abolghasemi, Pooya and Blni, Ladislau and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1707.02920.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2018},
  keywords  = {Affordable assistive robotics,Multi-task learning,Robot manipulation},
  title     = {{Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-To-End Learning from Demonstration}},
}

@article{Darvish,
  author   = {Darvish, Kourosh and Wanderlingh, Francesco and Bruno, Barbara and Simetti, Enrico and Mastrogiovanni, Fulvio and Casalino, Giuseppe},
  url      = {https://arxiv.org/pdf/1707.02591.pdf},
  keywords = {AND/OR graph,Human-Robot Cooperation,Smart Factory,Task Priority control,Wearable Sensing},
  title    = {{Flexible Human-Robot Cooperation Models for Assisted Shop-floor Tasks}},
}

@article{Lopez-Paz,
  author = {Lopez-Paz, David and Ranzato, Marc Aurelio},
  url    = {https://arxiv.org/pdf/1706.08840.pdf},
  title  = {{Gradient Episodic Memory for Continuum Learning}},
}

@article{Justesen,
  author = {Justesen, Niels and Risi, Sebastian},
  url    = {https://njustesen.files.wordpress.com/2017/07/njustesen2017learning.pdf},
  title  = {{Learning Macromanagement in StarCraft from Replays using Deep Learning}},
}

@article{Merel,
  author = {Merel, Josh and Tassa, Yuval and Tb, Dhruva and Srinivasan, Sriram and Lemmon, Jay and Wang, Ziyu and Wayne, Greg and Heess, Nicolas},
  url    = {https://arxiv.org/pdf/1707.02201.pdf},
  title  = {{Learning human behaviors from motion capture by adversarial imitation}},
}

@inproceedings{donahue2017bigan,
  author    = {Donahue, Jeff and Krhenbhl, Philipp and Darrell, Trevor},
  url       = {http://arxiv.org/abs/1605.09782},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017-05},
  eprint    = {1605.09782},
  title     = {{Adversarial Feature Learning}},
}

@inproceedings{oord2016pixelcnn,
  author    = {van den Oord, Aaron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
  publisher = {Neural information processing systems foundation},
  url       = {http://arxiv.org/abs/1606.05328},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2016-06},
  eprint    = {1606.05328},
  pages     = {4797--4805},
  title     = {{Conditional Image Generation with PixelCNN Decoders}},
}

@article{Cabi,
  author   = {Cabi, Serkan and {Gmez Colmenarejo}, Sergio and Hoffman, Matthew W and Denil, Misha and Wang, Ziyu and {De Freitas}, Nando},
  url      = {https://arxiv.org/pdf/1707.03300.pdf},
  keywords = {Deep deterministic policy gradients,control,multi-task,physics},
  title    = {{The Intentional Unintentional Agent: Learning to Solve Many Continuous Control Tasks Simultaneously}},
}

@inproceedings{finn2017maml,
  author    = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1703.03400.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}},
}

@article{Lake,
  author = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  url    = {https://arxiv.org/pdf/1604.00289.pdf},
  title  = {{Building Machines That Learn and Think Like People}},
}

@article{Selsam,
  author = {Selsam, Daniel and Liang, Percy and Dill, David L},
  url    = {https://arxiv.org/pdf/1706.08605.pdf},
  title  = {{Developing Bug-Free Machine Learning Systems With Formal Mathematics}},
}

@inproceedings{schaul2016prioritized,
  author    = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David and Deepmind, Google},
  url       = {https://arxiv.org/pdf/1511.05952.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2016},
  title     = {{Prioritized Experience Replay}},
}

@article{Parisotto,
  author = {Parisotto, Emilio and Ba, Jimmy and Salakhutdinov, Ruslan},
  url    = {https://arxiv.org/pdf/1511.06342.pdf},
  title  = {{ACTOR-MIMIC DEEP MULTITASK AND TRANSFER REINFORCEMENT LEARNING}},
}

@article{Morales,
  author = {Morales, Marco and Rodriguez, Samuel and Thomas, Shawna and Amato, Nancy M},
  url    = {http://rss2017ws.is.tuebingen.mpg.de/abstracts/push-planning-rss17-ws{\_}contact-camera-ready.pdf},
  title  = {{Sampling-Based Planning and Local Reactive Strategies for Environment Manipulation}},
}

@article{Hosseini,
  author = {Hosseini, Khaled},
  url    = {http://english4success.ru/Upload/books/1806.pdf},
  title  = {{A THOUSAND SPLENDID SUNS}},
}

@book{handmaid,
  title = {{The Handmaid's Tale}},
}

@article{VidiadharSurajprasadNaipaul,
  author = {{Vidiadhar Surajprasad Naipaul}, By and {Riaz Islamabad -Pakistan}, Shahid},
  url    = {http://rgi.edu.in/rgi{\_}pdf/A{\_}House{\_}for{\_}Mr{\_}Biswas{\_}By{\_}Vidiadhar{\_}Surajprasad{\_}Naipaul.pdf},
  title  = {{A House for Mr. Biswas}},
}

@article{GabrielGarciaMarquez,
  author = {{Gabriel Garcia Marquez}, By and {Riaz Islamabad -Pakistan}, Shahid},
  url    = {http://202.74.245.22:8080/xmlui/bitstream/handle/123456789/164/Marquez.pdf?sequence=1},
  title  = {{One Hundred Years of Solitude}},
}

@inproceedings{zhang2017tensegrity,
  author    = {Zhang, Marvin and Geng, Xinyang and Bruce, Jonathan and Caluwaerts, Ken and Vespignani, Massimo and Sunspiral, Vytas and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1609.09049.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2017},
  title     = {{Deep Reinforcement Learning for Tensegrity Robot Locomotion}},
}

@inproceedings{bacon2017optioncritic,
  author    = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  url       = {https://arxiv.org/pdf/1609.05140.pdf},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2017},
  title     = {{The Option-Critic Architecture}},
}

@article{Szita,
  author = {Szita, Istvn},
  url    = {http://icml2008.cs.helsinki.fi/papers/490.pdf},
  title  = {{The Many Faces of Optimism: a Unifying Approach}},
}

@article{Singha,
  author = {Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  url    = {https://web.eecs.umich.edu/{~}baveja/Papers/singh-lewis-barto-2009-cogsci.pdf},
  title  = {{Where Do Rewards Come From?}},
}

@article{Kendall,
  author = {Kendall, Alex and Cipolla, Roberto},
  url    = {https://arxiv.org/pdf/1704.00390.pdf},
  title  = {{Geometric loss functions for camera pose regression with deep learning}},
}

@article{Zenke,
  author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  url    = {https://arxiv.org/pdf/1703.04200.pdf},
  title  = {{Continual Learning Through Synaptic Intelligence}},
}

@article{Amodei,
  author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Openai, John Schulman and Man, Dan and Brain, Google},
  url    = {https://arxiv.org/pdf/1606.06565.pdf},
  title  = {{Concrete Problems in AI Safety}},
}

@article{Kirkpatrick,
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  url    = {https://arxiv.org/pdf/1612.00796.pdf},
  title  = {{Overcoming catastrophic forgetting in neural networks}},
}

@article{Goodfellow,
  author = {Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  url    = {https://arxiv.org/pdf/1312.6211.pdf},
  title  = {{An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks}},
}

@inproceedings{ruvolo2013ella,
  author    = {Ruvolo, Paul and Eaton, Eric},
  url       = {http://proceedings.mlr.press/v28/ruvolo13.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2013},
  title     = {{ELLA: An Efficient Lifelong Learning Algorithm}},
}

@inproceedings{williams2017mpc,
  author    = {Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  url       = {http://www.cc.gatech.edu/{~}bboots3/files/InformationTheoreticMPC.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2017},
  title     = {{Information Theoretic MPC for Model-Based Reinforcement Learning}},
}

@article{Montgomery,
  author = {Montgomery, William and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1607.04614.pdf},
  title  = {{Guided Policy Search as Approximate Mirror Descent}},
}

@inproceedings{chebotar2017pilqr,
  author    = {Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1703.03078.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning}},
}

@article{Klambauer,
  author = {Klambauer, Gnter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  url    = {https://arxiv.org/pdf/1706.02515.pdf},
  title  = {{Self-Normalizing Neural Networks}},
}

@article{Watters,
  author = {Watters, Nicholas and Tacchetti, Andrea and Weber, Thophane and Pascanu, Razvan and Battaglia, Peter and Zoran, Daniel},
  url    = {https://arxiv.org/pdf/1706.01433.pdf},
  title  = {{Visual Interaction Networks}},
}

@article{Lowe,
  author = {Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Openai, Igor Mordatch},
  url    = {https://arxiv.org/pdf/1706.02275.pdf},
  title  = {{Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments}},
}

@book{Bender2013,
  author = {Bender, Emily},
  date   = {2013},
  title  = {{Linguistic Fundamentals for Natural Language Processing}},
}

@article{Ehrhardt,
  author = {Ehrhardt, Sbastien and Monszpart, Aron and Vedaldi, Andrea and Mitra, Niloy},
  url    = {https://arxiv.org/pdf/1706.02179.pdf},
  title  = {{Learning to Represent Mechanics via Long-term Extrapolation and Interpolation}},
}

@inproceedings{Battaglia,
  author    = {Battaglia, Peter W and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo and Kavukcuoglu, Koray},
  url       = {https://arxiv.org/pdf/1612.00222.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  title     = {{Interaction Networks for Learning about Objects, Relations and Physics}},
}

@article{Theodorou2010,
  author   = {Theodorou, Evangelos A and Buchli, Jonas and Org, Jonas@buchli and Schaal, Stefan and Edu, Sschaal@usc},
  url      = {http://www.jmlr.org/papers/volume11/theodorou10a/theodorou10a.pdf},
  date     = {2010},
  keywords = {parameterized policies,reinforcement learning,stochastic optimal control},
  pages    = {3137--3181},
  title    = {{A Generalized Path Integral Control Approach to Reinforcement Learning}},
  volume   = {11},
}

@article{Santoro,
  author = {Santoro, Adam and Raposo, David and Barrett, David G T and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy and London, Deepmind},
  url    = {https://arxiv.org/pdf/1706.01427.pdf},
  title  = {{A simple neural network module for relational reasoning}},
}

@article{Egan,
  author = {Egan, Greg},
  url    = {http://ttapress.com/downloads/CrystalNights.pdf},
  title  = {{Crystal Nights}},
}

@article{Schenck,
  author = {Schenck, Connor and Fox, Dieter},
  url    = {https://arxiv.org/pdf/1606.06266.pdf},
  title  = {{Detection and Tracking of Liquids with Fully Convolutional Networks}},
}

@article{Vinyals,
  author = {Vinyals, Oriol and Deepmind, Google and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
  url    = {https://arxiv.org/pdf/1606.04080.pdf},
  title  = {{Matching Networks for One Shot Learning}},
}

@inproceedings{zaremba2015execute,
  author    = {Zaremba, Wojciech and Sutskever, Ilya},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2015},
  title     = {{Learning to Execute}},
}

@inproceedings{sutskever2014seq2seq,
  author    = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2014},
  eprint    = {arXiv:1409.3215v3},
  title     = {{Sequence to Sequence Learning with Neural Networks}},
}

@inproceedings{vinyals2015grammar,
  author    = {Vinyals, Oriol and Kaiser, Lukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
  url       = {https://arxiv.org/pdf/1412.7449.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2015},
  title     = {{Grammar as a Foreign Language}},
}

@inproceedings{riedmiller2005nfq,
  author    = {Riedmiller, Martin},
  url       = {http://ml.informatik.uni-freiburg.de/{\_}media/publications/rieecml05.pdf},
  booktitle = {European Conference on Machine Learning (ECML)},
  date      = {2005},
  title     = {{Neural Fitted Q Iteration -First Experiences with a Data Efficient Neural Reinforcement Learning Method}},
}

@article{Scott2008,
  author = {Scott, J F},
  url    = {http://physics.rutgers.edu/{~}pchandra/physics681/bananas.pdf},
  date   = {2008},
  doi    = {10.1088/0953-8984/20/02/021001},
  pages  = {21001--2},
  title  = {{Ferroelectrics go bananas}},
  volume = {20},
}

@article{Hutchings,
  author = {Hutchings, Michael},
  url    = {https://math.berkeley.edu/{~}hutching/teach/proofs.pdf},
  title  = {{Introduction to mathematical arguments}},
}

@article{Dietterich,
  author = {Dietterich, Thomas and Bishop, Christopher and Heckerman, David and Jordan, Michael and Kearns, Michael and Sutton, Richard S and Barto, Andrew G},
  url    = {http://miruvor.weebly.com/uploads/2/3/9/3/23933635/probabilistic{\_}graphical{\_}models.pdf},
  title  = {{Probabilistic Graphical Models Adaptive Computation and Machine Learning}},
}

@article{Gregora,
  author = {Gregor, Karol and Rezende, Danilo and Deepmind, Daan Wierstra},
  url    = {https://arxiv.org/pdf/1611.07507.pdf},
  title  = {{Variational Intrinsic Control}},
}

@article{Walker,
  author = {Walker, Jacob and Marino, Kenneth and Gupta, Abhinav and Hebert, Martial},
  url    = {https://arxiv.org/pdf/1705.00053.pdf},
  title  = {{The Pose Knows: Video Forecasting by Generating Pose Futures}},
}

@article{Writer,
  author = {Writer, The Anonymous},
  title  = {{KABULIWALA Rabindranath Tagore}},
}

@inproceedings{peng2017actionspace,
  author    = {{Bin Peng}, Xue and van de Panne, Michiel},
  url       = {https://arxiv.org/pdf/1611.01055.pdf},
  booktitle = {ACM SIGGRAPH / Eurographics Symposium on Computer Animation (SCA)},
  date      = {2017},
  title     = {{LEARNING LOCOMOTION SKILLS USING DEEPRL: DOES THE CHOICE OF ACTION SPACE MATTER?}},
}

@misc{Gal,
  author  = {Gal, Yarin},
  url     = {http://mlg.eng.cam.ac.uk/yarin/blog{\_}3d801aa532c1ce.html},
  title   = {{What my deep model doesn't know...}},
  urldate = {2017-04-28},
}

@inproceedings{gandhi2017fly,
  author    = {Gandhi, Dhiraj and Pinto, Lerrel and Gupta, Abhinav},
  url       = {https://arxiv.org/pdf/1704.05588.pdf},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2017},
  title     = {{Learning to Fly by Crashing}},
}

@article{Schulman,
  author = {Schulman, John and Chen, Xi and Abbeel, Pieter},
  url    = {https://arxiv.org/pdf/1704.06440.pdf},
  title  = {{Equivalence Between Policy Gradients and Soft Q-Learning}},
}

@article{Toussaint2012,
  author = {Toussaint, Marc},
  url    = {https://ipvs.informatik.uni-stuttgart.de/mlr/marc/notes/gradientDescent.pdf},
  date   = {2012},
  title  = {{Lecture Notes: Some notes on gradient descent}},
}

@article{Doersch2016,
  author   = {Doersch, Carl},
  url      = {https://arxiv.org/pdf/1606.05908.pdf},
  date     = {2016},
  keywords = {neural networks,structured prediction,unsupervised learning,variational autoencoders},
  title    = {{Tutorial on Variational Autoencoders}},
}

@article{Kang,
  author = {Kang, Daniel and Emmons, John and Abuzaid, Firas and Bailis, Peter and Zaharia, Matei and Infolab, Stanford},
  url    = {https://arxiv.org/pdf/1703.02529.pdf},
  title  = {{Optimizing Deep CNN-Based Queries over Video Streams at Scale}},
}

@article{Chiappa,
  author = {Chiappa, Silvia and Racaniere, Sbastien and Wierstra, Daan and Mohamed, Shakir},
  url    = {https://arxiv.org/pdf/1704.02254.pdf},
  title  = {{Recurrent Environment Simulators}},
}

@article{Li,
  author = {Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
  url    = {https://arxiv.org/pdf/1703.08840.pdf},
  title  = {{Inferring The Latent Structure of Human Decision-Making from Raw Visual Inputs}},
}

@article{Krishnan,
  author = {Krishnan, Rahul G and Shalit, Uri and Sontag, David},
  url    = {https://arxiv.org/pdf/1511.05121.pdf},
  title  = {{Deep Kalman Filters}},
}

@article{Gub,
  author = {Gu, Shixiang and Levine, Sergey and Sutskever, Ilya and Mnih, Andriy},
  url    = {https://arxiv.org/pdf/1511.05176.pdf},
  title  = {{MUPROP: UNBIASED BACKPROPAGATION FOR STOCHASTIC NEURAL NETWORKS}},
}

@article{Gregor,
  author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and {Jimenez Rezende}, Danilo and Wierstra, Daan},
  url    = {https://arxiv.org/pdf/1502.04623.pdf},
  title  = {{DRAW: A Recurrent Neural Network For Image Generation}},
}

@article{Zhu2016,
  author = {Zhu, Richard and Kang, Andrew},
  url    = {http://www.yisongyue.com/courses/cs159/lectures/imitation-learning-3.pdf},
  date   = {2016},
  title  = {{Imitation Learning}},
}

@article{Berthelot,
  author = {Berthelot, David and Schumm, Tom and Metz, Luke},
  url    = {https://arxiv.org/pdf/1703.10717.pdf},
  title  = {{BEGAN: Boundary Equilibrium Generative Adversarial Networks}},
}

@inproceedings{pinto2017robust,
  author    = {Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  url       = {https://arxiv.org/pdf/1703.02702.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Robust Adversarial Reinforcement Learning}},
}

@article{Hanna2017,
  author = {Hanna, Josiah P and Stone, Peter},
  url    = {https://www.cs.utexas.edu/{~}AustinVilla/papers/AAAI17-Hanna.pdf},
  date   = {2017},
  title  = {{Grounded Action Transformation for Robot Learning in Simulation}},
}

@article{Luan,
  author = {Luan, Fujun and Adobe, Sylvain Paris and {Shechtman Adobe}, Eli and Bala, Kavita},
  url    = {https://arxiv.org/pdf/1703.07511.pdf},
  title  = {{Deep Photo Style Transfer}},
}

@inproceedings{kakade2001npg,
  author    = {Kakade, Sham},
  url       = {http:},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2001},
  title     = {{A Natural Policy Gradient}},
}

@inproceedings{stadie2016exploration,
  author    = {Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  url       = {https://arxiv.org/pdf/1507.00814.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2016},
  title     = {{Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models}},
}

@article{Griffiths2014,
  author   = {Griffiths, Thomas L},
  url      = {http://dx.doi.org/10.1016/j.cognition.2014.11.026},
  date     = {2014},
  doi      = {10.1016/j.cognition.2014.11.026},
  keywords = {Big data,Computational modeling,Crowdsourcing},
  title    = {{Manifesto for a new (computational) cognitive revolution}},
}

@article{Britz,
  author = {Britz, Denny and Goldie, Anna and Luong, Minh-Thang and Le, Quoc and Brain, Google},
  url    = {https://arxiv.org/pdf/1703.03906.pdf},
  title  = {{Massive Exploration of Neural Machine Translation Architectures}},
}

@inproceedings{He2017,
  author    = {He, Ji and Chen, Jianshu and He, Xiaodong and Gao, Jianfeng and Li, Lihong and Deng, Li and Ostendorf, Mari},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2017},
  doi       = {10.1051/0004-6361/201527329},
  eprint    = {arXiv:1511.06434v1},
  isbn      = {2004012439},
  issn      = {0004-6361},
  number    = {1999},
  pages     = {1--17},
  title     = {{RL{\^}2: Fast Reinforcement Learning via Slow Reinforcement Learning}},
}

@article{Guo2015,
  author = {Guo, Philip J},
  date   = {2015},
  title  = {{pguo-PhD-grind}},
}

@article{Graves2014,
  author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  url    = {http://arxiv.org/abs/1410.5401},
  date   = {2014},
  doi    = {10.3389/neuro.12.006.2007},
  eprint = {arXiv:1410.5401v2},
  isbn   = {0028-0836},
  issn   = {2041-1723},
  pages  = {1--26},
  title  = {{Neural Turing Machines}},
  volume = {abs/1410.5},
}

@inproceedings{Oord2016,
  author    = {van den Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  url       = {http://arxiv.org/abs/1601.06759},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2016},
  eprint    = {1601.06759},
  isbn      = {9781510829008},
  title     = {{Pixel Recurrent Neural Networks}},
  volume    = {48},
}

@inproceedings{VanHasselt2016,
  author    = {van Hasselt, H and Guez, A and Silver, D},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2016},
  doi       = {10.1016/j.artint.2015.09.002},
  eprint    = {arXiv:1509.06461v1},
  isbn      = {9781577357605},
  issn      = {00043702},
  title     = {{Deep reinforcement learning with double Q-learning}},
}

@article{Bousmalis2016,
  author = {Bousmalis, Konstantinos and Trigeorgis, George and Silberman, Nathan and Krishnan, Dilip and Erhan, Dumitru},
  date   = {2016},
  eprint = {1608.06019},
  number = {Nips},
  title  = {{Domain Separation Networks}},
}

@inproceedings{Finn2016,
  author    = {Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
  url       = {http://arxiv.org/abs/1605.07157},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2016},
  eprint    = {1605.07157},
  title     = {{Unsupervised Learning for Physical Interaction through Video Prediction}},
}

@inproceedings{oord2017vqvae,
  author    = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
  publisher = {Neural information processing systems foundation},
  url       = {http://arxiv.org/abs/1711.00937},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2017-11},
  eprint    = {1711.00937},
  pages     = {6307--6316},
  title     = {{Neural Discrete Representation Learning}},
  volume    = {2017-Decem},
}

@inproceedings{lynch2019play,
  author    = {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  url       = {http://arxiv.org/abs/1903.01973},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-03},
  eprint    = {1903.01973},
  title     = {{Learning Latent Plans from Play}},
}

@book{gibson1979ecologicalapproach,
  author = {Gibson, James},
  date   = {1979},
  title  = {{The Ecological Approach to Visual Perception}},
}

@book{berger2014development,
  author = {Berger, Kathleen},
  date   = {2014},
  title  = {{The Developing Person Through the Life Span}},
}

@article{Fernando2017,
  author = {Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A. and Pritzel, Alexander and Wierstra, Daan},
  date   = {2017},
  eprint = {1701.08734},
  title  = {{PathNet: Evolution Channels Gradient Descent in Super Neural Networks}},
}

@article{Hardt2004,
  author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  date   = {2016},
  eprint = {arXiv:1611.03530v2},
  title  = {{Understanding Deep Learning Requires Rethinking Generalization}},
}

@article{Lia,
  author = {Li, Yuxi},
  title  = {{Deep Reinforcement Learning: An Overview}},
}

@article{Tang2017,
  author = {Tang, Shuai and Jolla, La and Jin, Hailin and Fang, Chen and Wang, Zhaowen and Jose, San},
  date   = {2017},
  pages  = {1--10},
  title  = {{Unsupervised Sentence Representation Learning}},
}

@article{Fukui2016,
  author = {Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
  url    = {http://arxiv.org/abs/1606.01847},
  date   = {2016},
  eprint = {1606.01847},
  isbn   = {978-1-945626-25-8},
  pages  = {9},
  title  = {{Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding}},
}

@article{Kaufmann2016,
  author   = {Kaufmann, Tobias and Ravi, Sujith},
  date     = {2016},
  doi      = {http://dx.doi.org/10.1145/2939672.2939801},
  eprint   = {arXiv:1606.04870v1},
  isbn     = {9781450342322},
  issn     = {0146-4833},
  keywords = {clustering,deep learning,email,lstm,semantics},
  title    = {{Smart Reply : Automated Response Suggestion for Email}},
}

@article{oord2016wavenet,
  author = {van den Oord, Aaron},
  date   = {2016},
  title  = {{Wavenet: A Generative Model for Raw Audio}},
}

@article{Mordatch,
  author = {Mordatch, Igor and Abbeel, Pieter},
  url    = {https://arxiv.org/pdf/1703.04908.pdf},
  title  = {{Emergence of Grounded Compositional Language in Multi-Agent Populations}},
}

@article{Jain,
  author = {Jain, Prateek and Kakade, Sham M and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  url    = {https://arxiv.org/pdf/1610.03774.pdf},
  title  = {{Parallelizing Stochastic Approximation Through Mini-Batching and Tail-Averaging}},
}

@inproceedings{byravan2017se3,
  author    = {Byravan, Arunkumar and Fox, Dieter},
  url       = {https://arxiv.org/pdf/1606.02378.pdf},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2017},
  title     = {{SE3-Nets: Learning Rigid Body Motion using Deep Neural Networks}},
}

@inproceedings{kohl2004quadruped,
  author    = {Kohl, Nate and Stone, Peter},
  url       = {http://www.cs.utexas.edu/{\%}7Bnate,pstone{\%}7D},
  booktitle = {AAAI Conference on Artificial Intelligence},
  date      = {2004},
  pages     = {611--616},
  title     = {{Machine Learning for Fast Quadrupedal Locomotion}},
}

@article{benbrahim1997biped,
  author    = {Benbrahim, Hamid and Franklin, Judy A.},
  publisher = {Elsevier},
  date      = {1997-12},
  doi       = {10.1016/S0921-8890(97)00043-2},
  issn      = {09218890},
  keywords  = {Biped robot,Biped walking,Legged robot,Reinforcement learning,Robot learning},
  number    = {3-4},
  pages     = {283--302},
  title     = {{Biped dynamic walking using reinforcement learning}},
  volume    = {22},
}

@article{nair2020awac,
  author = {Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  url    = {http://arxiv.org/abs/2006.09359},
  date   = {2020-06},
  eprint = {2006.09359},
  title  = {{Accelerating Online Reinforcement Learning with Offline Datasets}},
}

@inproceedings{fujimoto2019off,
  author       = {Fujimoto, Scott and Meger, David and Precup, Doina},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning},
  date         = {2019},
  pages        = {2052--2062},
  title        = {Off-policy deep reinforcement learning without exploration},
}

@incollection{lange2012batch,
  author    = {Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  publisher = {Springer},
  booktitle = {Reinforcement learning},
  date      = {2012},
  pages     = {45--73},
  title     = {Batch reinforcement learning},
}

@article{wu2019behavior,
  author = {Wu, Yifan and Tucker, George and Nachum, Ofir},
  date   = {2019},
  title  = {Behavior regularized offline reinforcement learning},
}

@inproceedings{kostrikov2021offline,
  author       = {Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning},
  date         = {2021},
  pages        = {5774--5783},
  title        = {Offline reinforcement learning with fisher divergence critic regularization},
}

@article{kumar2020conservative,
  author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  date   = {2020},
  title  = {Conservative q-learning for offline reinforcement learning},
}

@article{chen2021decision,
  author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  date   = {2021},
  title  = {Decision transformer: Reinforcement learning via sequence modeling},
}

@article{fujimoto2021minimalist,
  author = {Fujimoto, Scott and Gu, Shixiang Shane},
  date   = {2021},
  title  = {A Minimalist Approach to Offline Reinforcement Learning},
}

@inproceedings{fujimoto2018addressing,
  author       = {Fujimoto, Scott and Hoof, Herke and Meger, David},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning},
  date         = {2018},
  pages        = {1587--1596},
  title        = {Addressing function approximation error in actor-critic methods},
}

@article{wang2020critic,
  author = {Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  date   = {2020},
  title  = {Critic regularized regression},
}

@article{kumar2019stabilizing,
  author = {Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  date   = {2019},
  title  = {Stabilizing off-policy q-learning via bootstrapping error reduction},
}

@article{brandfonbrener2021offline,
  author = {Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  date   = {2021},
  title  = {Offline RL Without Off-Policy Evaluation},
}

@article{koenker2001quantile,
  author = {Koenker, Roger and Hallock, Kevin F},
  date   = {2001},
  number = {4},
  pages  = {143--156},
  title  = {Quantile regression},
  volume = {15},
}

@inproceedings{dabney2018implicit,
  author       = {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Rmi},
  organization = {PMLR},
  booktitle    = {International conference on machine learning},
  date         = {2018},
  pages        = {1096--1105},
  title        = {Implicit quantile networks for distributional reinforcement learning},
}

@inproceedings{dabney2018distributional,
  author    = {Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, Rmi},
  booktitle = {Thirty-Second AAAI Conference on Artificial Intelligence},
  date      = {2018},
  title     = {Distributional reinforcement learning with quantile regression},
}

@misc{zhang2021brac,
  author = {Zhang, Chi and Kuppannagari, Sanmukh Rao and Prasanna, Viktor},
  url    = {https://openreview.net/forum?id=bMCfFepJXM},
  date   = {2021},
  title  = {{\{}BRAC{\}}+: Going Deeper with Behavior Regularized Offline Reinforcement Learning},
}

@article{peng2019advantage,
  author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  date   = {2019},
  title  = {Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
}

@article{siegel2020keep,
  author = {Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  date   = {2020},
  title  = {Keep doing what worked: Behavioral modelling priors for offline reinforcement learning},
}

@inproceedings{kuznetsov2020controlling,
  author       = {Kuznetsov, Arsenii and Shvechikov, Pavel and Grishin, Alexander and Vetrov, Dmitry},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning},
  date         = {2020},
  pages        = {5556--5566},
  title        = {Controlling overestimation bias with truncated mixture of continuous distributional quantile critics},
}

@inproceedings{peters2007reinforcement,
  author    = {Peters, Jan and Schaal, Stefan},
  booktitle = {Proceedings of the 24th international conference on Machine learning},
  date      = {2007},
  pages     = {745--750},
  title     = {Reinforcement learning by reward-weighted regression for operational space control},
}

@inproceedings{wang2018exponentially,
  author    = {Wang, Qing and Xiong, Jiechao and Han, Lei and Sun, Peng and Liu, Han and Zhang, Tong},
  booktitle = {NeurIPS},
  date      = {2018},
  pages     = {6291--6300},
  title     = {Exponentially Weighted Imitation Learning for Batched Historical Data.},
}

@book{sutton2018reinforcement,
  author    = {Sutton, Richard S and Barto, Andrew G},
  publisher = {MIT press},
  date      = {2018},
  title     = {Reinforcement learning: An introduction},
}

@misc{jaxrl,
  author = {Kostrikov, Ilya},
  url    = {https://github.com/ikostrikov/jaxrl},
  date   = {2021-10},
  doi    = {10.5281/zenodo.5535154},
  title  = {{JAXRL: Implementations of Reinforcement Learning algorithms in JAX.}},
}

@software{flax2020github,
  author  = {Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and van {Z}ee, Marc},
  url     = {http://github.com/google/flax},
  date    = {2020},
  title   = {{F}lax: A neural network library and ecosystem for {JAX}},
  version = {0.3.5},
}

@software{jax2018github,
  author  = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and Vander{P}las, Jake and Wanderman-{M}ilne, Skye and Zhang, Qiao},
  url     = {http://github.com/google/jax},
  date    = {2018},
  title   = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  version = {0.2.5},
}

@article{srivastava2014dropout,
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  publisher = {JMLR. org},
  date      = {2014},
  number    = {1},
  pages     = {1929--1958},
  title     = {Dropout: a simple way to prevent neural networks from overfitting},
  volume    = {15},
}

@article{florence2021implicit,
  author = {Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
  date   = {2021},
  title  = {Implicit Behavioral Cloning},
}

@article{gulcehre2021regularized,
  author = {Gulcehre, Caglar and Colmenarejo, Sergio Gmez and Wang, Ziyu and Sygnowski, Jakub and Paine, Thomas and Zolna, Konrad and Chen, Yutian and Hoffman, Matthew and Pascanu, Razvan and de Freitas, Nando},
  date   = {2021},
  title  = {Regularized behavior value estimation},
}

@inproceedings{ghasemipour2021emaq,
  author       = {Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning},
  date         = {2021},
  pages        = {3682--3691},
  title        = {Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
}

@article{fakoor2021continuous,
  author = {Fakoor, Rasool and Mueller, Jonas and Asadi, Kavosh and Chaudhari, Pratik and Smola, Alexander J},
  date   = {2021},
  title  = {Continuous doubly constrained batch reinforcement learning},
}

@article{pong2019skewfit,
  author = {Pong, Vitchyr H. and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  url    = {http://arxiv.org/abs/1903.03698},
  date   = {2019},
  eprint = {1903.03698},
  title  = {Skew-Fit: State-Covering Self-Supervised Reinforcement Learning},
  volume = {abs/1903.03698},
}

@article{adolph2017motor,
  author   = {Adolph, Karen E and Franchak, John M},
  date     = {2017},
  doi      = {10.1002/wcs.1430},
  keywords = {Exploration,Fetal,Infants,Locomotion,Motor Action,Posture,Reaching},
  title    = {The development of motor behavior},
}

@article{Deisenroth2011,
  author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Fox, Dieter},
  url    = {http://www.roboticsproceedings.org/rss07/p08.pdf},
  date   = {2011},
  pages  = {57--64},
  title  = {{Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning}},
  volume = {VII},
}

@article{Silver2016,
  author    = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  url       = {http://dx.doi.org/10.1038/nature16961 http://10.0.4.14/nature16961 http://www.nature.com/nature/journal/v529/n7587/abs/nature16961.html{\#}supplementary-information http://airesearch.com/wp-content/uploads/2016/01/deepmind-mastering-go.pdf},
  date      = {2016-01},
  doi       = {10.1038/nature16961},
  eprint    = {1610.00633},
  isbn      = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
  issn      = {0028-0836},
  number    = {7587},
  pages     = {484--489},
  title     = {{Mastering the game of Go with deep neural networks and tree search}},
  volume    = {529},
}

@inproceedings{Haarnoja2017,
  author    = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1702.08165.pdf},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  title     = {{Reinforcement Learning with Deep Energy-Based Policies}},
}

@inproceedings{giusti2016trails,
  author    = {Giusti, Alessandro and Guzzi, Jrme Jerome and Cirean, Dan C and He, Fang-Lin and Rodrguez, Juan P and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, Jrgen Jurgen and Caro, Gianni Di and Scaramuzza, Davide and Gambardella, Luca M and Ciresan, Dan C. and He, Fang-Lin and Rodriguez, Juan P. and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, Jrgen Jurgen and Caro, Gianni Di and Scaramuzza, Davide and Gambardella, Luca M},
  url       = {http://bit.ly/perceivingtrails. http://ieeexplore.ieee.org/document/7358076/},
  booktitle = {IEEE Robotics and Automation Letters},
  date      = {2016},
  doi       = {10.1109/LRA.2015.2509024},
  isbn      = {9781467380256},
  issn      = {2377-3766},
  keywords  = {Aerial Robotics,Deep Learning,Index Terms Visual-Based Navigation,Ma-chine Learning},
  number    = {2},
  title     = {{A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots}},
  volume    = {1},
}

@article{Konda,
  author   = {Konda, Kishore and Memisevic, Roland},
  url      = {http://www.iro.umontreal.ca/{~}memisevr/pubs/VISAPP2015.pdf},
  keywords = {Convolutional networks,Motion,Stereo,Visual odometry},
  title    = {{Learning visual odometry with a convolutional network}},
}

@article{Coates,
  author = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y},
  url    = {https://www-cs.stanford.edu/people/ang/papers/icml08-LearningForControlFromMultipleDemonstrations.pdf},
  title  = {{Learning for Control from Multiple Demonstrations}},
}

@article{Petersa,
  author = {Peters, Jan and Schaal, Stefan},
  url    = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.6266{\&}rep=rep1{\&}type=pdf},
  title  = {{Reinforcement Learning by Reward-weighted Regression for Operational Space Control}},
}

@article{Bojanowski,
  author = {Bojanowski, Piotr and Joulin, Armand},
  url    = {https://arxiv.org/pdf/1704.05310.pdf},
  title  = {{Unsupervised Learning by Predicting Noise}},
}

@article{Osband,
  author = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Roy, Benjamin Van},
  url    = {https://arxiv.org/pdf/1602.04621.pdf},
  title  = {{Deep Exploration via Bootstrapped DQN}},
}

@article{Deepmind,
  author = {Deepmind, Matteo Hessel and Deepmind, Joseph Modayil and Van, Hado and Deepmind, Hasselt and Deepmind, Tom Schaul and Ostrovski, Georg and Will, Deepmind and Deepmind, Dabney and Horgan, Dan and Bilal, Deepmind and Deepmind, Piot and Azar, Mohammad and David, Deepmind and Deepmind, Silver},
  url    = {https://arxiv.org/pdf/1710.02298.pdf},
  title  = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
}

@article{Byravana,
  author = {Byravan, Arunkumar and Leeb, Felix and Meier, Franziska and Fox, Dieter},
  url    = {https://arxiv.org/pdf/1710.00489.pdf},
  title  = {{SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Planning and Control}},
}

@article{Bengio,
  author   = {Bengio, Emmanuel and Thoma, Valentin and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
  url      = {https://arxiv.org/pdf/1703.07718.pdf},
  keywords = {controllable features Acknowledgements,representation learning},
  title    = {{Independently Controllable Features}},
}

@article{Held,
  author = {Held, David and Geng, Xinyang and Florensa, Carlos and Abbeel, Pieter},
  url    = {https://arxiv.org/pdf/1705.06366.pdf},
  title  = {{Automatic Goal Generation for Reinforcement Learning Agents}},
}

@article{Schulmanb,
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I and Abbeel, Pieter},
  url    = {https://arxiv.org/pdf/1506.02438.pdf},
  title  = {{HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION}},
}

@article{Houthooft2016,
  author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and {De Turck}, Filip and Abbeel, Pieter},
  date   = {2016},
  eprint = {1605.09674},
  issn   = {10495258},
  title  = {{Variational Information Maximizing Exploration}},
}

@article{Nagabandi,
  author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1708.02596.pdf},
  title  = {{Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning}},
}

@article{Murali,
  author = {Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  url    = {https://arxiv.org/pdf/1708.01354.pdf},
  title  = {{CASSL: Curriculum Accelerated Self-Supervised Learning}},
}

@article{Vaswani,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {}ukasz and Polosukhin, Illia},
  url    = {https://arxiv.org/pdf/1706.03762.pdf},
  title  = {{Attention Is All You Need}},
}

@article{Schulmanc,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Openai, Oleg Klimov},
  url    = {https://arxiv.org/pdf/1707.06347.pdf},
  title  = {{Proximal Policy Optimization Algorithms}},
}

@article{Bellemare,
  author = {Bellemare, Marc G and Dabney, Will and Munos, Rmi},
  url    = {https://arxiv.org/pdf/1707.06887.pdf},
  title  = {{A Distributional Perspective on Reinforcement Learning}},
}

@article{Pearl,
  author = {Pearl, Judea},
  url    = {http://bayes.cs.ucla.edu/IJCAI99/ijcai-99.pdf},
  title  = {{REASONING WITH CAUSE AND EFFECT}},
}

@article{Finna,
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1703.03400.pdf},
  title  = {{Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}},
}

@article{Schaul,
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David and Deepmind, Google},
  url    = {https://arxiv.org/pdf/1511.05952.pdf},
  title  = {{PRIORITIZED EXPERIENCE REPLAY}},
}

@article{Narayan,
  author = {Narayan, R K},
  url    = {http://cms.tamindia.com/matrix/images/stories/article-images/may-2014/A{\_}Tiger{\_}for{\_}Malgudi.pdf},
  title  = {{A TIGER FOR MALGUDI PENGUIN BOOKS}},
}

@article{Zhang,
  author = {Zhang, Marvin and Geng, Xinyang and Bruce, Jonathan and Caluwaerts, Ken and Vespignani, Massimo and Sunspiral, Vytas and Abbeel, Pieter and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1609.09049.pdf},
  title  = {{Deep Reinforcement Learning for Tensegrity Robot Locomotion}},
}

@article{Bacon,
  author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  url    = {https://arxiv.org/pdf/1609.05140.pdf},
  title  = {{The Option-Critic Architecture}},
}

@article{Oha,
  author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
  url    = {https://arxiv.org/pdf/1706.05064.pdf},
  title  = {{Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning}},
}

@article{Ruvolo,
  author = {Ruvolo, Paul and Eaton, Eric},
  url    = {http://proceedings.mlr.press/v28/ruvolo13.pdf},
  title  = {{ELLA: An Efficient Lifelong Learning Algorithm}},
}

@article{Williams,
  author = {Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  url    = {http://www.cc.gatech.edu/{~}bboots3/files/InformationTheoreticMPC.pdf},
  title  = {{Information Theoretic MPC for Model-Based Reinforcement Learning}},
}

@article{Chebotar,
  author = {Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  url    = {https://arxiv.org/pdf/1703.03078.pdf},
  title  = {{Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning}},
}

@article{Sutskever2014,
  author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  date   = {2014},
  eprint = {arXiv:1409.3215v3},
  title  = {{Sequence to Sequence Learning with Neural Networks}},
}

@article{Vinyalsa,
  author = {Vinyals, Oriol and Kaiser, Lukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
  url    = {https://arxiv.org/pdf/1412.7449.pdf},
  title  = {{Grammar as a Foreign Language}},
}

@article{Riedmiller,
  author = {Riedmiller, Martin},
  url    = {http://ml.informatik.uni-freiburg.de/{\_}media/publications/rieecml05.pdf},
  title  = {{Neural Fitted Q Iteration -First Experiences with a Data Efficient Neural Reinforcement Learning Method}},
}

@article{BinPeng,
  author = {{Bin Peng}, Xue and van de Panne, Michiel},
  url    = {https://arxiv.org/pdf/1611.01055.pdf},
  title  = {{LEARNING LOCOMOTION SKILLS USING DEEPRL: DOES THE CHOICE OF ACTION SPACE MATTER?}},
}

@article{Gandhi,
  author = {Gandhi, Dhiraj and Pinto, Lerrel and Gupta, Abhinav},
  url    = {https://arxiv.org/pdf/1704.05588.pdf},
  title  = {{Learning to Fly by Crashing}},
}

@article{Pinto,
  author = {Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  url    = {https://arxiv.org/pdf/1703.02702.pdf},
  title  = {{Robust Adversarial Reinforcement Learning}},
}

@article{Kakade,
  author = {Kakade, Sham},
  url    = {http:},
  title  = {{A Natural Policy Gradient}},
}

@article{Oord2001,
  author = {van den Oord, Aaron},
  date   = {2001},
  number = {c},
  title  = {{Wavenet: A Generative Model for Raw Audio}},
}

@article{Byravan,
  author = {Byravan, Arunkumar and Fox, Dieter},
  url    = {https://arxiv.org/pdf/1606.02378.pdf},
  title  = {{SE3-Nets: Learning Rigid Body Motion using Deep Neural Networks}},
}

@inproceedings{pere2018unsupervisedgoalspaces,
  author    = {Pr, Alexandre and Forestier, Sebastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  url       = {https://arxiv.org/pdf/1803.00781.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration}},
}

@article{baranes2012activeimgep,
  author = {Baranes, A and Oudeyer, P-Y},
  url    = {http://dx.doi.org/10.1016/j.robot.2012.05.008},
  date   = {2012},
  doi    = {10.1016/j.robot.2012.05.008},
  eprint = {arXiv:1301.4862v1},
  number = {1},
  pages  = {49--73},
  title  = {{Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots}},
  volume = {61},
}

@inproceedings{srinivas2018upn,
  author    = {Srinivas, Aravind and Jabri, Allan and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  url       = {https://sites.google.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2018},
  eprint    = {arXiv:1804.00645v2},
  title     = {{Universal Planning Networks}},
}

@article{sermanet2017tcn,
  author = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey},
  date   = {2017},
  title  = {Time-Contrastive Networks: Self-Supervised Learning from Video},
}

@article{jonschkowski2017pves,
  author = {Jonschkowski, Rico and Hafner, Roland and Scholz, Jonathan and Riedmiller, Martin},
  date   = {2017},
  title  = {Pves: Position-velocity encoders for unsupervised learning of structured state representations},
}

@article{plappert2018techreport,
  author = {Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and Mcgrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and Kumar, Vikash and Zaremba, Wojciech},
  url    = {http://fetchrobotics.com/},
  date   = {2018},
  eprint = {arXiv:1802.09464v2},
  title  = {{Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research}},
}

@article{vondrickanticipating,
  author = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  title  = {Anticipating Visual Representations from Unlabeled Video},
}

@article{finn2015deep,
  author = {Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  date   = {2015},
  number = {117},
  pages  = {240},
  title  = {Deep Spatial Autoencoders for Visuomotor Learning},
  volume = {117},
}

@article{actionconditioned,
  author = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  date   = {2015},
  title  = {Action-Conditional Video Prediction using Deep Networks in Atari Games},
}

@inproceedings{DBLP:conf/icra/BootsBF14,
  author    = {Boots, Byron and Byravan, Arunkumar and Fox, Dieter},
  url       = {http://dx.doi.org/10.1109/ICRA.2014.6907443},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation, {ICRA} 2014, Hong Kong, China, May 31 - June 7, 2014},
  date      = {2014},
  doi       = {10.1109/ICRA.2014.6907443},
  pages     = {4021--4028},
  title     = {Learning predictive models of a depth camera {\&} manipulator from raw execution traces},
}

@article{levineFDA15,
  author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  date   = {2015},
  title  = {End-to-End Training of Deep Visuomotor Policies},
  volume = {abs/1504.00702},
}

@article{levine2016learning,
  author = {Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},
  date   = {2016},
  title  = {Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection},
}

@article{deisenroth2011blocks,
  author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Fox, Dieter},
  date   = {2011},
  pages  = {57--64},
  title  = {{Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning}},
  volume = {VII},
}

@article{Gu2016a,
  author = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey and Com, Slevine@google},
  url    = {https://arxiv.org/pdf/1603.00748.pdf},
  title  = {{Continuous Deep Q-Learning with Model-based Acceleration}},
}

@article{ross2014aggrevate,
  author = {Ross, Stephane and Bagnell, J Andrew},
  date   = {2014},
  title  = {{Reinforcement and Imitation Learning via Interactive No-Regret Learning}},
}

@inproceedings{agarwal2019optimism,
  author    = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2019},
  eprint    = {1907.04543v2},
  title     = {{An Optimistic Perspective on Offline Reinforcement Learning}},
}

@incollection{lange2012,
  author    = {Lange, Sascha and Gabel, Thomas and Riedmiller, Martin A.},
  editor    = {Wiering, Marco and van Otterlo, Martijn},
  publisher = {Springer},
  url       = {https://doi.org/10.1007/978-3-642-27645-3\_2},
  booktitle = {Reinforcement Learning},
  date      = {2012},
  doi       = {10.1007/978-3-642-27645-3\_2},
  pages     = {45--73},
  series    = {Adaptation, Learning, and Optimization},
  title     = {Batch Reinforcement Learning},
  volume    = {12},
}

@article{balduzzi2015,
  author = {Balduzzi, David and Ghifary, Muhammad},
  url    = {http://arxiv.org/abs/1509.03005},
  date   = {2015},
  eprint = {1509.03005},
  title  = {Compatible Value Gradients for Reinforcement Learning of Continuous Deep Policies},
  volume = {abs/1509.03005},
}

@article{pawel2009,
  author = {Wawrzynski, Pawel},
  url    = {https://doi.org/10.1016/j.neunet.2009.05.011},
  date   = {2009},
  doi    = {10.1016/j.neunet.2009.05.011},
  number = {10},
  pages  = {1484--1497},
  title  = {Real-time reinforcement learning by sequential Actor-Critics and experience replay},
  volume = {22},
}

@incollection{zhang2019,
  author    = {Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  editor    = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and dlch-Buc, F. and Fox, E. and Garnett, R.},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/8474-generalized-off-policy-actor-critic.pdf},
  booktitle = {Advances in Neural Information Processing Systems 32},
  date      = {2019},
  pages     = {2001--2011},
  title     = {Generalized Off-Policy Actor-Critic},
}

@article{peters2008,
  author = {Peters, Jan and Schaal, Stefan},
  url    = {https://doi.org/10.1016/j.neucom.2007.11.026},
  date   = {2008},
  doi    = {10.1016/j.neucom.2007.11.026},
  number = {7-9},
  pages  = {1180--1190},
  title  = {Natural Actor-Critic},
  volume = {71},
}

@article{bhatnagar2009,
  author = {Bhatnagar, Shalabh and Sutton, Richard S. and Ghavamzadeh, Mohammad and Lee, Mark},
  url    = {https://doi.org/10.1016/j.automatica.2009.07.008},
  date   = {2009},
  doi    = {10.1016/j.automatica.2009.07.008},
  number = {11},
  pages  = {2471--2482},
  title  = {Natural actor-critic algorithms},
  volume = {45},
}

@inproceedings{ahn2019robel,
  author    = {Ahn, Michael and Zhu, Henry and Hartikainen, Kristian and Ponte, Hugo and Gupta, Abhishek and Levine, Sergey and Kumar, Vikash},
  publisher = {arXiv},
  url       = {http://arxiv.org/abs/1909.11639},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2019-09},
  eprint    = {1909.11639},
  keywords  = {Benchmarks,Low cost robots,Reinforcement learning},
  title     = {{ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots}},
}

@inproceedings{gupta2021dexterous,
  author    = {Gupta, Abhishek and Yu, Justin and Zhao, Tony and Kumar, Vikash and Xu, Kelvin and Devlin, Thomas and Rovinsky, Aaron and Levine, Sergey},
  booktitle = {International Conference on Robotics and Automation (ICRA)},
  date      = {2021},
  title     = {{Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention}},
}

@article{nachum2019algaedice,
  author    = {Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  publisher = {arXiv},
  url       = {http://arxiv.org/abs/1912.02074},
  date      = {2019-12},
  eprint    = {1912.02074},
  title     = {{AlgaeDICE: Policy Gradient from Arbitrary Experience}},
}

@inproceedings{kumar2020cql,
  author    = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2020},
  eprint    = {2006.04779v1},
  title     = {{Conservative Q-Learning for Offline Reinforcement Learning}},
}

@inproceedings{thomas2016,
  author    = {Thomas, Philip S. and Brunskill, Emma},
  editor    = {Balcan, Maria{-}Florina and Weinberger, Kilian Q.},
  publisher = {JMLR.org},
  url       = {http://proceedings.mlr.press/v48/thomasa16.html},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  date      = {2016},
  pages     = {2139--2148},
  series    = {{JMLR} Workshop and Conference Proceedings},
  title     = {Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning},
  volume    = {48},
}

@inproceedings{wang2018marwil,
  author    = {Wang, Qing and Xiong, Jiechao and Han, Lei and Sun, Peng and Liu, Han and Zhang, Tong},
  booktitle = {Neural Information Processing Systems (NeurIPS)},
  date      = {2018},
  title     = {{Exponentially Weighted Imitation Learning for Batched Historical Data}},
}

@inproceedings{rasool2019p3o,
  author    = {Fakoor, Rasool and Chaudhari, Pratik and Smola, Alexander J},
  url       = {https://github.com/rasoolfa/P3O.},
  booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI)},
  date      = {2019},
  eprint    = {1905.01756v2},
  title     = {{P3O: Policy-on Policy-off Policy Optimization}},
}

@inproceedings{wang2020crr,
  author = {Wang, Ziyu and Novikov, Alexander and Zo{}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and {De Freitas}, Nando},
  date   = {2020},
  eprint = {2006.15134v1},
  title  = {{Critic Regularized Regression}},
}

@article{jaques2019,
  author = {Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, gata and Jones, Noah and Gu, Shixiang and Picard, Rosalind W.},
  url    = {http://arxiv.org/abs/1907.00456},
  date   = {2019},
  eprint = {1907.00456},
  title  = {Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog},
  volume = {abs/1907.00456},
}

@inproceedings{bentivagna2004,
  author    = {Bentivegna, Darrin C. and Cheng, Gordon and Atkeson, Christopher G.},
  editor    = {Dario, Paolo and Chatila, Raja},
  publisher = {Springer},
  url       = {https://doi.org/10.1007/11008941\_59},
  booktitle = {Robotics Research, The Eleventh International Symposium, ISRR, October 19-22, 2003, Siena, Italy},
  date      = {2003},
  doi       = {10.1007/11008941\_59},
  pages     = {551--560},
  series    = {Springer Tracts in Advanced Robotics},
  title     = {Learning from Observation and from Practice Using Behavioral Primitives},
  volume    = {15},
}

@article{mulling2013,
  author = {Mlling, Katharina and Kober, Jens and Kroemer, Oliver and Peters, Jan},
  url    = {https://doi.org/10.1177/0278364912472380},
  date   = {2013},
  doi    = {10.1177/0278364912472380},
  number = {3},
  pages  = {263--279},
  title  = {Learning to select and generalize striking movements in robot table tennis},
  volume = {32},
}

@inproceedings{kormushev2010,
  author    = {Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G.},
  publisher = {IEEE},
  url       = {https://doi.org/10.1109/IROS.2010.5649089},
  booktitle = {2010 {IEEE/RSJ} International Conference on Intelligent Robots and Systems, October 18-22, 2010, Taipei, Taiwan},
  date      = {2010},
  doi       = {10.1109/IROS.2010.5649089},
  pages     = {3232--3237},
  title     = {Robot motor skill coordination with EM-based Reinforcement Learning},
}

@misc{wu2020shaping,
  author = {Wu, Yuchen and Mozifian, Melissa and Shkurti, Florian},
  date   = {2020},
  eprint = {2011.01298},
  title  = {Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations using Generative Models},
}

@inproceedings{taylorsoccer,
  author    = {Taylor, Matthew E. and Suay, Halit Bener and Chernova, Sonia},
  editor    = {Sonenberg, Liz and Stone, Peter and Tumer, Kagan and Yolum, Pinar},
  publisher = {IFAAMAS},
  url       = {http://portal.acm.org/citation.cfm?id=2031705\&CFID=54178199\&CFTOKEN=61392764},
  booktitle = {10th International Conference on Autonomous Agents and Multiagent Systems {(AAMAS} 2011), Taipei, Taiwan, May 2-6, 2011, Volume 1-3},
  date      = {2011},
  pages     = {617--624},
  title     = {Integrating reinforcement learning with human demonstrations of varying ability},
}

@article{zhou2019wtl,
  author = {Zhou, Allan and Jang, Eric and Kappler, Daniel and Herzog, Alexander and Khansari, Mohi and Wohlhart, Paul and Bai, Yunfei and Kalakrishnan, Mrinal and Levine, Sergey and Finn, Chelsea},
  url    = {http://arxiv.org/abs/1906.03352},
  date   = {2019},
  eprint = {1906.03352},
  title  = {Watch, Try, Learn: Meta-Learning from Demonstrations and Reward},
  volume = {abs/1906.03352},
}

@article{gao2018imperfect,
  author = {Gao, Yang and Xu, Huazhe and Lin, Ji and Yu, Fisher and Levine, Sergey and Darrell, Trevor},
  url    = {http://arxiv.org/abs/1802.05313},
  date   = {2018},
  eprint = {1802.05313},
  title  = {Reinforcement Learning from Imperfect Demonstrations},
  volume = {abs/1802.05313},
}

@misc{siegel2020abm,
  author = {Siegel, Noah Y. and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  date   = {2020},
  eprint = {2002.08396},
  title  = {Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
}

@article{MATSUBARA2011493,
  author   = {Matsubara, Takamitsu and Hyon, Sang-Ho and Morimoto, Jun},
  url      = {https://www.sciencedirect.com/science/article/pii/S0893608011000566},
  date     = {2011},
  doi      = {https://doi.org/10.1016/j.neunet.2011.02.004},
  issn     = {0893-6080},
  keywords = {Imitation learning,Movement primitives,Motion styles},
  number   = {5},
  pages    = {493--500},
  title    = {Learning parametric dynamic movement primitives from multiple demonstrations},
  volume   = {24},
}

@article{ghourchian2017existence,
  author    = {Ghourchian, Hamid and Gohari, Amin and Amini, Arash},
  publisher = {IEEE},
  date      = {2017},
  number    = {7},
  pages     = {1469--1472},
  title     = {Existence and continuity of differential entropy for a class of distributions},
  volume    = {21},
}

@inproceedings{zhao2019maximum,
  author    = {Zhao, Rui and Sun, Xudong and Tresp, Volker},
  booktitle = {International Conference on Machine Learning},
  date      = {2019},
  pages     = {7553--7562},
  title     = {Maximum Entropy-Regularized Multi-Goal Reinforcement Learning},
}

@article{rubin1988using,
  author    = {Rubin, Donald B},
  publisher = {Oxford University Press},
  date      = {1988},
  pages     = {395--402},
  title     = {Using the SIR algorithm to simulate posterior distributions},
  volume    = {3},
}

@inproceedings{florensa2018selfsupervised,
  author    = {Florensa, Carlos and Degrave, Jonas and Heess, Nicolas and Springenberg, Jost Tobias and Riedmiller, Martin},
  booktitle = {Workshop on Inference to Control at NeurIPS},
  date      = {2018},
  title     = {{Self-supervised Learning of Image Embedding for Continuous Control}},
}

@article{sutton1999between,
  author    = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
  publisher = {Elsevier},
  date      = {1999},
  number    = {1-2},
  pages     = {181--211},
  title     = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  volume    = {112},
}

@inproceedings{kalakrishnan2011learning,
  author       = {Kalakrishnan, Mrinal and Righetti, Ludovic and Pastor, Peter and Schaal, Stefan},
  organization = {IEEE},
  booktitle    = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  date         = {2011},
  pages        = {4639--4644},
  title        = {Learning force control policies for compliant manipulation},
}

@inproceedings{chebotar2017path,
  author       = {Chebotar, Yevgen and Kalakrishnan, Mrinal and Yahya, Ali and Li, Adrian and Schaal, Stefan and Levine, Sergey},
  organization = {IEEE},
  booktitle    = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2017},
  pages        = {3381--3388},
  title        = {Path integral guided policy search},
}

@article{gupta2018unsupervised,
  author = {Gupta, Abhishek and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  date   = {2018},
  title  = {Unsupervised Meta-Learning for Reinforcement Learning},
  volume = {abs:1806.04640},
}

@book{billingsley2013convergence,
  author    = {Billingsley, Patrick},
  publisher = {John Wiley \& Sons},
  date      = {2013},
  title     = {Convergence of probability measures},
}

@article{haarnoja2018sacapp,
  author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  date   = {2018},
  title  = {Soft Actor-Critic Algorithms and Applications},
  volume = {abs/1812.05905},
}

@inproceedings{barber2004information,
  author    = {Barber, David and Agakov, Felix V},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2004},
  pages     = {201--208},
  title     = {Information maximization in noisy channels: A variational approach},
}

@inproceedings{nielsen2010entropies,
  author       = {Nielsen, Frank and Nock, Richard},
  organization = {IEEE},
  booktitle    = {Image Processing (ICIP), 2010 17th IEEE International Conference on},
  date         = {2010},
  pages        = {3621--3624},
  title        = {Entropies and cross-entropies of exponential families},
}

@article{brafman2002r,
  author = {Brafman, Ronen I and Tennenholtz, Moshe},
  date   = {2002},
  number = Oct,
  pages  = {213--231},
  title  = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  volume = {3},
}

@article{savinov2018episodic,
  author = {Savinov, Nikolay and Raichuk, Anton and Marinier, Raphal and Vincent, Damien and Pollefeys, Marc and Lillicrap, Timothy and Gelly, Sylvain},
  date   = {2018},
  title  = {Episodic curiosity through reachability},
}

@article{osband2018randomized,
  author = {Osband, Ian and Aslanides, John and Cassirer, Albin},
  date   = {2018},
  title  = {Randomized Prior Functions for Deep Reinforcement Learning},
}

@article{hazan2019provably,
  author = {Hazan, Elad and Kakade, Sham M. and Singh, Karan and Soest, Abby Van},
  date   = {2019},
  title  = {Provably Efficient Maximum Entropy Exploration},
}

@inproceedings{burda2018large,
  author    = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  title     = {Large-scale study of curiosity-driven learning},
}

@article{burda2018exploration,
  author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  date   = {2018},
  title  = {Exploration by random network distillation},
}

@inproceedings{ostrovski2017count,
  author    = {Ostrovski, Georg and Bellemare, Marc G and Oord, Aron and Munos, Rmi},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  pages     = {2721--2730},
  title     = {Count-Based Exploration with Neural Density Models},
}

@article{agarwal2018model,
  author = {Agarwal, Arpit and Muelling, Katharina and Fragkiadaki, Katerina},
  date   = {2018},
  title  = {Model Learning for Look-ahead Exploration in Continuous Control},
  volume = {abs/1811.08086},
}

@inproceedings{mohamed2015variational,
  author    = {Mohamed, Shakir and Rezende, Danilo Jimenez},
  booktitle = {Advances in neural information processing systems},
  date      = {2015},
  pages     = {2125--2133},
  title     = {Variational information maximisation for intrinsically motivated reinforcement learning},
}

@article{lindenbaum2018geometry,
  author = {Lindenbaum, Ofir and III, Jay S. Stanley and Wolf, Guy and Krishnaswamy, Smita},
  date   = {2018},
  title  = {Geometry-Based Data Generation},
  volume = {abs/1802.04927},
}

@article{levy2018hierarchical,
  author = {Levy, Andrew and Platt, Robert and Saenko, Kate},
  date   = {2018},
  title  = {Hierarchical Reinforcement Learning with Hindsight},
}

@article{veeriah2018many,
  author = {Veeriah, Vivek and Oh, Junhyuk and Singh, Satinder},
  date   = {2018},
  title  = {Many-goals reinforcement learning},
}

@article{wardefarley2018discern,
  author = {Warde{-}Farley, David and de Wiele, Tom Van and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  date   = {2018},
  title  = {Unsupervised Control Through Non-Parametric Discriminative Rewards},
  volume = {abs/1811.11359},
}

@article{colas2018gep,
  author = {Colas, Cdric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  date   = {2018},
  title  = {GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms},
}

@article{colas2018curious,
  author = {Colas, Cdric and Fournier, Pierre and Sigaud, Olivier and Oudeyer, Pierre{-}Yves},
  date   = {2018},
  title  = {{CURIOUS:} Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning},
  volume = {abs/1810.06284},
}

@incollection{Newell81,
  author    = {Newell, A. and Rosenbloom, P. S.},
  editor    = {Anderson, J. R.},
  publisher = {Lawrence Erlbaum Associates, Inc.},
  booktitle = {Cognitive Skills and Their Acquisition},
  chapter   = {1},
  date      = {1981},
  pages     = {1--51},
  title     = {Mechanisms of Skill Acquisition and the Law of Practice},
}

@article{Samuel59,
  author = {Samuel, A. L.},
  date   = {1959},
  number = {3},
  pages  = {211--229},
  title  = {Some Studies in Machine Learning Using the Game of Checkers},
  volume = {3},
}

@article{gibbs2002choosing,
  author    = {Gibbs, Alison L and Su, Francis Edward},
  publisher = {Wiley Online Library},
  date      = {2002},
  number    = {3},
  pages     = {419--435},
  title     = {On choosing and bounding probability metrics},
  volume    = {70},
}

@inproceedings{Zamir2018,
  author    = {Zamir, Amir R and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
  url       = {http://taskonomy.vision/},
  booktitle = {Computer Vision and Pattern Recognition},
  date      = {2018},
  title     = {{Taskonomy: Disentangling Task Transfer Learning}},
}

@inproceedings{pere2018unsupervised,
  author    = {Pr, Alexandre and Forestier, Sebastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  url       = {https://arxiv.org/pdf/1803.00781.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration}},
}

@inproceedings{Fu2017,
  author    = {Fu, Justin and Co-Reyes, John D and Levine, Sergey},
  url       = {https://papers.nips.cc/paper/6851-ex2-exploration-with-exemplar-models-for-deep-reinforcement-learning.pdf},
  booktitle = {Neural Information Processing Systems (NIPS)},
  date      = {2017},
  title     = {{EX 2 : Exploration with Exemplar Models for Deep Reinforcement Learning}},
}

@article{baranes2012,
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  url    = {http://dx.doi.org/10.1016/j.robot.2012.05.008},
  date   = {2012},
  doi    = {10.1016/j.robot.2012.05.008},
  eprint = {arXiv:1301.4862v1},
  number = {1},
  pages  = {49--73},
  title  = {{Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots}},
  volume = {61},
}

@article{VandenOordDeepMind,
  author = {{van den Oord DeepMind}, Aaron and {Li DeepMind}, Yazhe and {Vinyals DeepMind}, Oriol},
  url    = {https://arxiv.org/pdf/1807.03748.pdf},
  eprint = {arXiv:1807.03748v1},
  title  = {{Representation Learning with Contrastive Predictive Coding}},
}

@article{gregor2016variational,
  author = {Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},
  date   = {2016},
  title  = {Variational intrinsic control},
}

@inproceedings{nickerson01unsupervisedimbalanced,
  author    = {Nickerson, Adam S.},
  booktitle = {In Proceedings of the Eighth International Workshop on AI and Statitsics},
  date      = {2001},
  pages     = {261--265},
  title     = {Using unsupervised learning to guide resampling in imbalanced data sets},
}

@article{douzas18imbalancedsmote,
  author    = {Douzas, Georgios and Bacao, Fernando and Last, Felix},
  booktitle = {Information Sciences},
  date      = {2018-06},
  title     = {Improving Imbalanced Learning Through a Heuristic Oversampling Method Based on K-Means and SMOTE},
  volume    = {465},
}

@inproceedings{gupta2018structuredexploration,
  author    = {Gupta, Abhishek and Mendonca, Russell and Liu, Yuxuan and Abbeel, Pieter and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1802.07245.pdf},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  date      = {2018},
  eprint    = {arXiv:1802.07245v1},
  title     = {{Meta-Reinforcement Learning of Structured Exploration Strategies}},
}

@article{zhao2019rankweight,
  author = {Zhao, Rui and Tresp, Volker},
  url    = {http://arxiv.org/abs/1902.08039},
  date   = {2019},
  eprint = {1902.08039},
  title  = {Curiosity-Driven Experience Prioritization via Density Estimation},
  volume = {abs/1902.08039},
}

@techreport{Colas,
  author = {Colas, Cdric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  url    = {https://arxiv.org/pdf/1810.06284.pdf},
  eprint = {1810.06284v1},
  title  = {{CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning}},
}

@inproceedings{pmlr-v87-kalashnikov18a,
  author    = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and Levine, Sergey},
  publisher = {PMLR},
  booktitle = {Proceedings of The 2nd Conference on Robot Learning},
  date      = {2018-29},
  pages     = {651--673},
  series    = {Proceedings of Machine Learning Research},
  title     = {Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  volume    = {87},
}

@article{PETERS2008682,
  author   = {Peters, Jan and Schaal, Stefan},
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608008000701},
  date     = {2008},
  doi      = {https://doi.org/10.1016/j.neunet.2008.02.003},
  issn     = {0893-6080},
  keywords = {Reinforcement learning,Policy gradient methods,Natural gradients,Natural Actor-Critic,Motor skills,Motor primitives},
  note     = {Robotics and Neuroscience},
  number   = {4},
  pages    = {682--697},
  title    = {Reinforcement learning of motor skills with policy gradients},
  volume   = {21},
}

@article{kober2013reinforcement,
  author    = {Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  publisher = {SAGE Publications Sage UK: London, England},
  date      = {2013},
  number    = {11},
  pages     = {1238--1274},
  title     = {Reinforcement learning in robotics: A survey},
  volume    = {32},
}

@inproceedings{6907421,
  author    = {{Deisenroth}, M. P. and {Englert}, P. and {Peters}, J. and {Fox}, D.},
  booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  date      = {2014-05},
  doi       = {10.1109/ICRA.2014.6907421},
  issn      = {1050-4729},
  keywords  = {feedback;intelligent robots;learning (artificial intelligence);learning systems;nonlinear control systems;nonlinear feedback policy;imitation learning;knowledge transfer;continuous task variations;individual policy training;reinforcement learning;robotics;multitask policy search;Training;Approximation methods;Artificial neural networks;Grippers;Robot kinematics;Cameras},
  pages     = {3876--3881},
  title     = {Multi-task policy search for robotics},
}

@inproceedings{ekvall2004interactive,
  author       = {Ekvall, Staffan and Kragic, Danica},
  organization = {IEEE},
  booktitle    = {IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA'04. 2004},
  date         = {2004},
  pages        = {3519--3524},
  title        = {Interactive grasp learning based on human demonstration},
  volume       = {4},
}

@article{bohg2010learning,
  author    = {Bohg, Jeannette and Kragic, Danica},
  publisher = {Elsevier},
  date      = {2010},
  number    = {4},
  pages     = {362--377},
  title     = {Learning grasping points with shape context},
  volume    = {58},
}

@inproceedings{martinez2014active,
  author       = {Martinez, David and Alenya, Guillem and Jimenez, Pablo and Torras, Carme and Rossmann, Jrgen and Wantia, Nils and Aksoy, Eren Erdal and Haller, Simon and Piater, Justus},
  organization = {IEEE},
  booktitle    = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2014},
  pages        = {5671--5678},
  title        = {Active learning of manipulation sequences},
}

@inproceedings{krainin2011autonomous,
  author       = {Krainin, Michael and Curless, Brian and Fox, Dieter},
  organization = {IEEE},
  booktitle    = {2011 IEEE International Conference on Robotics and Automation},
  date         = {2011},
  pages        = {5031--5037},
  title        = {Autonomous generation of complete 3D object models using next best view manipulation planning},
}

@inproceedings{schenck2017visual,
  author       = {Schenck, Connor and Fox, Dieter},
  organization = {IEEE},
  booktitle    = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2017},
  pages        = {2629--2636},
  title        = {Visual closed-loop control for pouring liquids},
}

@article{florensa2019self,
  author = {Florensa, Carlos and Degrave, Jonas and Heess, Nicolas and Springenberg, Jost Tobias and Riedmiller, Martin},
  date   = {2019},
  title  = {Self-supervised Learning of Image Embedding for Continuous Control},
}

@article{lin2019rlwithoutstate,
  author   = {Lin, Xingyu and {Singh Baweja}, Harjatin and Held, David},
  url      = {https://arxiv.org/pdf/1905.07866.pdf},
  date     = {2019},
  eprint   = {1905.07866v1},
  keywords = {lin2019rlwithoutstate},
  title    = {{Reinforcement Learning without Ground-Truth State}},
}

@article{DBLP:journals/corr/abs-1802-01557,
  author = {Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  url    = {http://arxiv.org/abs/1802.01557},
  date   = {2018},
  eprint = {1802.01557},
  title  = {One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning},
  volume = {abs/1802.01557},
}

@article{DBLP:journals/corr/abs-1804-08606,
  author = {Pathak, Deepak and Mahmoudieh, Parsa and Luo, Guanghao and Agrawal, Pulkit and Chen, Dian and Shentu, Yide and Shelhamer, Evan and Malik, Jitendra and Efros, Alexei A. and Darrell, Trevor},
  url    = {http://arxiv.org/abs/1804.08606},
  date   = {2018},
  eprint = {1804.08606},
  title  = {Zero-Shot Visual Imitation},
  volume = {abs/1804.08606},
}

@article{DBLP:journals/corr/abs-1808-00177,
  author = {OpenAI and Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jzefowicz, Rafal and McGrew, Bob and Pachocki, Jakub W. and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and Schneider, Jonas and Sidor, Szymon and Tobin, Josh and Welinder, Peter and Weng, Lilian and Zaremba, Wojciech},
  url    = {http://arxiv.org/abs/1808.00177},
  date   = {2018},
  eprint = {1808.00177},
  title  = {Learning Dexterous In-Hand Manipulation},
  volume = {abs/1808.00177},
}

@book{lotsizeone,
  author = {Kannengiesser, Udo and Heininger, Richard and Billy, Lubomir and Terpak, Pavol and Neubauer, Matthias and Stary, Chris and Majoe, Dennis and Totter, Alexandra and Bonaldi, David},
  date   = {2017-01},
  doi    = {10.1007/978-3-319-48466-2_4},
  isbn   = {978-3-319-48465-5},
  pages  = {69--111},
  title  = {Lot-Size One Production},
}

@misc{nistbenchmark,
  date         = {2017},
  howpublished = {\url{http://www.rhgm.org/activities/competition_iros2017/}},
  title        = {IROS 2017 Robotic Grasping and Manipulation Competition},
}

@inproceedings{fu2018variationalinversecontrol,
  author    = {Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  url       = {http://papers.nips.cc/paper/8073-variational-inverse-control-with-events-a-general-framework-for-data-driven-reward-definition.pdf},
  booktitle = {NIPS},
  date      = {2018},
  pages     = {8538--8547},
  title     = {Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition},
}

@inproceedings{inoue2017deeprlassembly,
  author    = {Inoue, Tadanobu and De Magistris, Giovanni and Munawar, Asim and Yokoya, Tsuyoshi and Tachibana, Ryuki},
  booktitle = {IROS},
  date      = {2017},
  pages     = {819--825},
  title     = {Deep reinforcement learning for high precision assembly tasks},
}

@inproceedings{luo19variableimpedance,
  author    = {Luo, J and Solowjow, E and Wen, C and Aparicio Ojea, J and Agogino, A and Tamar, A and P, Abbeel},
  booktitle = {ICRA},
  date      = {2019},
  title     = {Reinforcement Learning on Variable Impedance Controller for High-Precision Robotic Assembly},
}

@inproceedings{reinhart17firstperson,
  author    = {Rhinehart, Nicholas and Kitani, Kris M.},
  booktitle = {ICCV},
  date      = {2017},
  title     = {First-Person Activity Forecasting With Online Inverse Reinforcement Learning},
}

@inproceedings{tamar2017hindsightplan,
  author    = {Tamar, Aviv and Thomas, Garrett and Zhang, Tianhao and Levine, Sergey and Abbeel, Pieter},
  booktitle = {ICRA},
  date      = {2017},
  pages     = {336--343},
  title     = {Learning from the hindsight plan Episodic MPC improvement},
}

@inproceedings{eruhimov2011outlet,
  author    = {Eruhimov, Victor and Meeussen, Wim},
  booktitle = {IROS},
  date      = {2011},
  pages     = {2941--2946},
  title     = {Outlet detection and pose estimation for robot continuous operation},
}

@inproceedings{mayton2010plug,
  author = {Mayton, Brian and LeGrand, Louis and Smith, Joshua R.},
  date   = {2010},
  pages  = {715--722},
  title  = {Robot, feed thyself: Plugging in to unmodified electrical outlets by sensing emitted AC electric fields},
}

@inproceedings{roboticgrasping2017iros,
  author    = {Falco, Joe and Sun, Yu and Roa, Maximo},
  editor    = {Sun, Yu and Falco, Joe},
  publisher = {Springer International Publishing},
  booktitle = {Robotic Grasping and Manipulation},
  date      = {2018},
  isbn      = {978-3-319-94568-2},
  pages     = {180--189},
  title     = {Robotic Grasping and Manipulation Competition: Competitor Feedback and Lessons Learned},
}

@inproceedings{rakelly2019efficient,
  author    = {Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle = {International conference on machine learning},
  date      = {2019},
  pages     = {5331--5340},
  title     = {Efficient off-policy meta-reinforcement learning via probabilistic context variables},
}

@inproceedings{barreto2018transfer,
  author    = {Barreto, Andre and Borsa, Diana and Quan, John and Schaul, Tom and Silver, David and Hessel, Matteo and Mankowitz, Daniel and Zidek, Augustin and Munos, Remi},
  booktitle = {International Conference on Machine Learning},
  date      = {2018},
  pages     = {501--510},
  title     = {Transfer in deep reinforcement learning using successor features and generalised policy improvement},
}

@inproceedings{barreto2017successor,
  author    = {Barreto, Andr and Dabney, Will and Munos, Rmi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  booktitle = {Advances in neural information processing systems},
  date      = {2017},
  pages     = {4055--4065},
  title     = {Successor features for transfer in reinforcement learning},
}

@article{kulkarni2016deep,
  author = {Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  date   = {2016},
  title  = {Deep successor reinforcement learning},
}

@article{dayan1993improving,
  author    = {Dayan, Peter},
  publisher = {MIT Press},
  date      = {1993},
  number    = {4},
  pages     = {613--624},
  title     = {Improving generalization for temporal difference learning: The successor representation},
  volume    = {5},
}

@article{borsa2018universal,
  author = {Borsa, Diana and Barreto, Andr and Quan, John and Mankowitz, Daniel and Munos, Rmi and van Hasselt, Hado and Silver, David and Schaul, Tom},
  date   = {2018},
  title  = {Universal successor features approximators},
}

@inproceedings{jabri2019unsupervised,
  author    = {Jabri, Allan and Hsu, Kyle and Gupta, Abhishek and Eysenbach, Ben and Levine, Sergey and Finn, Chelsea},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2019},
  pages     = {10519--10531},
  title     = {Unsupervised curricula for visual meta-reinforcement learning},
}

@inproceedings{gupta2018meta,
  author    = {Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2018},
  pages     = {5302--5311},
  title     = {Meta-reinforcement learning of structured exploration strategies},
}

@article{raffin2019decoupling,
  author = {Raffin, Antonin and Hill, Ashley and Traor, Kalifou Ren and Lesort, Timothe and Daz-Rodrguez, Natalia and Filliat, David},
  date   = {2019},
  title  = {Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics},
}

@inproceedings{ghosh2018learning,
  author    = {Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {Learning actionable representations with goal-conditioned policies},
}

@article{lesort2018state,
  author    = {Lesort, Timothe and Daz-Rodrguez, Natalia and Goudou, Jean-Franois and Filliat, David},
  publisher = {Elsevier},
  date      = {2018},
  pages     = {379--392},
  title     = {State representation learning for control: An overview},
  volume    = {108},
}

@inproceedings{van2016stable,
  author       = {Van Hoof, Herke and Chen, Nutan and Karl, Maximilian and van der Smagt, Patrick and Peters, Jan},
  organization = {IEEE},
  booktitle    = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  date         = {2016},
  pages        = {3928--3934},
  title        = {Stable reinforcement learning with autoencoders for tactile and visual data},
}

@inproceedings{munk2016learning,
  author       = {Munk, Jelle and Kober, Jens and Babuka, Robert},
  organization = {IEEE},
  booktitle    = {2016 IEEE 55th Conference on Decision and Control (CDC)},
  date         = {2016},
  pages        = {4667--4673},
  title        = {Learning state representation for deep actor-critic control},
}

@inproceedings{whitney2020dynamics,
  author    = {Whitney, William and Agarwal, Rajat and Cho, Kyunghyun and Gupta, Abhinav},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2020},
  title     = {Dynamics-aware Embeddings},
}

@article{jonschkowski2015learning,
  author    = {Jonschkowski, Rico and Brock, Oliver},
  publisher = {Springer},
  date      = {2015},
  number    = {3},
  pages     = {407--428},
  title     = {Learning state representations with robotic priors},
  volume    = {39},
}

@article{oord2018representation,
  author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  date   = {2018},
  title  = {Representation learning with contrastive predictive coding},
}

@article{srinivas2020curl,
  author = {Srinivas, Aravind and Laskin, Michael and Abbeel, Pieter},
  date   = {2020},
  title  = {CURL: Contrastive unsupervised representations for reinforcement learning},
}

@article{misra2019kinematic,
  author = {Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  date   = {2019},
  title  = {Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning},
}

@inproceedings{nachum2018near,
  author    = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  title     = {Near-optimal representation learning for hierarchical reinforcement learning},
}

@article{lee2019stochastic,
  author = {Lee, Alex X and Nagabandi, Anusha and Abbeel, Pieter and Levine, Sergey},
  date   = {2019},
  title  = {Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model},
}

@article{hafner2018learning,
  author = {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  date   = {2018},
  title  = {Learning latent dynamics for planning from pixels},
}

@inproceedings{kurutach2018learning,
  author    = {Kurutach, Thanard and Tamar, Aviv and Yang, Ge and Russell, Stuart J and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2018},
  pages     = {8733--8744},
  title     = {Learning plannable representations with causal infogan},
}

@article{gregor2018temporal,
  author = {Gregor, Karol and Papamakarios, George and Besse, Frederic and Buesing, Lars and Weber, Theophane},
  date   = {2018},
  title  = {Temporal difference variational auto-encoder},
}

@article{jaderberg2016reinforcement,
  author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  date   = {2016},
  title  = {Reinforcement learning with unsupervised auxiliary tasks},
}

@inproceedings{fu2018variational,
  author    = {Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2018},
  pages     = {8538--8547},
  title     = {Variational inverse control with events: A general framework for data-driven reward definition},
}

@inproceedings{sermanet2018time,
  author       = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  organization = {IEEE},
  booktitle    = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  date         = {2018},
  pages        = {1134--1141},
  title        = {Time-contrastive networks: Self-supervised learning from video},
}

@inproceedings{edwards2019imitating,
  author    = {Edwards, Ashley and Sahni, Himanshu and Schroecker, Yannick and Isbell, Charles},
  booktitle = {International Conference on Machine Learning},
  date      = {2019},
  pages     = {1755--1763},
  title     = {Imitating latent policies from observation},
}

@article{torabi2018generative,
  author = {Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  date   = {2018},
  title  = {Generative adversarial imitation from observation},
}

@inproceedings{torabi2018behavioral,
  author    = {Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
  date      = {2018},
  pages     = {4950--4957},
  title     = {Behavioral cloning from observation},
}

@article{edwards2016perceptual,
  author = {Edwards, Ashley and Isbell, Charles and Takanishi, Atsuo},
  date   = {2016},
  title  = {Perceptual reward functions},
}

@article{jurgenson2019sub,
  author = {Jurgenson, Tom and Groshev, Edward and Tamar, Aviv},
  date   = {2019},
  title  = {Sub-Goal Trees--a Framework for Goal-Directed Trajectory Prediction and Optimization},
}

@article{dhiman2018floyd,
  author = {Dhiman, Vikas and Banerjee, Shurjo and Siskind, Jeffrey M and Corso, Jason J},
  date   = {2018},
  title  = {Floyd-Warshall Reinforcement Learning: Learning from Past Experiences to Reach New Goals},
}

@inproceedings{laversanne2018curiosity,
  author    = {Laversanne-Finot, Adrien and Pere, Alexandre and Oudeyer, Pierre-Yves},
  booktitle = {Conference on Robot Learning},
  date      = {2018},
  pages     = {487--504},
  title     = {Curiosity Driven Exploration of Learned Disentangled Goal Spaces},
}

@article{nagabandi2018learning,
  author = {Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  date   = {2018},
  title  = {Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
}

@article{xie2018few,
  author = {Xie, Annie and Singh, Avi and Levine, Sergey and Finn, Chelsea},
  date   = {2018},
  title  = {Few-shot goal inference for visuomotor learning and planning},
}

@inproceedings{teh2017distral,
  author    = {Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2017},
  pages     = {4496--4506},
  title     = {Distral: Robust multitask reinforcement learning},
}

@article{edwards2019perceptual,
  author = {Edwards, Ashley D and Isbell, Charles L},
  date   = {2019},
  title  = {Perceptual Values from Observation},
}

@inproceedings{wardefarley2019discern,
  author    = {Warde-Farley, David and {Van De Wiele}, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Volodymyr, {\&} and Deepmind, Mnih},
  url       = {https://arxiv.org/pdf/1811.11359.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2019},
  eprint    = {1811.11359v1},
  isbn      = {1811.11359v1},
  title     = {{Unsupervised Control Through Non-Parametric Discriminative Rewards}},
}

@inproceedings{singh2020cog,
  author    = {Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  booktitle = {CoRL},
  date      = {2020},
  title     = {{COG}: Connecting new skills to past experience with offline reinforcement learning},
}

@article{nair2019hierarchical,
  author = {Nair, Suraj and Finn, Chelsea},
  date   = {2019},
  title  = {Hierarchical foresight: Self-supervised learning of long-horizon tasks via visual subgoal generation},
}

@article{plappert2018multigoal,
  author = {Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and Mcgrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and Kumar, Vikash and Zaremba, Wojciech},
  url    = {http://fetchrobotics.com/},
  date   = {2018},
  eprint = {arXiv:1802.09464v2},
  title  = {{Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research}},
}

@article{finn2017deepvf,
  author = {Finn, Chelsea and Levine, Sergey},
  date   = {2017},
  title  = {Deep Visual Foresight for Planning Robot Motion},
}

@inproceedings{ichter2019robot,
  author = {Ichter, Brian and Pavone, Marco},
  date   = {2019},
  title  = {Robot Motion Planning in Learned Latent Spaces},
}

@article{ichter2018learning,
  author    = {Ichter, Brian and Harrison, James and Pavone, Marco},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  date      = {2018-09},
  doi       = {10.1109/ICRA.2018.8460730},
  isbn      = {9781538630815},
  issn      = {10504729},
  pages     = {7087--7094},
  title     = {Learning Sampling Distributions for Robot Motion Planning},
}

@article{coreyes2018sectar,
  author    = {Co-Reyes, John D. and Liu, Yu Xuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},
  publisher = {International Machine Learning Society (IMLS)},
  date      = {2018},
  isbn      = {9781510867963},
  pages     = {1637--1647},
  title     = {Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings},
  volume    = {3},
}

@inproceedings{florensa2018automatic,
  author    = {Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle = {International conference on machine learning},
  date      = {2018},
  pages     = {1515--1528},
  title     = {Automatic goal generation for reinforcement learning agents},
}

@article{cabi2019scaling,
  author = {Cabi, Serkan and Colmenarejo, Sergio Gmez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  date   = {2019},
  title  = {Scaling data-driven robotics with reward sketching and batch reinforcement learning},
}

@inproceedings{kalashnikov2018scalable,
  author       = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  organization = {PMLR},
  booktitle    = {Conference on Robot Learning},
  date         = {2018},
  pages        = {651--673},
  title        = {Scalable deep reinforcement learning for vision-based robotic manipulation},
}

@article{lu2021awopt,
  author   = {Lu, Yao and Hausman, Karol and Chebotar, Yevgen and Yan, Mengyuan and Jang, Eric and Herzog, Alexander and Xiao, Ted and Irpan, Alex and Khansari, Mohi and Kalashnikov, Dmitry and Levine, Sergey},
  date     = {2021},
  keywords = {Imitation Learning,Reinforcement Learning,Robot Learning},
  title    = {AW-Opt: Learning Robotic Skills with Imitation and Reinforcement at Scale},
}

@article{chebotar2021actionable,
  author = {Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and Levine, Sergey},
  date   = {2021-04},
  title  = {Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
}

@inproceedings{kalashnikov2021mtopt,
  author = {Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  date   = {2021},
  title  = {MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
}

@article{yu2021conservative,
  author = {Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  date   = {2021-12},
  title  = {Conservative Data Sharing for Multi-Task Offline Reinforcement Learning},
  volume = {34},
}

@inproceedings{villaflor2020finetuning,
  author = {Villaflor, Adam and Dolan, John and Schneider, Jeff},
  date   = {2020},
  title  = {Fine-tuning Offline Reinforcement Learning With Model-Based Policy Optimization},
}

@article{meng2021starcraft,
  author = {Meng, Linghui and Wen, Muning and Yang, Yaodong and Le, Chenyang and Li, Xiyun and Zhang, Weinan and Wen, Ying and Zhang, Haifeng and Wang, Jun and Xu, Bo},
  date   = {2021},
  title  = {Offline Pre-trained Multi-Agent Decision Transformer: One Big Sequence Model Tackles All SMAC Tasks},
}

@article{lee2021finetuning,
  author   = {Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  date     = {2021},
  keywords = {Deep Reinforcement Learning,Fine-tuning,Offline RL},
  title    = {Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble},
}

@article{koenig2002dstarlite,
  author = {Koenig, Sven and Likhachev, Maxim},
  date   = {2002},
  title  = {D* Lite},
}

@article{kalakrishnan2011stomp,
  author = {Kalakrishnan, Mrinal and Chitta, Sachin and Theodorou, Evangelos and Pastor, Peter and Schaal, Stefan},
  date   = {2011},
  doi    = {10.1109/ICRA.2011.5980280},
  isbn   = {9781612843865},
  issn   = {10504729},
  pages  = {4569--4574},
  title  = {STOMP: Stochastic trajectory optimization for motion planning},
}

@article{karaman2011rrtstar,
  author    = {Karaman, Sertac and Frazzoli, Emilio},
  publisher = {Sage UK: London, England},
  date      = {2011-06},
  doi       = {10.1177/0278364911406761},
  issn      = {02783649},
  issue     = {7},
  keywords  = {Motion planning,optimal path planning,random geometric graphs,sampling-based algorithms},
  pages     = {846--894},
  title     = {Sampling-based algorithms for optimal motion planning:},
  volume    = {30},
}

@article{zucker2013chomp,
  author = {Zucker, Matt and Ratliff, Nathan and Dragan, Anca D and Pivtoraiko, Mihail and Klingensmith, Matthew and Dellin, Christopher M and Bagnell, J Andrew and Srinivasa, Siddhartha S},
  date   = {2013},
  title  = {CHOMP: Covariant Hamiltonian Optimization for Motion Planning},
}

@article{fikes1971strips,
  author = {Fikes, Richard E and Nilsson, Nils J},
  date   = {1971},
  title  = {STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving},
}

@inproceedings{NIPS2016_6591,
  author    = {Houthooft, Rein and Chen, Xi and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2016},
  pages     = {1109--1117},
  title     = {VIME: Variational Information Maximizing Exploration},
}

@inproceedings{pathakICMl17curiosity,
  author    = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  booktitle = {International Conference on Machine Learning},
  date      = {2017},
  title     = {Curiosity-driven Exploration by Self-supervised Prediction},
}

@inproceedings{conti2018improving,
  author    = {Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth and Clune, Jeff},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2018},
  pages     = {5027--5038},
  title     = {Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents},
}

@inproceedings{maillard2014hard,
  author    = {Maillard, Odalric-Ambrym and Mann, Timothy A and Mannor, Shie},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2014},
  title     = {How hard is my MDP?" The distribution-norm to the rescue"},
}

@article{Gupta2021ResetFreeRL,
  author = {Gupta, Abhishek and Yu, Justin and Zhao, Tony and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  date   = {2021},
  pages  = {6664--6671},
  title  = {Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
}

@article{Lu2021ResetFreeLL,
  author = {Lu, Kevin and Grover, Aditya and Abbeel, P. and Mordatch, Igor},
  date   = {2021},
  title  = {Reset-Free Lifelong Learning with Skill-Space Planning},
  volume = {abs/2012.03548},
}

@article{kostrikov2021iql,
  author = {Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  date   = {2021},
  title  = {Offline reinforcement learning with implicit q-learning},
}

@inproceedings{Kaelbling1993LearningTA,
  author    = {Kaelbling, Leslie Pack},
  booktitle = {IJCAI},
  date      = {1993},
  title     = {Learning to Achieve Goals},
}

@inproceedings{Schaul2015UniversalVF,
  author    = {Schaul, Tom and Horgan, Dan and Gregor, Karol and Silver, David},
  booktitle = {ICML},
  date      = {2015},
  title     = {Universal Value Function Approximators},
}

@article{Eysenbach2021CLearningLT,
  author = {Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  date   = {2021},
  title  = {C-Learning: Learning to Achieve Goals via Recursive Classification},
  volume = {abs/2011.08909},
}

@inproceedings{Andrychowicz2017HindsightER,
  author    = {Andrychowicz, Marcin and Crow, Dwight and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Joshua and Abbeel, P. and Zaremba, Wojciech},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2017},
  title     = {Hindsight Experience Replay},
}

@article{Pong2020SkewFitSS,
  author = {Pong, Vitchyr H. and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  date   = {2020},
  title  = {Skew-Fit: State-Covering Self-Supervised Reinforcement Learning},
  volume = {abs/1903.03698},
}

@inproceedings{Fang2019CurriculumguidedHE,
  author    = {Fang, Meng and Zhou, Tianyi and Du, Yali and Han, Lei and Zhang, Zhengyou},
  booktitle = {NeurIPS},
  date      = {2019},
  title     = {Curriculum-guided Hindsight Experience Replay},
}

@inproceedings{Ding2019GoalconditionedIL,
  author    = {Ding, Yiming and Florensa, Carlos and Phielipp, Mariano and Abbeel, P.},
  booktitle = {NeurIPS},
  date      = {2019},
  title     = {Goal-conditioned Imitation Learning},
}

@inproceedings{Gupta2019RelayPL,
  author    = {Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  booktitle = {CoRL},
  date      = {2019},
  title     = {Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
}

@inproceedings{Sun2019PolicyCW,
  author    = {Sun, Hao and Li, Zhizhong and Liu, Xiaotong and Lin, Dahua and Zhou, Bolei},
  booktitle = {NeurIPS},
  date      = {2019},
  title     = {Policy Continuation with Hindsight Inverse Dynamics},
}

@article{Eysenbach2020RewritingHW,
  author = {Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan},
  date   = {2020},
  title  = {Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement},
  volume = {abs/2002.11089},
}

@article{Ghosh2021LearningTR,
  author = {Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  date   = {2021},
  title  = {Learning to Reach Goals via Iterated Supervised Learning},
}

@inproceedings{Nasiriany2019PlanningWG,
  author    = {Nasiriany, Soroush and Pong, Vitchyr H. and Lin, Steven and Levine, Sergey},
  booktitle = {NeurIPS},
  date      = {2019},
  title     = {Planning with Goal-Conditioned Policies},
}

@article{Charlesworth2020PlanGANMP,
  author = {Charlesworth, Henry and Montana, G.},
  date   = {2020},
  title  = {PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals},
  volume = {abs/2006.00900},
}

@article{fang2019cavin,
  author = {Fang, Kuan and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li},
  date   = {2019},
  title  = {Dynamics Learning with Cascaded Variational Inference for Multi-Step Manipulation},
}

@inproceedings{Eysenbach2019SearchOT,
  author    = {Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  booktitle = {NeurIPS},
  date      = {2019},
  title     = {Search on the Replay Buffer: Bridging Planning and Reinforcement Learning},
}

@article{Pertsch2020LongHorizonVP,
  author = {Pertsch, Karl and Rybkin, Oleh and Ebert, Frederik and Finn, Chelsea and Jayaraman, Dinesh and Levine, Sergey},
  date   = {2020},
  title  = {Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors},
  volume = {abs/2006.13205},
}

@inproceedings{Sharma2021AutonomousRL,
  author = {Sharma, Archit and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  date   = {2021},
  title  = {Autonomous Reinforcement Learning via Subgoal Curricula},
}

@article{Zhang2021CPlanningAA,
  author = {Zhang, Tianjun and Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey and Gonzalez, Joseph E.},
  date   = {2021},
  title  = {C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks},
  volume = {abs/2110.12080},
}

@inproceedings{Nair2019ContextualIG,
  author    = {Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr H. and Berseth, Glen and Levine, Sergey},
  booktitle = {CoRL},
  date      = {2019},
  title     = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
}

@article{Khazatsky2021WhatCI,
  author = {Khazatsky, Alexander and Nair, Ashvin and Jing, Dan and Levine, Sergey},
  date   = {2021},
  pages  = {14291--14297},
  title  = {What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
}

@inproceedings{Oord2017NeuralDR,
  author    = {van den Oord, Aron and Vinyals, Oriol and Kavukcuoglu, Koray},
  booktitle = {NeurIPS},
  date      = {2017},
  title     = {Neural Discrete Representation Learning},
}

@inproceedings{ChaneSane2021GoalConditionedRL,
  author    = {Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  booktitle = {ICML},
  date      = {2021},
  title     = {Goal-Conditioned Reinforcement Learning with Imagined Subgoals},
}

@article{Lu2019AdaptiveOP,
  author = {Lu, Kevin and Mordatch, Igor and Abbeel, P.},
  date   = {2019},
  title  = {Adaptive Online Planning for Continual Lifelong Learning},
  volume = {abs/1912.01188},
}

@article{CoReyes2020EcologicalRL,
  author = {Co-Reyes, John D. and Sanjeev, Suvansh and Berseth, Glen and Gupta, Abhishek and Levine, Sergey},
  date   = {2020},
  title  = {Ecological Reinforcement Learning},
  volume = {abs/2006.12478},
}

@misc{zhu2020robosuite,
  author = {Zhu, Yuke and Wong, Josiah and Mandlekar, Ajay and Martn-Martn, Roberto},
  date   = {2020},
  eprint = {2009.12293},
  title  = {robosuite: A Modular Simulation Framework and Benchmark for Robot Learning},
}

@article{Gandhi2021RobustMP,
  author = {Gandhi, Manan S. and Vlahov, Bogdan and Gibson, Jason and Williams, Grady and Theodorou, Evangelos A.},
  date   = {2021},
  pages  = {1423--1430},
  title  = {Robust Model Predictive Path Integral Control: Analysis and Performance Guarantees},
  volume = {6},
}

@inproceedings{Ronneberger2015UNetCN,
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle = {MICCAI},
  date      = {2015},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
}

@inproceedings{pong2022smac,
  author = {Pong, Vitchyr H. and Nair, Ashvin and Smith, Laura and Huang, Catherine and Levine, Sergey},
  date   = {2022},
  title  = {Offline Meta-Reinforcement Learning with Online Self-Supervision},
}

@inproceedings{zhu2020ingredients,
  author = {Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  url    = {https://sites.google.com/view/realworld-rl/.},
  date   = {2020},
  title  = {The Ingredients of Real-World Robotic Reinforcement Learning},
}

@inproceedings{singh2020parrot,
  author = {Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  url    = {https://sites.google.com/view/parrot-rl.},
  date   = {2020},
  title  = {Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
}

@inproceedings{nguyen2021tpc,
  author = {Nguyen, Tung and Shu, Rui and Pham, Tuan and Bui, Hung and Ermon, Stefano},
  url    = {https://arxiv.org/abs/2106.07156v1},
  date   = {2021-06},
  doi    = {10.48550/arxiv.2106.07156},
  title  = {Temporal Predictive Coding For Model-Based Planning In Latent Space},
}

@inproceedings{schwarzer2020spr,
  author = {Schwarzer, Max and Anand, Ankesh and Goel, Rishab and Hjelm, R Devon and Courville, Aaron and Bachman, Philip},
  url    = {https://arxiv.org/abs/2007.05929v4},
  date   = {2020-07},
  doi    = {10.48550/arxiv.2007.05929},
  title  = {Data-Efficient Reinforcement Learning with Self-Predictive Representations},
}

@inproceedings{stooke2021decoupling,
  author = {Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
  url    = {http://proceedings.mlr.press/v139/stooke21a.html},
  date   = {2021},
  title  = {Decoupling Representation Learning from Reinforcement Learning},
}

@inproceedings{zhao2020meld,
  author   = {Zhao, Tony Z. and Nagabandi, Anusha and Rakelly, Kate and Finn, Chelsea and Levine, Sergey},
  url      = {https://arxiv.org/abs/2010.13957v2},
  date     = {2020-10},
  doi      = {10.48550/arxiv.2010.13957},
  keywords = {meta-learning,reinforcement learning,robotic manipulation},
  title    = {MELD: Meta-Reinforcement Learning from Images via Latent State Models},
}

@inproceedings{zhao2022insertion,
  author = {Zhao, Tony Z. and Luo, Jianlan and Sushkov, Oleg and Pevceviciute, Rugile and Heess, Nicolas and Scholz, Jon and Schaal, Stefan and Levine, Sergey},
  url    = {https://arxiv.org/abs/2110.04276v3},
  date   = {2022-10},
  doi    = {10.48550/arxiv.2110.04276},
  title  = {Offline Meta-Reinforcement Learning for Industrial Insertion},
}

@inproceedings{ferns2004bisimulation,
  author    = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  location  = {Banff, Canada},
  url       = {http://dl.acm.org/citation.cfm?id=1036843.1036863},
  booktitle = {Uncertainty in Artificial Intelligence (UAI)},
  date      = {2004},
  isbn      = {0-9749039-0-6},
  pages     = {162--169},
  title     = {Metrics for Finite {Markov} Decision Processes},
}

@inproceedings{jonschkowski2017pve,
  author = {Jonschkowski, Rico and Hafner, Roland and Scholz, Jonathan and Riedmiller, Martin},
  url    = {https://arxiv.org/abs/1705.09805v3},
  date   = {2017-05},
  isbn   = {1705.09805v3},
  title  = {PVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations},
}

@inproceedings{zhang2021dbc,
  author    = {Zhang, Amy and McAllister, Rowan Thomas and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  url       = {https://openreview.net/forum?id=-2FCwDKRREu},
  booktitle = {International Conference on Learning Representations},
  date      = {2021},
  title     = {Learning Invariant Representations for Reinforcement Learning without Reconstruction},
}

@inproceedings{laskin2020curl,
  author       = {Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  organization = {PMLR},
  booktitle    = {International Conference on Machine Learning (ICML)},
  date         = {2020},
  pages        = {5639--5650},
  title        = {{CURL}: Contrastive unsupervised representations for reinforcement learning},
}

@inproceedings{castro20bisimulation,
  author    = {Castro, Pablo Samuel},
  booktitle = {Association for the Advancement of Artificial Intelligence (AAAI)},
  date      = {2020},
  title     = {Scalable methods for computing state similarity in deterministic {M}arkov Decision Processes},
}

@article{ebert2021bridge,
  author = {Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  url    = {http://arxiv.org/abs/2109.13396},
  date   = {2021-09},
  title  = {Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
}

@article{james218simtosim,
  author = {James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  url    = {http://arxiv.org/abs/1812.07252},
  date   = {2018-12},
  title  = {Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks},
}

@article{thota2021contrastiveda,
  author = {Thota, Mamatha and Leontidis, Georgios},
  url    = {http://arxiv.org/abs/2103.15566},
  date   = {2021-03},
  title  = {Contrastive Domain Adaptation},
}

@inproceedings{li2018domainadversarial,
  author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C},
  date   = {2018},
  title  = {Domain Generalization with Adversarial Feature Learning},
}

@inproceedings{li2018domaingeneralization,
  author   = {Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
  date     = {2018},
  keywords = {Adversarial networks,Domain generalization,Domain in-variant representation},
  title    = {Deep Domain Generalization via Conditional Invariant Adversarial Networks},
}

@article{ganin2016domainadversarial,
  author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Franois and Marchand, Mario and Lempitsky, Victor},
  url    = {http://arxiv.org/abs/1505.07818},
  date   = {2016-05},
  title  = {Domain-Adversarial Training of Neural Networks},
}

@article{tzeng2014domainconfusion,
  author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  url    = {http://arxiv.org/abs/1412.3474},
  date   = {2014-12},
  title  = {Deep Domain Confusion: Maximizing for Domain Invariance},
}

@article{gupta2018homes,
  author = {Gupta, Abhinav and Murali, Adithyavairavan and Gandhi, Dhiraj and Pinto, Lerrel},
  url    = {http://arxiv.org/abs/1807.07049},
  date   = {2018-07},
  title  = {Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias},
}

@inproceedings{sun2016coral,
  author = {Sun, Baochen and Saenko, Kate},
  url    = {http://arxiv.org/abs/1607.01719},
  date   = {2016-07},
  title  = {Deep CORAL: Correlation Alignment for Deep Domain Adaptation},
}

@inproceedings{long2015adaptation,
  author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
  url    = {http://arxiv.org/abs/1502.02791},
  date   = {2015-02},
  title  = {Learning Transferable Features with Deep Adaptation Networks},
}

@inproceedings{koh2021wilds,
  author    = {Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and Lee, Tony and David, Etienne and Stavness, Ian and Guo, Wei and Earnshaw, Berton and Haque, Imran and Beery, Sara M and Leskovec, Jure and Kundaje, Anshul and Pierson, Emma and Levine, Sergey and Finn, Chelsea and Liang, Percy},
  editor    = {Meila, Marina and Zhang, Tong},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v139/koh21a.html},
  date      = {2021-06},
  pages     = {5637--5664},
  title     = {WILDS: A Benchmark of in-the-Wild Distribution Shifts},
  volume    = {139},
}

@article{spector2021insertionnet,
  author    = {Spector, Oren and Castro, Dotan Di},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  date      = {2021-07},
  doi       = {10.1109/LRA.2021.3076971},
  keywords  = {Machine learning for robot control,assembly,deep learning methods},
  number    = {3},
  pages     = {5509--5516},
  title     = {{InsertionNet - A Scalable Solution for Insertion}},
  volume    = {6},
}

@inproceedings{lian2021insertionbenchmark,
  author    = {Lian, Wenzhao and Kelch, Tim and Holz, Dirk and Norton, Adam and Schaal, Stefan},
  booktitle = {IEEE International Conference on Intelligent Robots and Systems (IROS)},
  date      = {2021},
  eprint    = {2103.05140v1},
  title     = {{Benchmarking Off-The-Shelf Solutions to Robotic Assembly Tasks}},
}

@inproceedings{luo2021insertion,
  author    = {Luo, Jianlan and Sushkov, Oleg and Pevceviciute, Rugile and Lian, Wenzhao and Su, Chang and Vecerik, Mel and Ye, Ning and Schaal, Stefan and Scholz, Jon},
  url       = {https://arxiv.org/abs/2103.11512v3},
  booktitle = {Robotics: Science and Systems (RSS)},
  date      = {2021-03},
  eprint    = {2103.11512},
  title     = {{Robust Multi-Modal Policies for Industrial Assembly via Reinforcement Learning and Demonstrations: A Large-Scale Study}},
}

@article{Aytar,
  author = {Aytar, Yusuf and Pfaff, Tobias and Budden, David and {Le Paine}, Tom and Wang, Ziyu and {De Freitas}, Nando},
  eprint = {1805.11592v2},
  title  = {{Playing hard exploration games by watching YouTube}},
}

@article{Chen,
  author = {Chen, Xinyue and Wang, Che and Zhou, Zijian and Ross, Keith},
  url    = {https://github.com/watchernyu/REDQ},
  eprint = {2101.05982v2},
  title  = {{RANDOMIZED ENSEMBLED DOUBLE Q-LEARNING: LEARNING FAST WITHOUT A MODEL}},
}

@article{Chena,
  author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  url    = {https://sites.google.com/berkeley.edu/decision-transformer},
  eprint = {2106.01345v2},
  title  = {{Decision Transformer: Reinforcement Learning via Sequence Modeling}},
}

@article{Abdolmaleki,
  author = {Abdolmaleki, Abbas and Huang, Sandy H and Vezzani, Giulia and Shahriari, Bobak and Springenberg, Tobias and Mishra, Shruti and Tb, Dhruva and Byravan, Arunkumar and Bousmalis, Konstantinos and Gyrgy, Andrs and Szepesvri, Csaba and Hadsell, Raia and Heess, Nicolas and Riedmiller, Martin and London, Deepmind},
  eprint = {2106.08199v1},
  title  = {{On Multi-objective Policy Optimization as a Tool for Reinforcement Learning}},
}

@article{Cang,
  author = {Cang, Catherine and Rajeswaran, Aravind and Abbeel, Pieter and Laskin, Michael},
  eprint = {2106.09119v2},
  isbn   = {2106.09119v2},
  title  = {{Behavioral Priors and Dynamics Models: Improving Performance and Domain Transfer in Offline RL}},
}

@article{Hafner2020,
  author = {Hafner, Danijar and Brain, Google and Deepmind, Pedro A Ortega and Ba, Jimmy and Parr, Thomas and Friston, Karl and Deepmind, Nicolas Heess},
  date   = {2020},
  eprint = {2009.01791v2},
  title  = {{Action and Perception as Divergence Minimization}},
}

@inproceedings{khazatsky2021val,
  author    = {Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  url       = {https://arxiv.org/abs/2106.00671v2},
  booktitle = {International Conference on Robotics and Automation (ICRA)},
  date      = {2021-06},
  eprint    = {2106.00671},
  title     = {{What Can I Do Here? Learning New Skills by Imagining Visual Affordances}},
}

@inproceedings{sun2020testtimetrain,
  author    = {Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei A and Hardt, Moritz},
  url       = {https://test-time-training.github.io/.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2020},
  eprint    = {1909.13231v3},
  title     = {{Test-Time Training with Self-Supervision for Generalization under Distribution Shifts}},
}

@techreport{Geva,
  author = {Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  eprint = {2012.14913v1},
  title  = {{Transformer Feed-Forward Layers Are Key-Value Memories}},
}

@article{Barreto2020,
  author    = {Barreto, Andr and Hou, Shaobo and Borsa, Diana and Silver, David and Precup, Doina},
  publisher = {National Academy of Sciences},
  url       = {http://www.nasonline.org/science-of-deep-},
  date      = {2020-12},
  doi       = {10.1073/pnas.1907370117},
  issn      = {10916490},
  keywords  = {Artificial intelligence,Generalized policy evaluation,Generalized policy improvement,Reinforcement learning,Successor features},
  number    = {48},
  pages     = {30079--30087},
  title     = {{Fast reinforcement learning with generalized policy updates}},
  volume    = {117},
}

@techreport{Simeonov,
  author   = {Simeonov, Anthony and Du, Yilun and Kim, Beomjoon and Hogan, Francois R and Tenenbaum, Joshua and Agrawal, Pulkit and Rodriguez, Alberto},
  url      = {https://anthonysimeonov.github.io/rpo-planning-framework/.},
  eprint   = {2011.08177v1},
  keywords = {Learning,Manipulation,Planning},
  title    = {{A Long Horizon Planning Framework for Manipulating Rigid Pointcloud Objects}},
}

@techreport{Raziei,
  author   = {Raziei, Zohreh and Moghaddam, Mohsen},
  eprint   = {2012.01934v1},
  keywords = {Actor-critic architecture,Deep reinforcement learning,Meta learning,Meta-World,Modularization,Multi-task learning},
  title    = {{Adaptable Automation with Modular Deep Reinforcement Learning and Policy Transfer}},
}

@techreport{batra2020rearrangement,
  author = {Batra, Dhruv and Chang, Angel and Chernova, Sonia and Davison, Andrew and Deng, Jia and Koltun, Vladlen and Levine, Sergey and Malik, Jitendra and Mordatch, Igor and Mottaghi, Roozbeh and Savva, Manolis and Su, Hao},
  date   = {2020},
  eprint = {2011.01975v1},
  title  = {{Rearrangement: A Challenge for Embodied AI}},
}

@techreport{Nachum2019,
  author = {Nachum, Ofir and Dai, Bo},
  date   = {2019},
  eprint = {2001.01866v2},
  title  = {{Reinforcement Learning via Fenchel-Rockafellar Duality}},
}

@techreport{Gleave,
  author = {Gleave, Adam and Habryka, Oliver},
  eprint = {1805.08882v2},
  title  = {{Multi-task Maximum Causal Entropy Inverse Reinforcement Learning}},
}

@inproceedings{Faccio,
  author = {Faccio, Francesco and Kirsch, Louis and Schmidhuber, Jurgen},
  date   = {2020},
  eprint = {2006.09226v2},
  title  = {{Parameter-Based Value Functions}},
}

@inproceedings{chen2019surrogate,
  author    = {Chen, Minmin and Gummadi, Ramki and Harris, Chris and Schuurmans, Dale},
  url       = {https://www.cs.ualberta.ca/{~}dale/neurips19/supplement},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  date      = {2019},
  title     = {{Surrogate Objectives for Batch Policy Optimization in One-step Decision Making}},
}

@misc{Schoettler2020,
  author    = {Schoettler, G. and Nair, A. and Ojea, J.A. and Levine, S. and Solowjow, E.},
  booktitle = {arXiv},
  date      = {2020},
  title     = {{Meta-reinforcement learning for robotic industrial insertion tasks}},
}

@misc{Nair2020,
  author    = {Nair, A. and Gupta, A. and Dalal, M. and Levine, S.},
  booktitle = {arXiv},
  date      = {2020},
  title     = {{Accelerating Online Reinforcement Learning with Offline Datasets}},
}

@misc{Schoettler2019,
  author    = {Schoettler, G. and Nair, A. and Luo, J. and Bahl, S. and Ojea, J.A. and Solowjow, E. and Levine, S.},
  booktitle = {arXiv},
  date      = {2019},
  title     = {{Deep reinforcement learning for industrial insertion tasks with visual inputs and natural rewards}},
}

@techreport{Tedrake,
  author = {Tedrake, Russ and Zhang, Teresa Weirui and Seung, H Sebastian},
  title  = {{Stochastic Policy Gradient Reinforcement Learning on a Simple 3D Biped}},
}

@misc{Nair2017,
  author    = {Nair, A. and McGrew, B. and Andrychowicz, M. and Zaremba, W. and Abbeel, P.},
  booktitle = {arXiv},
  date      = {2017},
  title     = {{Overcoming exploration in reinforcement learning with demonstrations}},
}

@article{Ghasemipour2020,
  author = {Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  url    = {http://arxiv.org/abs/2007.11091},
  date   = {2020-07},
  eprint = {2007.11091},
  title  = {{EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL}},
}

@techreport{Finn,
  author = {Finn, Chelsea and Yu, Tianhe and Fu, Justin and Abbeel, Pieter and Levine, Sergey},
  eprint = {1612.00429v2},
  title  = {{GENERALIZING SKILLS WITH SEMI-SUPERVISED REINFORCEMENT LEARNING}},
}

@techreport{Yu,
  author = {Yu, Lantao and Yu, Tianhe and Finn, Chelsea and Ermon, Stefano},
  eprint = {1909.09314v2},
  title  = {{Meta-Inverse Reinforcement Learning with Probabilistic Context Variables}},
}

@techreport{CastroDaSilva2012,
  author = {{Castro Da Silva}, Bruno and Konidaris, George and Barto, Andrew G},
  date   = {2012},
  title  = {{Learning Parameterized Skills}},
}

@inproceedings{ghasemipour2019smile,
  author    = {Ghasemipour, Seyed Kamyar Seyed and Gu, Shixiang and Zemel, Richard},
  url       = {https://github.com/},
  booktitle = {Neural Information Processing Systems (NeurIPS)},
  date      = {2019},
  title     = {{SMILe : Scalable Meta Inverse Reinforcement Learning through Context-Conditional Policies}},
}

@inproceedings{ghasemipour2020divergence,
  author    = {Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  url       = {https://github.com/KamyarGh/rl{\_}swiss/},
  booktitle = {Conference on Robot Learning (CoRL)},
  date      = {2020},
  eprint    = {1911.02256v1},
  keywords  = {Imitation Learning,State-Marginal Matching},
  title     = {{A Divergence Minimization Perspective on Imitation Learning Methods}},
}

@inproceedings{fu2018airl,
  author    = {Fu, Justin and Luo, Katie and Levine, Sergey},
  url       = {https://arxiv.org/pdf/1710.11248.pdf},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018},
  title     = {{Learning Robust Rewards With Adversarial Inverse Reinforcement Learning}},
}

@inproceedings{zhang2018mixup,
  author    = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
  url       = {http://arxiv.org/abs/1710.09412},
  booktitle = {International Conference on Learning Representations (ICLR)},
  date      = {2018-10},
  eprint    = {1710.09412},
  title     = {{mixup: Beyond Empirical Risk Minimization}},
}

@techreport{Du,
  author = {Du, Yilun and Mordatch, Igor},
  url    = {https://sites.google.com/view/igebm},
  title  = {{Implicit Generation and Generalization in Energy-Based Models}},
}

@techreport{Charlesworth,
  author = {Charlesworth, Henry and Montana, Giovanni},
  eprint = {2006.00900v1},
  isbn   = {2006.00900v1},
  title  = {{PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals}},
}

@techreport{Srivastava2020,
  author = {Srivastava, Megha and Hashimoto, Tatsunori and Liang, Percy},
  date   = {2020},
  eprint = {2007.06661v1},
  title  = {{Robustness to Spurious Correlations via Human Annotations}},
}

@techreport{Herschkowitz,
  author = {Herschkowitz, Didier and Nadal, Jean-Pierre},
  url    = {www.lps.ens.fr/risc/rescomp/},
  title  = {{Unsupervised and supervised learning: Mutual information between parameters and observations}},
}

@inproceedings{finn2016ganirl,
  author    = {Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
  booktitle = {NeurIPS Workshop on Adversarial Training},
  date      = {2016},
  eprint    = {1611.03852v3},
  keywords  = {()},
  title     = {{A Connection Between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models}},
}

@techreport{Nair,
  author = {Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  eprint = {2006.09359v1},
  title  = {{Accelerating Online Reinforcement Learning with Offline Datasets}},
}

@techreport{Song2020,
  author   = {Song, Shuran and Zeng, Andy and Lee, Johnny and Funkhouser, Thomas},
  url      = {https://graspinwild.cs.columbia.edu},
  date     = {2020},
  eprint   = {1912.04344v2},
  keywords = {Deep Learning for Visual Perception},
  number   = {1},
  title    = {{Grasping in the Wild: Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations}},
}

@techreport{Vahdat,
  author = {Vahdat, Arash and Kautz, Jan},
  eprint = {2007.03898v1},
  title  = {{NVAE: A Deep Hierarchical Variational Autoencoder}},
}

@article{Roy2018,
  author = {Roy, Aurko and Vaswani, Ashish and Neelakantan, Arvind and Parmar, Niki},
  url    = {http://arxiv.org/abs/1805.11063},
  date   = {2018-05},
  eprint = {1805.11063},
  title  = {{Theory and Experiments on Vector Quantized Autoencoders}},
}

@techreport{Jayakumar2019,
  author = {Jayakumar, Siddhant M and Czarnecki, Wojciech M and Menick, Jacob and Schwarz, Jonathan and Rae, Jack and Osidnero, Simon and Teh, Yee Whye and Harley, Tim and Deepmind, Razvan Pascanu},
  date   = {2019-09},
  title  = {{MULTIPLICATIVE INTERACTIONS AND WHERE TO FIND THEM}},
}

@techreport{Perez,
  author = {Perez, Ethan and Strub, Florian and {De Vries}, Harm and Dumoulin, Vincent and Courville, Aaron},
  url    = {www.aaai.org},
  eprint = {1709.07871v2},
  title  = {{FiLM: Visual Reasoning with a General Conditioning Layer}},
}

@inproceedings{Johannink2019,
  author    = {Johannink, T. and Bahl, S. and Nair, A. and Luo, J. and Kumar, A. and Loskyll, M. and Ojea, J.A. and Solowjow, E. and Levine, S.},
  booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  date      = {2019},
  doi       = {10.1109/ICRA.2019.8794127},
  isbn      = {9781538660263},
  issn      = {10504729},
  title     = {{Residual reinforcement learning for robot control}},
  volume    = {2019-May},
}

@inproceedings{oh2017zeroshot,
  author    = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
  url       = {https://arxiv.org/pdf/1706.05064.pdf https://sites.google.com/a/umich.},
  booktitle = {International Conference on Machine Learning (ICML)},
  date      = {2017},
  eprint    = {arXiv:1706.05064v2},
  title     = {{Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning}},
}

@inproceedings{platt2019deictic,
  author = {Platt, Robert and Kohler, Colin and Gualtieri, Marcus},
  url    = {www.aaai.org},
  date   = {2019},
  pages  = {19},
  title  = {Deictic Image Mapping: An Abstraction for Learning Pose Invariant Manipulation Policies},
}

@article{alemi2017vib,
  author = {Alemi, Alexander A. and Fischer, Ian S. and Dillon, Joshua V. and Murphy, Kevin P.},
  date   = {2017},
  title  = {Deep Variational Information Bottleneck},
}

@report{bousmalis2017simtoreal,
  author = {Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and Levine, Sergey and Vanhoucke, Vincent},
  date   = {2017},
  title  = {Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping},
}

@inproceedings{kumar2021workflow,
  author   = {Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea and Levine, Sergey},
  url      = {https://arxiv.org/abs/2109.10813v2},
  date     = {2021-09},
  doi      = {10.48550/arxiv.2109.10813},
  keywords = {offline RL,offline tuning,workflow},
  title    = {A Workflow for Offline Model-Free Robotic Reinforcement Learning},
}

@web_page{sutton2019bitter,
   author = {Richard Sutton},
   title = {The Bitter Lesson},
   url = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
   year = {2019},
}

