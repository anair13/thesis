\documentclass{article}

% \usepackage{corl_2019}
\usepackage[final]{corl_2019_preprint} % Uncomment for the camera-ready ``final'' version

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath, bm} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{graphicx}
% \usepackage{subfig}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{graphicx}
% \usepackage{caption}
\usepackage{mathtools}
% \usepackage{enumitem}
\usepackage{dsfont}
\usepackage{float}
\usepackage{makecell}
\usepackage{authblk}
\usepackage{algorithm}
\usepackage{algcompatible}
\usepackage{graphicx}
\usepackage{multirow} 
\usepackage{wrapfig}
\usepackage[table]{xcolor}% http://ctan.org/pkg/xcolors
\pdfminorversion=4

\setlength{\intextsep}{0pt}%
\renewcommand{\baselinestretch}{1.0}

\renewcommand\Authands{, }
\makeatletter
\renewcommand\AB@affilsepx{\hspace{1in} \protect\Affilfont}
\makeatother

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\usepackage{subcaption}
\DeclareMathOperator{\E}{\mathbb{E}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}

% \setlength{\belowcaptionskip}{-10pt}

\title{Deep Reinforcement Learning for Industrial Insertion Tasks with Visual Inputs and Natural Rewards
}

\author{Gerrit Schoettler$^{*1}$, Ashvin Nair$^{*2}$, Jianlan Luo$^{2}$, Shikhar Bahl$^{2}$,\\ Juan Aparicio Ojea$^{1}$, Eugen Solowjow$^{1}$, Sergey Levine$^2$}

\begin{document}
%  \maketitle


% \thispagestyle{empty}
% \pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-10pt}
\maketitle
\blfootnote{$^*$ First two authors contributed equally, $^1$ Siemens Corporation, $^2$ University of California, Berkeley.}
\begin{abstract}
Connector insertion and many other tasks commonly found in modern manufacturing settings involve complex contact dynamics and friction.
Since it is difficult to capture related physical effects with first-order modeling, traditional control methods often result in brittle and inaccurate controllers, which have to be manually tuned.
Reinforcement learning (RL) methods have been demonstrated to be capable of learning controllers in such environments from autonomous interaction with the environment, but running RL algorithms in the real world poses sample efficiency and safety challenges.
Moreover, in practical real-world settings we cannot assume access to perfect state information or dense reward signals.
In this paper, we consider a variety of difficult industrial insertion tasks with visual inputs and different natural reward specifications, namely sparse rewards and goal images.
We show that methods that combine RL with prior information, such as classical controllers or demonstrations, can solve these tasks from a reasonable amount of real-world interaction.

\end{abstract}

% \keywords{Robotics, Deep Reinforcement Learning}

%=============================================================================== SECTIONS

\input{texs/01_introduction.tex}
\input{texs/02_related_work.tex} %% related work moved after results 
\input{texs/03_background.tex}
\input{texs/04_method.tex}
\input{texs/05_experiments.tex}
\input{texs/06_results.tex}
\input{texs/07_discussion.tex}
% \section{Acknowledgements}

{ \small
% \bibliographystyle{corlabbrvnat}
\bibliographystyle{IEEEtran}
\bibliography{example}
}

\end{document}
